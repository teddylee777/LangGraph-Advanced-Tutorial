{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph V1.0 Quickstart\n",
    "\n",
    "이 튜토리얼은 간단한 설정부터 완전히 작동하는 AI 에이전트까지 단계별로 안내합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "환경 변수를 설정해야 원활하게 동작합니다.\n",
    "이를 설정하기 위해서는 `.env` 에 키를 추가해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv(override=True)\n",
    "# 추적을 위한 프로젝트 이름 설정\n",
    "logging.langsmith(\"LangChain-Advanced-Tutorial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 이름 지정\n",
    "\n",
    "모델 이름을 지정할 때 다음 형식을 사용할 수 있습니다:\n",
    "\n",
    "### 기본 형식\n",
    "\n",
    "단순히 모델 이름만 지정:\n",
    "* `'o3-mini'`\n",
    "* `'claude-sonnet-4-5'`\n",
    "\n",
    "### 통합 형식\n",
    "\n",
    "모델 제공자와 모델을 함께 지정할 수 있습니다:\n",
    "\n",
    "```\n",
    "'{model_provider}:{model}'\n",
    "```\n",
    "\n",
    "**예시:**\n",
    "* `'openai:o1'`\n",
    "* `'anthropic:claude-sonnet-4-5'`\n",
    "\n",
    "이 형식을 사용하면 하나의 인자로 모델 제공자와 모델을 동시에 명시할 수 있습니다.\n",
    "\n",
    "**주요 파라미터**\n",
    "\n",
    "* **temperature**: 출력의 무작위성을 조절하는 모델 온도 값\n",
    "* **max_tokens**: 생성할 최대 토큰 수\n",
    "* **timeout**: 응답 대기 최대 시간 (초 단위)\n",
    "* **max_retries**: 요청 실패 시 최대 재시도 횟수\n",
    "* **base_url**: 커스텀 API endpoint URL\n",
    "* **rate_limiter**: 요청 속도를 제어하는 BaseRateLimiter 인스턴스\n",
    "\n",
    "### 사용 예시\n",
    "\n",
    "```python\n",
    "model_kwargs = {\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_tokens\": 1000,\n",
    "    \"timeout\": 30\n",
    "}\n",
    "```\n",
    "\n",
    "> **참고**: 사용 가능한 전체 파라미터 목록은 각 모델 제공자의 integration reference를 참조하세요.\n",
    "\n",
    "- [공식문서](https://reference.langchain.com/python/langchain/models/?_gl=1*kundig*_gcl_au*MjAwMTM0Mzc1Mi4xNzYxNDEwNDky*_ga*MTI0ODcwNDIuMTc2MTgwNjA5Mg..*_ga_47WX3HKKY2*czE3NjE4MDYwNzUkbzUkZzEkdDE3NjE4MDYxMjEkajE0JGwwJGgw#langchain.chat_models.init_chat_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# model 인스턴스 생성\n",
    "llm = init_chat_model(\"openai:gpt-4.1\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_response\n",
    "\n",
    "result = llm.stream(\"반가워\")\n",
    "# 스트리밍 출력\n",
    "stream_response(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 에이전트 생성\n",
    "\n",
    "LangGraph 기반의 에이전트를 사용합니다. 과거 `create_react_agent` 대신 `create_agent` 를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "# 모델 식별자 문자열을 사용한 간단한 방법\n",
    "agent = create_agent(\"openai:gpt-4.1-mini\", tools=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만들어진 그래프 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "visualize_graph(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "메시지 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_graph\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "stream_graph(agent, inputs={\"messages\": [HumanMessage(content=\"안녕하세요?\")]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본 에이전트 구축\n",
    "\n",
    "질문에 답하고 도구를 호출할 수 있는 간단한 에이전트를 만듭니다. \n",
    "\n",
    "기본 날씨 함수(실제로 기능이 있는 도구는 아닙니다!) 를 도구로 사용하며, 간단한 프롬프트로 동작을 안내합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 도구(Tool)\n",
    "\n",
    "도구를 사용하면 모델이 정의한 함수를 호출하여 외부 시스템과 상호작용할 수 있습니다.\n",
    "\n",
    "LangChain 에서는 `@tool` 데코레이터를 사용하여 도구를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "# 날씨 정보를 반환하는 간단한 함수\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로는 생성한 도구를 에이전트에 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "# 에이전트 생성\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-4.1-mini\",\n",
    "    tools=[get_weather],\n",
    "    system_prompt=\"You are a helpful assistant\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프 시각화를 수행합니다. 아래 그림은 `ReAct` 에이전트의 그래프 시각화입니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "visualize_graph(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스트리밍 답변 출력을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에이전트 실행\n",
    "stream_graph(agent, inputs={\"messages\": [HumanMessage(content=\"서울 날씨가 어때?\")]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 컨택스트(Context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToolRuntime\n",
    "\n",
    "Tool 함수에 자동으로 주입되는 runtime context를 제공하는 dataclass입니다.\n",
    "\n",
    "### 주요 속성\n",
    "\n",
    "* `state`: 현재 graph state\n",
    "* `tool_call_id`: 현재 tool call의 ID\n",
    "* `config`: 현재 실행의 `RunnableConfig`\n",
    "* `context`: Runtime context (langgraph `Runtime`에서 제공)\n",
    "* `store`: 영구 저장소를 위한 `BaseStore` instance (langgraph `Runtime`에서 제공)\n",
    "* `stream_writer`: 출력 streaming을 위한 `StreamWriter` (langgraph `Runtime`에서 제공)\n",
    "\n",
    "### 사용 방법\n",
    "\n",
    "`Annotated` wrapper 없이 `runtime: ToolRuntime`을 parameter로 선언하면 됩니다.\n",
    "\n",
    "```python\n",
    "from langchain_core.tools import tool\n",
    "from langchain.tools import ToolRuntime\n",
    "\n",
    "@tool\n",
    "def my_tool(x: int, runtime: ToolRuntime) -> str:\n",
    "    \"\"\"Tool that accesses runtime context.\"\"\"\n",
    "    # state 접근\n",
    "    messages = runtime.state[\"messages\"]\n",
    "    \n",
    "    # tool_call_id 접근\n",
    "    print(f\"Tool call ID: {runtime.tool_call_id}\")\n",
    "    \n",
    "    # config 접근\n",
    "    print(f\"Run ID: {runtime.config.get('run_id')}\")\n",
    "    \n",
    "    # runtime context 접근\n",
    "    user_id = runtime.context.get(\"user_id\")\n",
    "    \n",
    "    # store 접근\n",
    "    runtime.store.put((\"metrics\",), \"count\", 1)\n",
    "    \n",
    "    # 출력 streaming\n",
    "    runtime.stream_writer.write(\"Processing...\")\n",
    "    \n",
    "    return f\"Processed {x}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "컨택스트는 도구에 전달되는 추가 정보를 제공합니다. \n",
    "\n",
    "`runtime.context` 를 통해 컨택스트에 접근할 수 있습니다.\n",
    "\n",
    "```python\n",
    "runtime.context.user_id\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "\n",
    "\n",
    "USER_DATABASE = {\n",
    "    \"teddy\": {\n",
    "        \"name\": \"Teddy Lee\",\n",
    "        \"account_type\": \"Premium\",\n",
    "        \"balance\": 5000,\n",
    "        \"email\": \"teddy@example.com\",\n",
    "    },\n",
    "    \"shirley\": {\n",
    "        \"name\": \"Shirley Kim\",\n",
    "        \"account_type\": \"Standard\",\n",
    "        \"balance\": 1200,\n",
    "        \"email\": \"shirley@example.com\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tool 함수의 parameter에 `tool_runtime`이라는 이름과 `ToolRuntime` type hint를 사용하면, tool 실행 시스템이 자동으로 runtime 정보를 포함한 instance를 주입합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 컨택스트 정의\n",
    "@dataclass\n",
    "class UserContext:\n",
    "    user_id: str\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_account_info(runtime: ToolRuntime[UserContext]) -> str:\n",
    "    \"\"\"Get the current user's account information.\"\"\"\n",
    "\n",
    "    # 사용자 컨택스트에 접근하여 `user_id` 를 가져옵니다.\n",
    "    user_id = runtime.context.user_id\n",
    "\n",
    "    if user_id in USER_DATABASE:\n",
    "        user = USER_DATABASE[user_id]\n",
    "        return f\"Account holder: {user['name']}\\nType: {user['account_type']}\\nBalance: ${user['balance']}\"\n",
    "    return \"User not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    # 에이전트 생성\n",
    "    model=\"openai:gpt-4.1-mini\",\n",
    "    tools=[get_account_info],\n",
    "    context_schema=UserContext,\n",
    "    system_prompt=\"You are a financial assistant.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_graph\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "stream_graph(\n",
    "    agent,\n",
    "    inputs={\"messages\": [HumanMessage(content=\"내 계좌의 현재 잔고를 알려주세요.\")]},\n",
    "    context=UserContext(user_id=\"teddy\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_graph(\n",
    "    agent,\n",
    "    inputs={\"messages\": [HumanMessage(content=\"내 계좌의 현재 잔고를 알려주세요.\")]},\n",
    "    context=UserContext(user_id=\"shirley\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 응답 형식(Response Format)\n",
    "\n",
    "에이전트 응답이 특정 스키마와 일치하도록 구조화된 응답 형식을 정의합니다.\n",
    "\n",
    "참고: dataclass 또는 pydantic 모델을 사용하여 응답 형식을 정의할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class ResponseFormat(BaseModel):\n",
    "    \"\"\"Response schema for the agent.\"\"\"\n",
    "\n",
    "    email_sender: str = Field(description=\"The sender of the email\")\n",
    "    email_sender_address: str = Field(description=\"The address of the sender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 구성요소를 포함한 에이전트 생성\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-4.1-mini\",\n",
    "    system_prompt=\"Extract useful information from the email.\",\n",
    "    tools=[],\n",
    "    response_format=ResponseFormat,\n",
    ")\n",
    "\n",
    "sample_input = \"\"\"From: 김철수 (chulsoo.kim@bikecorporation.me)\n",
    "Subject: \"ZENESIS\" 자전거 유통 협력 및 미팅 일정 제안\n",
    "\n",
    "안녕하세요, 이은채 대리님,\n",
    "\n",
    "저는 바이크코퍼레이션의 김철수 상무입니다. 최근 보도자료를 통해 귀사의 신규 자전거 \"ZENESIS\"에 대해 알게 되었습니다. 바이크코퍼레이션은 자전거 제조 및 유통 분야에서 혁신과 품질을 선도하는 기업으로, 이 분야에서의 장기적인 경험과 전문성을 가지고 있습니다.\n",
    "\n",
    "ZENESIS 모델에 대한 상세한 브로슈어를 요청드립니다. 특히 기술 사양, 배터리 성능, 그리고 디자인 측면에 대한 정보가 필요합니다. 이를 통해 저희가 제안할 유통 전략과 마케팅 계획을 보다 구체화할 수 있을 것입니다.\n",
    "\n",
    "또한, 협력 가능성을 더 깊이 논의하기 위해 다음 주 화요일(1월 15일) 오전 10시에 미팅을 제안합니다. 귀사 사무실에서 만나 이야기를 나눌 수 있을까요?\n",
    "\n",
    "감사합니다.\n",
    "\n",
    "김철수\n",
    "상무이사\n",
    "바이크코퍼레이션\n",
    "\"\"\"\n",
    "\n",
    "# 첫 번째 질문: 날씨 문의\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=sample_input)]},\n",
    ")\n",
    "\n",
    "# 구조화된 응답 출력\n",
    "structured_response = response[\"structured_response\"]\n",
    "structured_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "구조화된 응답 출력을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(structured_response.email_sender)\n",
    "print(structured_response.email_sender_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단기 메모리 추가\n",
    "\n",
    "에이전트에 메모리를 추가하여 상호작용 간에 상태를 유지합니다. 이를 통해 에이전트는 이전 대화와 컨텍스트를 기억할 수 있습니다.\n",
    "\n",
    "단기 기억의 유지의 범위는 `thread_id` 로 관리 합니다. 즉, 동일한 `thread_id` 는 동일한 메모리를 공유합니다.\n",
    "\n",
    "참고: 프로덕션 환경에서는 데이터베이스에 저장하는 영구 체크포인터를 사용하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "# checkpointer 생성\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "# 에이전트 생성\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    checkpointer=checkpointer,\n",
    ")\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "stream_graph(\n",
    "    agent,\n",
    "    inputs={\"messages\": [HumanMessage(content=\"안녕, 내 이름은 테디야\")]},\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_graph(\n",
    "    agent,\n",
    "    inputs={\"messages\": [HumanMessage(content=\"내 이름이 뭔지 기억나?\")]},\n",
    "    config={\"configurable\": {\"thread_id\": \"1\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_graph(\n",
    "    agent,\n",
    "    inputs={\"messages\": [HumanMessage(content=\"내 이름이 뭔지 기억나?\")]},\n",
    "    config={\"configurable\": {\"thread_id\": \"2\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 미들웨어(Middleware)\n",
    "\n",
    "미들웨어는 에이전트 실행의 모든 단계를 제어하고 커스터마이징하는 방법을 제공합니다.\n",
    "\n",
    "핵심 에이전트 루프는 모델을 호출하고, 모델이 실행할 도구를 선택하도록 한 다음, 더 이상 도구를 호출하지 않으면 종료하는 것을 포함합니다.\n",
    "\n",
    "![](./assets/langgraph-middleware.avif)\n",
    "\n",
    "미들웨어는 각 단계 전후에 후크를 노출합니다.\n",
    "\n",
    "- 에이전트 시작 전/후\n",
    "- 모델 호출 전/후\n",
    "- 도구 실행 전/후"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human in the Loop Middleware\n",
    "\n",
    "### 개요\n",
    "\n",
    "Human in the Loop Middleware는 AI 시스템의 의사결정 과정에 사람의 개입을 가능하게 하는 중간 계층입니다. 자동화된 프로세스 중 특정 시점에서 사람의 검토, 승인 또는 수정을 요구할 수 있습니다.\n",
    "\n",
    "### 주요 특징\n",
    "\n",
    "* **검증 단계 추가**: AI의 출력을 사람이 검토하고 승인하는 단계 삽입\n",
    "* **오류 방지**: 중요한 결정에 대한 사람의 최종 확인으로 오류 최소화\n",
    "* **유연한 개입**: 필요에 따라 자동/수동 모드 전환 가능\n",
    "* **피드백 루프**: 사람의 수정 사항을 학습 데이터로 활용\n",
    "\n",
    "### Parameters\n",
    "\n",
    "#### `timeout`\n",
    "* **타입**: `int` 또는 `float`\n",
    "* **기본값**: `None`\n",
    "* **설명**: 사람의 응답을 기다리는 최대 시간(초)\n",
    "* **사용법**: timeout 초과 시 기본 동작 실행 또는 예외 발생\n",
    "```python\n",
    "middleware = HumanInTheLoopMiddleware(timeout=300)  # 5분\n",
    "```\n",
    "\n",
    "#### `approval_required`\n",
    "* **타입**: `bool`\n",
    "* **기본값**: `True`\n",
    "* **설명**: 사람의 명시적 승인이 필요한지 여부\n",
    "* **사용법**: `False`로 설정 시 검토만 하고 자동 진행\n",
    "```python\n",
    "middleware = HumanInTheLoopMiddleware(approval_required=True)\n",
    "```\n",
    "\n",
    "#### `callback_function`\n",
    "* **타입**: `callable`\n",
    "* **기본값**: `None`\n",
    "* **설명**: 사람의 개입이 필요할 때 호출되는 함수\n",
    "* **사용법**: 알림, 로깅, UI 표시 등의 커스텀 동작 정의\n",
    "```python\n",
    "def notify_user(data):\n",
    "    print(f\"Review needed: {data}\")\n",
    "\n",
    "middleware = HumanInTheLoopMiddleware(callback_function=notify_user)\n",
    "```\n",
    "\n",
    "#### `intervention_condition`\n",
    "* **타입**: `callable` 또는 `str`\n",
    "* **기본값**: `\"always\"`\n",
    "* **설명**: 사람 개입이 필요한 조건 정의\n",
    "* **사용법**: 함수 또는 조건 문자열로 지정\n",
    "```python\n",
    "# 함수로 조건 정의\n",
    "def check_confidence(result):\n",
    "    return result.confidence < 0.8\n",
    "\n",
    "middleware = HumanInTheLoopMiddleware(intervention_condition=check_confidence)\n",
    "\n",
    "# 문자열로 조건 정의\n",
    "middleware = HumanInTheLoopMiddleware(intervention_condition=\"low_confidence\")\n",
    "```\n",
    "\n",
    "#### `retry_limit`\n",
    "* **타입**: `int`\n",
    "* **기본값**: `3`\n",
    "* **설명**: 사람의 응답을 요청하는 최대 재시도 횟수\n",
    "* **사용법**: 응답이 없을 때 재시도 횟수 제한\n",
    "```python\n",
    "middleware = HumanInTheLoopMiddleware(retry_limit=5)\n",
    "```\n",
    "\n",
    "#### `fallback_action`\n",
    "* **타입**: `str` 또는 `callable`\n",
    "* **기본값**: `\"reject\"`\n",
    "* **설명**: timeout 또는 응답 실패 시 수행할 동작\n",
    "* **옵션**: `\"approve\"`, `\"reject\"`, `\"skip\"`, 또는 커스텀 함수\n",
    "* **사용법**:\n",
    "```python\n",
    "middleware = HumanInTheLoopMiddleware(fallback_action=\"approve\")\n",
    "\n",
    "# 커스텀 fallback\n",
    "def custom_fallback(context):\n",
    "    return context.get(\"default_value\")\n",
    "\n",
    "middleware = HumanInTheLoopMiddleware(fallback_action=custom_fallback)\n",
    "```\n",
    "\n",
    "#### `notification_channels`\n",
    "* **타입**: `list`\n",
    "* **기본값**: `[\"console\"]`\n",
    "* **설명**: 알림을 전송할 채널 목록\n",
    "* **옵션**: `\"console\"`, `\"email\"`, `\"slack\"`, `\"webhook\"` 등\n",
    "* **사용법**:\n",
    "```python\n",
    "middleware = HumanInTheLoopMiddleware(\n",
    "    notification_channels=[\"email\", \"slack\"]\n",
    ")\n",
    "```\n",
    "\n",
    "#### `store_feedback`\n",
    "* **타입**: `bool`\n",
    "* **기본값**: `True`\n",
    "* **설명**: 사람의 피드백을 저장할지 여부\n",
    "* **사용법**: 학습 데이터로 활용하기 위해 피드백 저장\n",
    "```python\n",
    "middleware = HumanInTheLoopMiddleware(store_feedback=True)\n",
    "```\n",
    "\n",
    "#### `priority_level`\n",
    "* **타입**: `str` 또는 `int`\n",
    "* **기본값**: `\"normal\"`\n",
    "* **설명**: 개입 요청의 우선순위\n",
    "* **옵션**: `\"low\"`, `\"normal\"`, `\"high\"`, `\"critical\"` 또는 1-5\n",
    "* **사용법**:\n",
    "```python\n",
    "middleware = HumanInTheLoopMiddleware(priority_level=\"high\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import HumanInTheLoopMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.types import Command\n",
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_tool(query: str) -> str:\n",
    "    \"\"\"Search for information.\"\"\"\n",
    "    return f\"Search results for: {query}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def send_email_tool(recipient: str, subject: str, body: str) -> str:\n",
    "    \"\"\"Send an email. This is a sensitive operation.\"\"\"\n",
    "    return f\"Email sent to {recipient}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def delete_database_tool(database_name: str) -> str:\n",
    "    \"\"\"Delete a database. This is a critical operation.\"\"\"\n",
    "    return f\"Database {database_name} deleted\"\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[search_tool, send_email_tool, delete_database_tool],\n",
    "    middleware=[\n",
    "        HumanInTheLoopMiddleware(\n",
    "            interrupt_on={\n",
    "                # 민감한 작업에 대해 승인 필요\n",
    "                \"send_email_tool\": True,\n",
    "                \"delete_database_tool\": True,\n",
    "                # 안전한 작업은 자동 승인\n",
    "                \"search_tool\": False,\n",
    "            }\n",
    "        ),\n",
    "    ],\n",
    "    checkpointer=InMemorySaver(),  # 상태 지속성 필요\n",
    ")\n",
    "\n",
    "# thread_id 필요\n",
    "config = {\"configurable\": {\"thread_id\": \"123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import invoke_graph\n",
    "\n",
    "invoke_graph(\n",
    "    agent,\n",
    "    inputs={\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"teddy@example.com 에게 메일을 보내 주세요. 제목은 '테스트' 이고 내용은 '안녕하세요' 입니다.\"\n",
    "            )\n",
    "        ]\n",
    "    },\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interrupt 확인\n",
    "print(agent.get_state(config).interrupts[0].value[\"action_requests\"][0][\"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decisions: approve, reject, skip\n",
    "stream_graph(\n",
    "    agent, inputs=Command(resume={\"decisions\": [{\"type\": \"approve\"}]}), config=config\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
