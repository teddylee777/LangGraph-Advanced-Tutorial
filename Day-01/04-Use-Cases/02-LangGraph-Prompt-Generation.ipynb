{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba2b78cd",
   "metadata": {},
   "source": [
    "# GPT-5 최적화 메타 프롬프트 생성 에이전트\n",
    "\n",
    "이 튜토리얼은 GPT-5에 최적화된 프롬프트 생성 시스템을 구축하는 방법을 다룹니다. OpenAI 프롬프트 가이드북의 모범 사례를 기반으로 사용자 요구사항을 수집하고 고품질 프롬프트를 생성하는 AI 에이전트를 구현합니다.\n",
    "\n",
    "## 주요 특징\n",
    "\n",
    "### 데이터 모델\n",
    "- 필수 필드(objective, context, output_format, tone_style)로 구성\n",
    "- GPT-5 특화 기능 지원\n",
    "- 구체적인 출력 형식 지정\n",
    "\n",
    "### 요구사항 수집\n",
    "- 사용자 입력을 구체적인 질문으로 분해\n",
    "- 프롬프트 유형에 따른 맞춤형 질문 시스템\n",
    "- 정보 수집 완료 시점 자동 판단\n",
    "\n",
    "### 메타 프롬프트 엔진\n",
    "- XML 기반 구조화된 지시문\n",
    "- 추론 과정을 우선시하는 설계\n",
    "- 에스컬레이션 조건 및 안전 가이드라인 포함\n",
    "\n",
    "## 시스템 아키텍처\n",
    "\n",
    "시스템은 두 개의 주요 상태로 구성됩니다:\n",
    "\n",
    "1. 정보 수집 단계(info): 사용자 요구사항 수집\n",
    "2. 프롬프트 생성 단계(prompt): 수집된 정보 기반 프롬프트 생성\n",
    "\n",
    "LLM이 상태 전환 시점을 자동으로 결정하며, 진행상황을 실시간으로 추적합니다.\n",
    "\n",
    "![meta-prompt-generator.png](assets/meta-prompt-generator.png)\n",
    "\n",
    "## 참고자료\n",
    "- [OpenAI GPT-5 프롬프트 가이드북](https://cookbook.openai.com/examples/gpt-5/gpt-5_prompting_guide)\n",
    "- [LangGraph 공식 문서](https://langchain-ai.github.io/langgraph/)\n",
    "- [프롬프트 엔지니어링 모범 사례](https://platform.openai.com/docs/guides/prompt-engineering)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ffd226",
   "metadata": {},
   "source": [
    "## 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d6c0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv(override=True)\n",
    "# 추적을 위한 프로젝트 이름 설정\n",
    "logging.langsmith(\"LangChain-Advanced-Tutorial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65d330b",
   "metadata": {},
   "source": [
    "## 요구사항 수집\n",
    "\n",
    "사용자 요구사항을 수집하는 노드를 정의합니다.\n",
    "\n",
    "사용자에게 구체적인 정보를 요구하며, 필요한 정보가 모두 충족될 때까지 반복적으로 질문합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb32ec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "from langchain_teddynote.models import get_model_name, LLMs\n",
    "\n",
    "# GPT-5에 최적화된 사용자 요구사항 수집을 위한 시스템 메시지 템플릿\n",
    "template = \"\"\"You are a profession## 프롬프트 생성\n",
    "\n",
    "GPT-5에 최적화된 프롬프트 생성 시스템을 구축합니다. OpenAI 가이드라인을 반영한 META_PROMPT와 메시지 처리 로직을 포함합니다.\n",
    "\n",
    "### 메타 프롬프트 특징\n",
    "\n",
    "#### 구조화된 접근법\n",
    "- XML 태그를 활용한 명확한 구조 제공(`<task_definition>`, `<core_principles>`, `<safety_considerations>`)\n",
    "- 추론 과정을 우선시하는 설계\n",
    "- 문제 요청에 대한 명시적 처리 방법\n",
    "\n",
    "#### 안전성 및 신뢰성\n",
    "- 불확실한 상황에서의 대응 방법 정의\n",
    "- 입력 요구사항의 완전성 검증\n",
    "- 오류 발생 시 피드백 및 복구 메커니즘\n",
    "\n",
    "#### 품질 최적화\n",
    "- 플레이스홀더를 활용한 예시 제공\n",
    "- JSON, 마크다운 등 구체적인 출력 형식 지정\n",
    "- 요구사항에 특화된 프롬프트 생성\n",
    "\n",
    "### 메타 프롬프트 정의\n",
    "\n",
    "메타 프롬프트(Meta Prompt)는 프롬프트를 생성하고 최적화하기 위한 프롬프트 엔지니어링 기법입니다. GPT-5의 능력을 활용하여 다음을 수행합니다:\n",
    "\n",
    "#### 추론 능력 활용\n",
    "- reasoning_effort 매개변수를 통한 추론 깊이 조절\n",
    "- 단계적 사고 과정을 통한 품질 향상\n",
    "- 요구사항의 체계적 분석\n",
    "\n",
    "#### 적응형 프롬프트 설계\n",
    "- 사용자 컨텍스트에 따른 동적 조정\n",
    "- 도메인별 특화 프롬프트 생성\n",
    "- 실시간 피드백을 통한 개선\n",
    "\n",
    "#### 안전성 강화\n",
    "- 잠재적 위험 요소의 사전 식별\n",
    "- 명확한 경계 및 제한사항 설정\n",
    "- 안전 가이드라인 통합\n",
    "\n",
    "#### 구조화된 출력\n",
    "- XML 기반 명확한 지시문 구조\n",
    "- 일관된 품질 및 형식 보장\n",
    "- 재사용 가능한 프롬프트 템플릿\n",
    "\n",
    "### 적용 예시\n",
    "\n",
    "기존 프롬프트:\n",
    "```\n",
    "\"PDF에서 정보를 추출해줘\"\n",
    "```\n",
    "\n",
    "메타 프롬프트 적용 후:\n",
    "```xml\n",
    "<task_definition>\n",
    "Extract and analyze relevant information from PDF documents with contextual understanding and structured output.\n",
    "</task_definition>\n",
    "\n",
    "<reasoning_approach>\n",
    "1. Analyze document structure and content hierarchy\n",
    "2. Identify key information based on context clues\n",
    "3. Organize findings in logical, accessible format\n",
    "</reasoning_approach>\n",
    "\n",
    "<safety_guidelines>\n",
    "- Respect document confidentiality and privacy\n",
    "- Avoid speculation beyond available information\n",
    "- Clearly distinguish between explicit and inferred content\n",
    "</safety_guidelines>\n",
    "```\n",
    "\n",
    "### 참고 자료\n",
    "- [OpenAI GPT-5 프롬프트 엔지니어링 가이드](https://cookbook.openai.com/examples/gpt-5/gpt-5_prompting_guide)\n",
    "- [메타 프롬프트 모범 사례](https://platform.openai.com/docs/guides/prompt-generation)\n",
    "- [XML 기반 프롬프트 구조화 방법론](https://docs.anthropic.com/claude/docs/use-xml-tags)al prompt engineering consultant specializing in creating high-quality, production-ready prompts. Your expertise lies in systematically gathering requirements through structured inquiry.\n",
    "\n",
    "<instructions>\n",
    "Your task is to collect exactly 4 essential pieces of information through professional, focused questions:\n",
    "\n",
    "REQUIRED INFORMATION:\n",
    "1. Objective (목표): The primary goal and intended outcome of the prompt\n",
    "2. Context (맥락): The specific domain, use case, industry, or operational environment\n",
    "3. Output Format (출력 형식): The desired structure and format of the response\n",
    "4. Tone & Style (톤/스타일): The communication style and voice characteristics\n",
    "\n",
    "INQUIRY PROTOCOL:\n",
    "- Maintain a professional, consultative tone throughout the conversation\n",
    "- Ask questions using numbered format (1, 2, 3, 4) to clearly indicate which requirement you're addressing\n",
    "- Begin by identifying which requirements are missing from the user's input\n",
    "- Ask about missing requirements in logical sequence, preferably combining related items\n",
    "- Present questions in clear, numbered format for easy reference\n",
    "- Adapt your questioning based on user's level of detail and expertise\n",
    "- Use plain text format without any markdown formatting (no bold, italics, etc.)\n",
    "\n",
    "QUESTION FORMAT EXAMPLES (Plain Text):\n",
    "- \"다음 정보가 필요합니다. 1. Objective (목표): 이 프롬프트로 달성하고자 하는 주요 목표는 무엇인가요?\"\n",
    "- \"추가로 3. Output Format (출력 형식)과 4. Tone & Style (톤/스타일)에 대해 알려주세요.\"\n",
    "- \"2. Context (맥락): 어떤 도메인이나 상황에서 이 프롬프트를 사용하실 계획인가요?\"\n",
    "\n",
    "COMPLETION CRITERIA:\n",
    "- Once ALL 4 requirements (objective, context, output_format, tone_style) are collected, immediately invoke the tool\n",
    "- Confirm receipt of information professionally: \"요구사항을 모두 수집했습니다.\"\n",
    "- Do NOT ask for information beyond these 4 core requirements\n",
    "- If user provides all 4 items initially, acknowledge completeness and proceed directly to tool calling\n",
    "\n",
    "PROFESSIONAL STANDARDS:\n",
    "- Use clear, numbered references when discussing requirements\n",
    "- Acknowledge information as it's provided\n",
    "- Summarize collected information before proceeding to tool calling\n",
    "- Maintain clarity and precision in all communications\n",
    "- Output responses in plain text without markdown formatting\n",
    "</instructions>\n",
    "\n",
    "[CRITICAL] Conduct ALL conversations in Korean. Generate the final prompt in English.\n",
    "\n",
    "[INITIAL APPROACH] Begin by analyzing the user's initial input to identify which of the 4 requirements are missing, then ask for those specific items using numbered format in plain text (no markdown) in a professional manner.\"\"\"\n",
    "\n",
    "\n",
    "def get_messages_info(messages):\n",
    "    \"\"\"사용자 요구사항 수집을 위한 시스템 메시지와 기존 메시지를 결합\"\"\"\n",
    "    return [SystemMessage(content=template)] + messages\n",
    "\n",
    "\n",
    "# GPT-5에 최적화된 프롬프트 지침을 정의하는 데이터 모델 (4가지 필수 항목으로 간소화)\n",
    "class PromptInstructions(BaseModel):\n",
    "    \"\"\"Simplified instructions for GPT-5 prompt generation with 4 essential fields.\"\"\"\n",
    "\n",
    "    # 핵심 요소 (필수)\n",
    "    objective: str  # 프롬프트의 주요 목표\n",
    "    context: str  # 사용 맥락 및 도메인 정보\n",
    "\n",
    "    # 출력 관련 (필수)\n",
    "    output_format: str  # JSON, 마크다운, 구조화된 텍스트 등\n",
    "    tone_style: str  # 공식적, 친근한, 기술적 등\n",
    "\n",
    "\n",
    "# 최신 GPT 모델 사용 (GPT-4o 또는 최신 버전)\n",
    "MODEL_NAME = \"gpt-5\"\n",
    "# LLM 초기화 (reasoning effort 최적화)\n",
    "llm = ChatOpenAI(temperature=0, model=MODEL_NAME)\n",
    "# PromptInstructions 구조체를 바인딩\n",
    "llm_with_tool = llm.bind_tools([PromptInstructions])\n",
    "\n",
    "\n",
    "def info_chain(state):\n",
    "    \"\"\"개선된 정보 수집 체인 - 진행상황 피드백 포함\"\"\"\n",
    "    messages = get_messages_info(state[\"messages\"])\n",
    "    response = llm_with_tool.invoke(messages)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f314f44",
   "metadata": {},
   "source": [
    "## 프롬프트 생성\n",
    "\n",
    "GPT-5에 최적화된 프롬프트 생성 시스템을 구축합니다. OpenAI 가이드라인을 반영한 META_PROMPT와 메시지 처리 로직을 포함합니다.\n",
    "\n",
    "### 메타 프롬프트 특징\n",
    "\n",
    "#### 구조화된 접근법\n",
    "- XML 태그를 활용한 명확한 구조 제공(`<task_definition>`, `<core_principles>`, `<safety_considerations>`)\n",
    "- 추론 과정을 우선시하는 설계\n",
    "- 문제 요청에 대한 명시적 처리 방법\n",
    "\n",
    "#### 안전성 및 신뢰성\n",
    "- 불확실한 상황에서의 대응 방법 정의\n",
    "- 입력 요구사항의 완전성 검증\n",
    "- 오류 발생 시 피드백 및 복구 메커니즘\n",
    "\n",
    "#### 품질 최적화\n",
    "- 플레이스홀더를 활용한 예시 제공\n",
    "- JSON, 마크다운 등 구체적인 출력 형식 지정\n",
    "- 요구사항에 특화된 프롬프트 생성\n",
    "\n",
    "### 메타 프롬프트 정의\n",
    "\n",
    "메타 프롬프트(Meta Prompt)는 프롬프트를 생성하고 최적화하기 위한 프롬프트 엔지니어링 기법입니다. GPT-5의 능력을 활용하여 다음을 수행합니다:\n",
    "\n",
    "#### 추론 능력 활용\n",
    "- reasoning_effort 매개변수를 통한 추론 깊이 조절\n",
    "- 단계적 사고 과정을 통한 품질 향상\n",
    "- 요구사항의 체계적 분석\n",
    "\n",
    "#### 적응형 프롬프트 설계\n",
    "- 사용자 컨텍스트에 따른 동적 조정\n",
    "- 도메인별 특화 프롬프트 생성\n",
    "- 실시간 피드백을 통한 개선\n",
    "\n",
    "#### 안전성 강화\n",
    "- 잠재적 위험 요소의 사전 식별\n",
    "- 명확한 경계 및 제한사항 설정\n",
    "- 안전 가이드라인 통합\n",
    "\n",
    "#### 구조화된 출력\n",
    "- XML 기반 명확한 지시문 구조\n",
    "- 일관된 품질 및 형식 보장\n",
    "- 재사용 가능한 프롬프트 템플릿\n",
    "\n",
    "### 적용 예시\n",
    "\n",
    "기존 프롬프트:\n",
    "```\n",
    "\"PDF에서 정보를 추출해줘\"\n",
    "```\n",
    "\n",
    "메타 프롬프트 적용 후:\n",
    "```xml\n",
    "<task_definition>\n",
    "Extract and analyze relevant information from PDF documents with contextual understanding and structured output.\n",
    "</task_definition>\n",
    "\n",
    "<reasoning_approach>\n",
    "1. Analyze document structure and content hierarchy\n",
    "2. Identify key information based on context clues\n",
    "3. Organize findings in logical, accessible format\n",
    "</reasoning_approach>\n",
    "\n",
    "<safety_guidelines>\n",
    "- Respect document confidentiality and privacy\n",
    "- Avoid speculation beyond available information\n",
    "- Clearly distinguish between explicit and inferred content\n",
    "</safety_guidelines>\n",
    "```\n",
    "\n",
    "### 참고 자료\n",
    "- [OpenAI GPT-5 프롬프트 엔지니어링 가이드](https://cookbook.openai.com/examples/gpt-5/gpt-5_prompting_guide)\n",
    "- [메타 프롬프트 모범 사례](https://platform.openai.com/docs/guides/prompt-generation)\n",
    "- [XML 기반 프롬프트 구조화 방법론](https://docs.anthropic.com/claude/docs/use-xml-tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3564d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage, SystemMessage\n",
    "\n",
    "# GPT-5에 최적화된 메타 프롬프트 정의 (OpenAI GPT-5 프롬프트 가이드북 기반)\n",
    "META_PROMPT = \"\"\"You are an expert prompt engineer tasked with creating highly effective system prompts for GPT-5. Your goal is to produce prompts that are clear, actionable, and optimized for the target model's capabilities.\n",
    "\n",
    "<task_definition>\n",
    "Create a comprehensive system prompt based on the provided requirements that will guide GPT-5 to complete the specified task effectively and safely.\n",
    "</task_definition>\n",
    "\n",
    "<core_principles>\n",
    "1. **Understand the Task**: Thoroughly analyze the objective, context, requirements, and constraints\n",
    "2. **Structured Clarity**: Use XML tags, clear headings, and logical organization\n",
    "3. **Reasoning First**: Always encourage step-by-step reasoning before conclusions\n",
    "4. **Safety by Design**: Include appropriate safety guidelines and escalation paths\n",
    "5. **Actionable Instructions**: Provide specific, clear directives rather than vague guidance\n",
    "6. **Example-Driven**: Include relevant examples with placeholders when beneficial\n",
    "7. **Output Specification**: Clearly define the expected output format and structure\n",
    "</core_principles>\n",
    "\n",
    "<safety_considerations>\n",
    "- Include explicit instructions for handling ambiguous or potentially harmful requests\n",
    "- Define clear boundaries for what the AI should and should not do\n",
    "- Provide escalation conditions for uncertain situations\n",
    "- Ensure outputs align with ethical guidelines and user safety\n",
    "</safety_considerations>\n",
    "\n",
    "<prompt_structure>\n",
    "Your output should follow this structure (adapt as needed for the specific task):\n",
    "\n",
    "[Task Instruction - Clear, specific opening statement]\n",
    "\n",
    "<reasoning_approach>\n",
    "[How to think through the problem - step-by-step guidance]\n",
    "</reasoning_approach>\n",
    "\n",
    "<safety_guidelines>\n",
    "[Relevant safety considerations and limitations]\n",
    "</safety_guidelines>\n",
    "\n",
    "# Steps\n",
    "1. [Specific actionable steps]\n",
    "2. [Each step should be clear and implementable]\n",
    "3. [Include decision points and branching logic if needed]\n",
    "\n",
    "# Output Format\n",
    "[Precise specification of response format, structure, and style]\n",
    "- Use JSON for structured data outputs\n",
    "- Specify length requirements (e.g., 2-3 sentences, detailed paragraph)\n",
    "- Define tone and style requirements\n",
    "- Include any required templates or schemas\n",
    "\n",
    "# Examples\n",
    "[1-3 high-quality examples using placeholders like [PLACEHOLDER] for complex content]\n",
    "Input: [Example input with placeholders]\n",
    "Output: [Expected output format]\n",
    "\n",
    "# Edge Cases & Notes\n",
    "- [How to handle uncertain or ambiguous inputs]\n",
    "- [Escalation conditions: when to ask for clarification]\n",
    "- [Specific requirements or exceptions]\n",
    "- [Performance considerations]\n",
    "\n",
    "</prompt_structure>\n",
    "\n",
    "<escalation_conditions>\n",
    "If any requirement is unclear, contradictory, or potentially problematic:\n",
    "- Proceed with reasonable assumptions while noting uncertainties\n",
    "- Include guidance for the AI to seek clarification when needed\n",
    "- Provide fallback behaviors for edge cases\n",
    "</escalation_conditions>\n",
    "\n",
    "# Instructions\n",
    "Based on the following requirements, create an optimized system prompt that incorporates these principles:\n",
    "\n",
    "Requirements Analysis:\n",
    "{reqs}\n",
    "\n",
    "Create a system prompt that addresses these specific requirements while following GPT-5 best practices for clarity, safety, and effectiveness.\"\"\"\n",
    "\n",
    "\n",
    "def get_prompt_messages(messages: list):\n",
    "    \"\"\"프롬프트 생성을 위한 메시지 가져오기 - 도구 호출 정보 추출 및 처리\"\"\"\n",
    "    tool_call = None\n",
    "    other_msgs = []\n",
    "\n",
    "    for m in messages:\n",
    "        if isinstance(m, AIMessage) and m.tool_calls:\n",
    "            tool_call = m.tool_calls[0][\"args\"]\n",
    "        elif isinstance(m, ToolMessage):\n",
    "            continue\n",
    "        elif tool_call is not None:\n",
    "            other_msgs.append(m)\n",
    "\n",
    "    # GPT-5 최적화된 META_PROMPT로 시스템 메시지 생성\n",
    "    return [SystemMessage(content=META_PROMPT.format(reqs=tool_call))] + other_msgs\n",
    "\n",
    "\n",
    "def prompt_gen_chain(state):\n",
    "    \"\"\"개선된 프롬프트 생성 체인 - GPT-5 최적화 및 오류 처리 포함\"\"\"\n",
    "    try:\n",
    "        messages = get_prompt_messages(state[\"messages\"])\n",
    "        response = llm.invoke(messages)\n",
    "        return {\"messages\": [response]}\n",
    "    except Exception as e:\n",
    "        # 오류 처리 및 사용자 친화적 메시지\n",
    "        error_msg = f\"프롬프트 생성 중 오류가 발생했습니다: {str(e)}\"\n",
    "        return {\"messages\": [AIMessage(content=error_msg)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c4d636",
   "metadata": {},
   "source": [
    "## 상태 논리 정의\n",
    "\n",
    "챗봇의 상태를 결정하는 논리를 정의합니다.\n",
    "\n",
    "- 마지막 메시지가 tool call인 경우: prompt 상태로 전환\n",
    "- 마지막 메시지가 HumanMessage가 아닌 경우: END 상태로 전환\n",
    "- 마지막 메시지가 HumanMessage이고 이전에 tool call이 있었던 경우: prompt 상태로 전환\n",
    "- 그 외의 경우: info 상태 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e725b748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "\n",
    "\n",
    "def get_state(state):\n",
    "    \"\"\"개선된 상태 결정 로직 - GPT-5 최적화 및 더 명확한 조건 처리\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    if not messages:\n",
    "        return \"info\"\n",
    "\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    # AI 메시지에 도구 호출이 있는 경우 - 프롬프트 생성 준비\n",
    "    if isinstance(last_message, AIMessage) and last_message.tool_calls:\n",
    "        return \"add_tool_message\"\n",
    "\n",
    "    # 사용자 메시지가 아닌 경우 (AI 응답 후) - 대화 종료\n",
    "    elif not isinstance(last_message, HumanMessage):\n",
    "        return END\n",
    "\n",
    "    # 이전에 도구 호출이 있었는지 확인하여 프롬프트 상태로 전환할지 결정\n",
    "    for msg in reversed(messages[:-1]):  # 마지막 메시지 제외하고 역순으로 확인\n",
    "        if isinstance(msg, AIMessage) and msg.tool_calls:\n",
    "            return \"prompt\"\n",
    "        elif isinstance(msg, ToolMessage):\n",
    "            continue\n",
    "\n",
    "    # 기본적으로 정보 수집 상태\n",
    "    return \"info\"\n",
    "\n",
    "\n",
    "def validate_tool_call(tool_call_args):\n",
    "    \"\"\"도구 호출 인수 유효성 검사 - 4가지 필수 필드 모두 확인\"\"\"\n",
    "    required_fields = [\"objective\", \"context\", \"output_format\", \"tone_style\"]\n",
    "    for field in required_fields:\n",
    "        if not tool_call_args.get(field):\n",
    "            return False, f\"필수 필드 '{field}'가 누락되었습니다.\"\n",
    "    return True, \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3150ab",
   "metadata": {},
   "source": [
    "## 그래프 생성\n",
    "\n",
    "그래프를 생성합니다. 대화 기록 저장을 위해 MemorySaver를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e03b383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "# 개선된 State 정의 - 진행상황 추적 기능 추가\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    progress: Annotated[str, lambda x, y: y if y else x]  # 현재 진행 단계\n",
    "\n",
    "\n",
    "# 메모리에 대화 기록을 저장하기 위한 MemorySaver 초기화\n",
    "memory = MemorySaver()\n",
    "\n",
    "# 상태 그래프 초기화\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# 노드 추가\n",
    "workflow.add_node(\"info\", info_chain)\n",
    "workflow.add_node(\"prompt\", prompt_gen_chain)\n",
    "\n",
    "\n",
    "@workflow.add_node\n",
    "def add_tool_message(state: State):\n",
    "    \"\"\"개선된 도구 메시지 추가 - 유효성 검사 및 피드백 포함\"\"\"\n",
    "    try:\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        tool_call = last_message.tool_calls[0]\n",
    "        tool_args = tool_call[\"args\"]\n",
    "\n",
    "        # 도구 호출 유효성 검사\n",
    "        is_valid, error_msg = validate_tool_call(tool_args)\n",
    "\n",
    "        if not is_valid:\n",
    "            # 유효하지 않은 경우 오류 메시지 반환\n",
    "            return {\n",
    "                \"messages\": [\n",
    "                    ToolMessage(\n",
    "                        content=f\"요구사항 정보가 불완전합니다: {error_msg}. 더 자세한 정보를 제공해 주세요.\",\n",
    "                        tool_call_id=tool_call[\"id\"],\n",
    "                    )\n",
    "                ],\n",
    "                \"progress\": \"요구사항 재수집 필요\",\n",
    "            }\n",
    "\n",
    "        # 성공적으로 정보를 수집한 경우\n",
    "        success_message = f\"\"\"요구사항 수집 완료\n",
    "\n",
    "수집된 정보:\n",
    "- 목표: {tool_args.get('objective', '미지정')}\n",
    "- 맥락: {tool_args.get('context', '미지정')}\n",
    "- 출력 형식: {tool_args.get('output_format', '미지정')}\n",
    "- 톤/스타일: {tool_args.get('tone_style', '미지정')}\n",
    "\n",
    "최적화된 프롬프트를 생성합니다.\"\"\"\n",
    "\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                ToolMessage(content=success_message, tool_call_id=tool_call[\"id\"])\n",
    "            ],\n",
    "            \"progress\": \"프롬프트 생성 중\",\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        # 오류 처리\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                ToolMessage(\n",
    "                    content=f\"요구사항 처리 중 오류가 발생했습니다: {str(e)}\",\n",
    "                    tool_call_id=state[\"messages\"][-1].tool_calls[0][\"id\"],\n",
    "                )\n",
    "            ],\n",
    "            \"progress\": \"오류 발생\",\n",
    "        }\n",
    "\n",
    "\n",
    "# 조건부 상태 전환 정의 - 더 명확한 플로우\n",
    "workflow.add_conditional_edges(\n",
    "    \"info\",\n",
    "    get_state,\n",
    "    {\"add_tool_message\": \"add_tool_message\", \"info\": \"info\", END: END},\n",
    ")\n",
    "\n",
    "# 엣지 정의\n",
    "workflow.add_edge(\"add_tool_message\", \"prompt\")\n",
    "workflow.add_edge(\"prompt\", END)\n",
    "workflow.add_edge(START, \"info\")\n",
    "\n",
    "# 그래프 컴파일 - 향상된 메모리 관리\n",
    "graph = workflow.compile(\n",
    "    checkpointer=memory,\n",
    "    interrupt_before=[],  # 필요시 중단점 설정\n",
    "    interrupt_after=[],  # 필요시 중단점 설정\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9d8b24",
   "metadata": {},
   "source": [
    "그래프를 시각화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfec101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "visualize_graph(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3849ce",
   "metadata": {},
   "source": [
    "## 실행\n",
    "\n",
    "생성한 그래프를 실행하여 프롬프트를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c97d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langchain_teddynote.messages import stream_graph\n",
    "\n",
    "\n",
    "def run_prompt_generator():\n",
    "    \"\"\"GPT-5 최적화된 프롬프트 생성기 실행\"\"\"\n",
    "\n",
    "    # 구성 설정 초기화 (고유한 thread_id 생성)\n",
    "    config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "    print(\"GPT-5 최적화 프롬프트 생성기\")\n",
    "    print(\"프롬프트 생성을 위한 요구사항을 수집합니다.\")\n",
    "    print(\"'q' 또는 'Q'를 입력하면 종료됩니다.\\n\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            # 사용자 입력 받기\n",
    "            print(\"=\" * 60)\n",
    "            user = input(\"사용자 입력: \")\n",
    "            print()\n",
    "\n",
    "        except (KeyboardInterrupt, EOFError):\n",
    "            print(\"\\n프로그램을 종료합니다.\")\n",
    "            break\n",
    "\n",
    "        # 종료 조건 확인\n",
    "        if user.lower() in {\"q\", \"quit\", \"exit\", \"종료\", \"끝\"}:\n",
    "            print(\"프롬프트 생성기를 종료합니다.\")\n",
    "            break\n",
    "\n",
    "        # 빈 입력 처리\n",
    "        if not user.strip():\n",
    "            print(\"입력이 비어있습니다. 프롬프트에 대한 요구사항을 입력해 주세요.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            stream_graph(\n",
    "                graph,\n",
    "                {\"messages\": [HumanMessage(content=user)], \"progress\": \"시작\"},\n",
    "                config=config,\n",
    "                node_names=[\"info\", \"prompt\", \"add_tool_message\"],\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"오류 발생: {str(e)}\")\n",
    "            print(\"다시 시도해 주세요.\\n\")\n",
    "\n",
    "\n",
    "# 프롬프트 생성기 실행\n",
    "if __name__ == \"__main__\":\n",
    "    run_prompt_generator()\n",
    "else:\n",
    "    # 노트북에서 실행할 때\n",
    "    print(\"실행 방법:\")\n",
    "    print(\"`run_prompt_generator()` 함수를 호출하여 시작하세요.\")\n",
    "    print(\"또는 아래 코드를 직접 실행하세요:\\n\")\n",
    "\n",
    "    # 간단한 실행 예제\n",
    "    config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "    print(\"GPT-5 최적화 프롬프트 생성기 준비 완료\")\n",
    "    print(\"대화를 시작하려면 다음과 같이 입력하세요:\")\n",
    "    print(\"```python\")\n",
    "    print('user_input = \"블로그 포스트 작성을 위한 프롬프트를 만들고 싶어요\"')\n",
    "    print(\n",
    "        \"stream_graph(graph, {'messages': [HumanMessage(content=user_input)], 'progress': '시작'}, config=config)\"\n",
    "    )\n",
    "    print(\"```\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
