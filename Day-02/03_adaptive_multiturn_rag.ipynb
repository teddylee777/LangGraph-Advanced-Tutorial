{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d39510b3",
   "metadata": {},
   "source": [
    "# Adaptive RAG\n",
    "\n",
    "### 주요 학습 주제\n",
    "\n",
    "#### 1. Intent Classification & Complexity Analysis\n",
    "> **유저 질의 의도 분류 및 복잡도 기반 라우팅**\n",
    "- 질문 복잡도(simple/medium/complex)를 자동 분류하여 최적 전략 선택\n",
    "- 단순 질문 → no-retrieval 또는 경량 검색(K=2)\n",
    "- 중간 질문 → 단일 스텝 검색 + 그레이딩\n",
    "- 복잡 질문 → 반복 검색 + 쿼리 분해\n",
    "\n",
    "#### 2. Query Transformation (HyDE, Rewrite 등 User Input 을 시스템에 맞게 변형하는 것)\n",
    "> **질문과 문서 간 더 정확한 검색을 위한 질문 변형 기법들**\n",
    "- **HyDE(Hypothetical Document Embeddings)**: 가설 답변 생성 → 임베딩 → 검색 시드\n",
    "  > 실무에서는 쓸모 없는 경우가 대부분입니다.\n",
    "- **Query Rewrite(Query Construction)**: 질의 정제 및 다변형 질의 생성 → TOP-K 융합\n",
    "  > 검색 정확도 향상 및 의미적 차이를 해소\n",
    "\n",
    "#### 3. 라우팅 전략 및 Fallback 보장\n",
    "> **다양한 라우팅 구현 방법과 탈출 방지**\n",
    "- **프롬프트 기반 라우팅**: LLM Structured Output(JSON)으로 경로 결정\n",
    "- **툴 기반 라우팅**: Tool calling으로 노드 선택\n",
    "- **Default Fallback 필수**: 모든 분기에서 최종 경로 보장 → 그래프 무한루프/탈출 방지\n",
    "\n",
    "#### 4. Hallucination & Relevance Grading\n",
    "> **답변 품질 검증 및 재시도 전략**\n",
    "- 답변-근거 일치 여부 판단(환각 감지)\n",
    "- 검색 문서 관련성 평가\n",
    "- 실패 시 → 재검색 또는 경로 승급(single → iterative)\n",
    "\n",
    "## 아키텍처 개요\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    A[사용자 질문 + thread_id] --> B[복잡도 분류기: gpt-4o-mini]\n",
    "    B --> C{복잡도 분류}\n",
    "    C -->|simple| D[no-retrieval / 직접 생성]\n",
    "    C -->|medium| E[단일 검색 + 그레이딩]\n",
    "    C -->|complex| F[HyDE 변형 + 검색]\n",
    "    D --> G[답변 생성 with 대화 히스토리]\n",
    "    E --> H[문서 검색: Qdrant docs_te3l]\n",
    "    F --> I[문서 검색: Qdrant docs_te3l]\n",
    "    H --> J[관련성 그레이딩]\n",
    "    I --> J\n",
    "    J -->|관련 있음| K[답변 생성 with 대화 히스토리]\n",
    "    J -->|관련 없음| D\n",
    "    K --> L[환각 검증]\n",
    "    L -->|통과| M[최종 답변]\n",
    "    L -->|실패 & retry < 2| H\n",
    "    L -->|실패 & retry >= 2| M\n",
    "    G --> M\n",
    "    M --> N[Checkpointer: thread별 상태 저장]\n",
    "```\n",
    "\n",
    "### 주요 변경사항 (v2.0 - Multi-Turn 지원)\n",
    "\n",
    "#### 1. 메모리 관리 아키텍처 변경\n",
    "- **이전**: Mem0 기반 Long-Term Memory\n",
    "  - 별도의 메모리 노드 (`save_memory`) 필요\n",
    "  - 사용자별 메모리 저장 및 검색\n",
    "- **현재**: LangGraph Checkpointer 기반 Short-Term Memory\n",
    "  - Thread ID 기반 대화 히스토리 자동 관리\n",
    "  - Messages 필드에 대화 내용 누적 저장\n",
    "  - 노드 간 상태 자동 체크포인트\n",
    "\n",
    "#### 2. Multi-Turn 대화 지원\n",
    "- **동일 thread_id**: 이전 대화 컨텍스트 자동 로드\n",
    "  - 대화 히스토리를 프롬프트에 자동 포함\n",
    "  - \"그것\", \"그거\" 등 대명사 참조 해결\n",
    "- **다른 thread_id**: 새로운 대화 세션 시작\n",
    "  - 독립적인 컨텍스트 관리\n",
    "\n",
    "#### 3. 그래프 플로우 최적화\n",
    "- **classify 직후 조건부 라우팅**: 더 명확한 경로 선택\n",
    "- **save_memory 노드 제거**: Checkpointer가 자동 관리\n",
    "- **retry 로직 개선**: 환각 감지 시 retrieve로 재시도\n",
    "\n",
    "---\n",
    "\n",
    "## 참고문헌\n",
    "- **Adaptive-RAG 논문**: [arXiv:2403.14403](https://arxiv.org/abs/2403.14403) - 질문 복잡도 기반 동적 전략 선택\n",
    "- **LangChain 한국어 튜토리얼**: [위키독스 Adaptive/Agentic RAG](https://wikidocs.net/267814) - 실전 흐름 예시\n",
    "- **LangGraph Adaptive RAG**: [튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_adaptive_rag/) - Document Grader / Routing Baseline Code\n",
    "- **Mem0 Self-host Quickstart**: [공식 문서](https://docs.mem0.ai/open-source/python-quickstart)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5097c2c",
   "metadata": {},
   "source": [
    "# 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e520cb2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 환경 설정 및 초기화\n",
    "# ============================================================================\n",
    "\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from qdrant_client.models import PointStruct\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5822e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# OpenAI / OpenRouter 모델 초기화 헬퍼\n",
    "# ----------------------------------------------------------------------------\n",
    "from typing import Literal\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def _resolve_api_context() -> tuple[str, str]:\n",
    "    \"\"\"선택된 API 키와 베이스 URL 정보를 반환합니다.\"\"\"\n",
    "    api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise RuntimeError(\"OPENROUTER_API_KEY가 필요합니다.\")\n",
    "\n",
    "    base_url = os.getenv(\"OPENROUTER_API_BASE\") or \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "    return (api_key, base_url)\n",
    "\n",
    "\n",
    "def create_openrouter_llm(\n",
    "    model: str = \"openai/gpt-4.1-mini\",\n",
    "    temperature: float = 0.3,\n",
    "    max_tokens: int | None = None,\n",
    "    **kwargs: object,\n",
    ") -> ChatOpenAI:\n",
    "    \"\"\"OpenAI 호환 LLM 생성 헬퍼.\n",
    "\n",
    "    Args:\n",
    "        model: 모델 이름. OpenRouter에서는 provider/model 형식 사용 가능\n",
    "               (예: openai/gpt-4o, anthropic/claude-3-sonnet, google/gemini-pro)\n",
    "        temperature: 생성 온도 (0.0-2.0)\n",
    "        max_tokens: 최대 생성 토큰 수\n",
    "\n",
    "    Returns:\n",
    "        ChatOpenAI: 설정된 LLM 인스턴스\n",
    "    \"\"\"\n",
    "    api_key, base_url = _resolve_api_context()\n",
    "\n",
    "    openai_kwargs: dict = {\n",
    "        \"model\": model,\n",
    "        \"api_key\": api_key,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_retries\": 3,\n",
    "        \"timeout\": 60,\n",
    "        **kwargs,\n",
    "    }\n",
    "    if max_tokens is not None:\n",
    "        openai_kwargs[\"max_tokens\"] = max_tokens\n",
    "    if base_url:\n",
    "        openai_kwargs[\"base_url\"] = base_url\n",
    "    return ChatOpenAI(**openai_kwargs)\n",
    "\n",
    "\n",
    "def create_embedding_model(\n",
    "    model: str = \"openai/text-embedding-3-small\",\n",
    "    **kwargs,\n",
    ") -> OpenAIEmbeddings:\n",
    "    \"\"\"OpenAI 호환 임베딩 모델 생성.\n",
    "\n",
    "    Args:\n",
    "        model: 임베딩 모델 이름. OpenRouter에서는 provider/model 형식 사용 가능\n",
    "               (예: openai/text-embedding-3-small, openai/text-embedding-3-large)\n",
    "        **kwargs: 추가 파라미터 (encoding_format 등은 model_kwargs로 전달됨)\n",
    "\n",
    "    Returns:\n",
    "        OpenAIEmbeddings: 설정된 임베딩 모델 인스턴스\n",
    "    \"\"\"\n",
    "    api_key, base_url = _resolve_api_context()\n",
    "\n",
    "    # 전달받은 kwargs에서 model_kwargs로 전달할 파라미터 분리\n",
    "    # encoding_format, extra_headers 등은 model_kwargs로 전달\n",
    "    model_kwargs: dict = {}\n",
    "    embedding_kwargs: dict = {\n",
    "        \"model\": model,\n",
    "        \"api_key\": api_key,\n",
    "        \"show_progress_bar\": True,\n",
    "        \"skip_empty\": True,\n",
    "    }\n",
    "\n",
    "    # 전달받은 kwargs 처리\n",
    "    for key, value in kwargs.items():\n",
    "        # OpenRouter API 특정 파라미터는 model_kwargs로 전달\n",
    "        if key in (\"encoding_format\"):\n",
    "            model_kwargs[key] = value\n",
    "        else:\n",
    "            # 나머지는 OpenAIEmbeddings에 직접 전달\n",
    "            embedding_kwargs[key] = value\n",
    "\n",
    "    if base_url:\n",
    "        embedding_kwargs[\"base_url\"] = base_url\n",
    "\n",
    "    # model_kwargs가 있으면 전달\n",
    "    if model_kwargs:\n",
    "        embedding_kwargs[\"model_kwargs\"] = model_kwargs\n",
    "\n",
    "    return OpenAIEmbeddings(**embedding_kwargs)\n",
    "\n",
    "\n",
    "def create_embedding_model_direct(\n",
    "    model: str = \"qwen/qwen3-embedding-0.6b\",\n",
    "    encoding_format: Literal[\"float\", \"base64\"] = \"float\",\n",
    "    input_text: str | list[str] = \"\",\n",
    "    **kwargs,\n",
    ") -> list[float] | list[list[float]]:\n",
    "    \"\"\"OpenAI SDK를 직접 사용하여 임베딩 생성 (encoding_format 지원).\n",
    "\n",
    "    LangChain의 OpenAIEmbeddings가 encoding_format을 지원하지 않을 때 사용.\n",
    "\n",
    "    Args:\n",
    "        model: 임베딩 모델 이름\n",
    "        encoding_format: 인코딩 형식 (\"float\")\n",
    "        input_text: 임베딩할 텍스트 (문자열 또는 문자열 리스트)\n",
    "        **kwargs: 추가 파라미터\n",
    "\n",
    "    Returns:\n",
    "        임베딩 벡터 리스트 (단일 텍스트) 또는 리스트의 리스트 (여러 텍스트)\n",
    "    \"\"\"\n",
    "    from openai import OpenAI\n",
    "\n",
    "    api_key, base_url = _resolve_api_context()\n",
    "\n",
    "    client = OpenAI(\n",
    "        base_url=base_url,\n",
    "        api_key=api_key,\n",
    "    )\n",
    "\n",
    "    # input_text가 비어있으면 kwargs에서 가져오기\n",
    "    if not input_text:\n",
    "        input_text = kwargs.get(\"input\", \"\")\n",
    "\n",
    "    response = client.embeddings.create(\n",
    "        model=model,\n",
    "        input=input_text,\n",
    "        encoding_format=encoding_format,\n",
    "    )\n",
    "\n",
    "    # 단일 텍스트인 경우 첫 번째 임베딩 반환\n",
    "    if isinstance(input_text, str):\n",
    "        return response.data[0].embedding\n",
    "    else:\n",
    "        # 여러 텍스트인 경우 모든 임베딩 반환\n",
    "        return [item.embedding for item in response.data]\n",
    "\n",
    "\n",
    "def get_available_model_types() -> dict[str, list[str]]:\n",
    "    \"\"\"OpenRouter에서 사용 가능한 모델 유형을 반환합니다.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, list[str]]: 모델 유형별 모델 목록\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"chat\": [\n",
    "            \"openai/gpt-4.1\",\n",
    "            \"openai/gpt-4.1-mini\",\n",
    "            \"openai/gpt-5\",\n",
    "            \"openai/gpt-5-mini\",\n",
    "            \"anthropic/claude-sonnet-4.5\",\n",
    "            \"anthropic/claude-haiku-4.5\",\n",
    "            \"google/gemini-2.5-flash-preview-09-2025\",\n",
    "            \"google/gemini-pro-2.5\",\n",
    "            \"x-ai/grok-4-fast\",\n",
    "            \"moonshotai/kimi-k2-thinking\",\n",
    "            \"liquid/lfm-2.2-6b\",\n",
    "            \"z-ai/glm-4.6\",\n",
    "        ],\n",
    "        \"embedding\": [\n",
    "            \"openai/text-embedding-3-small\",\n",
    "            \"openai/text-embedding-3-large\",\n",
    "            \"google/gemini-embedding-001\",\n",
    "            \"qwen/qwen3-embedding-0.6b\",\n",
    "            \"qwen/qwen3-embedding-4b\",\n",
    "            \"qwen/qwen3-embedding-8b\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "\n",
    "embeddings = create_embedding_model()\n",
    "llm = create_openrouter_llm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54626bf1",
   "metadata": {},
   "source": [
    "## 1.1 Qdrant 로컬 실행 (Docker)\n",
    "\n",
    "Qdrant를 로컬 Docker 컨테이너로 실행합니다.  \n",
    "문서 스토어와 Mem0 메모리 스토어 모두 동일한 Qdrant 인스턴스를 사용하되 **컬렉션을 분리**합니다.\n",
    "\n",
    "- **문서 컬렉션**: `docs_te3l`\n",
    "- **메모리 컬렉션**: `mem0_user`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8912d7fb",
   "metadata": {},
   "source": [
    "## 2.1 Intent Classification (의도 분류)\n",
    "\n",
    "질문의 의도를 분류하여 적절한 처리 전략을 선택합니다.\n",
    "\n",
    "### 왜 필요한가?\n",
    "1. **적응형 처리**: 질문 유형에 따라 다른 처리 전략 사용\n",
    "2. **라우팅 최적화**: 의도에 맞는 노드/파이프라인으로 라우팅\n",
    "3. **사용자 경험 향상**: 정확한 의도 파악으로 더 나은 답변 제공\n",
    "\n",
    "### 5가지 의도 유형\n",
    "- **SEARCH**: 특정 정보 찾기 (조항, 섹션 등)\n",
    "- **EXPLAIN**: 개념/용어 설명\n",
    "- **COMPARE**: 여러 항목 비교\n",
    "- **CALCULATE**: 수치 계산\n",
    "- **ANALYZE**: 복합 분석 (조건부 추론, 영향 평가 등)\n",
    "\n",
    "### Structured Output의 장점\n",
    "- **타입 안전성**: Pydantic으로 구조 검증\n",
    "- **일관성**: 항상 동일한 형식의 응답\n",
    "- **디버깅 용이**: 명확한 스키마\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f4fc258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Intent Classification 테스트\n",
      "============================================================\n",
      "\n",
      "[질문 1]: 계약서 A의 제5조 내용이 뭐야?\n",
      "  → Intent: SEARCH\n",
      "  → Confidence: 0.95\n",
      "  → Reasoning: The question is asking for specific information regarding the content of Article 5 in Contract A, which aligns with the characteristics of a SEARCH intent.\n",
      "  → Keywords: 계약서 A, 제5조, 내용\n",
      "------------------------------------------------------------\n",
      "\n",
      "[질문 2]: 자기자본비율이 무슨 뜻이야?\n",
      "  → Intent: EXPLAIN\n",
      "  → Confidence: 0.95\n",
      "  → Reasoning: The question asks for the meaning of '자기자본비율' (equity ratio), which indicates a request for an explanation of a financial term.\n",
      "  → Keywords: 자기자본비율, meaning, explain\n",
      "------------------------------------------------------------\n",
      "\n",
      "[질문 3]: A은행과 B은행의 자기자본비율을 비교해줘\n",
      "  → Intent: COMPARE\n",
      "  → Confidence: 0.95\n",
      "  → Reasoning: The question explicitly asks to compare the capital adequacy ratios of two banks (A은행 and B은행), which fits the characteristics of a comparison intent.\n",
      "  → Keywords: A은행, B은행, 자기자본비율\n",
      "------------------------------------------------------------\n",
      "\n",
      "[질문 4]: 이 계약의 총 비용을 계산해줘\n",
      "  → Intent: CALCULATE\n",
      "  → Confidence: 0.95\n",
      "  → Reasoning: The question asks for the total cost of a contract, which indicates a request for numerical calculation related to financial figures.\n",
      "  → Keywords: 계약, 총 비용, 계산\n",
      "------------------------------------------------------------\n",
      "\n",
      "[질문 5]: 만약 금리가 상승하면 우리 포트폴리오에 미치는 영향은?\n",
      "  → Intent: ANALYZE\n",
      "  → Confidence: 0.92\n",
      "  → Reasoning: The question asks about the impact on a portfolio if interest rates rise, which involves conditional reasoning and an assessment of potential effects, fitting the ANALYZE category.\n",
      "  → Keywords: 금리, 상승, 포트폴리오, 영향\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Intent Classification 구현\n",
    "# ============================================================================\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Intent Classification Output Schema\n",
    "class IntentResult(BaseModel):\n",
    "    \"\"\"Intent Classification Result\"\"\"\n",
    "\n",
    "    intent: Literal[\"SEARCH\", \"EXPLAIN\", \"COMPARE\", \"CALCULATE\", \"ANALYZE\"] = Field(\n",
    "        description=\"User question intent\"\n",
    "    )\n",
    "    confidence: float = Field(ge=0.0, le=1.0, description=\"Classification confidence (0.0-1.0)\")\n",
    "    reasoning: str = Field(description=\"Classification reasoning\")\n",
    "    keywords: list[str] = Field(description=\"Extracted key keywords\")\n",
    "\n",
    "\n",
    "def classify_intent(query: str, llm: ChatOpenAI) -> IntentResult:\n",
    "    \"\"\"\n",
    "    사용자 질문의 의도를 분류합니다.\n",
    "\n",
    "    Args:\n",
    "        query: 사용자 질문\n",
    "        llm: LLM 모델 (ChatOpenAI)\n",
    "\n",
    "    Returns:\n",
    "        IntentResult: 의도 분류 결과 (intent, confidence, reasoning, keywords)\n",
    "    \"\"\"\n",
    "    # Structured Output 설정\n",
    "    structured_llm = llm.with_structured_output(IntentResult)\n",
    "    # Intent Classification Prompt\n",
    "    INTENT_CLASSIFICATION_PROMPT = \"\"\"You are an intent classification expert for a legal/financial document Q&A system.\n",
    "    Classify the user's question into one of the following 5 intent categories:\n",
    "\n",
    "    **Intent Definitions**:\n",
    "\n",
    "    1. **SEARCH**: Retrieve specific information (articles, sections, keyword search)\n",
    "    - Characteristics: \"What is ~?\", \"Find ~\", \"What does ~ say?\"\n",
    "\n",
    "    2. **EXPLAIN**: Explain terms/concepts, interpret legal meanings\n",
    "    - Characteristics: \"What does ~ mean?\", \"Explain ~\", \"Why is ~?\"\n",
    "\n",
    "    3. **COMPARE**: Compare multiple items, analyze differences\n",
    "    - Characteristics: \"Compare A and B\", \"What are the differences?\", \"What changed?\"\n",
    "\n",
    "    4. **CALCULATE**: Perform numerical calculations, compute amounts\n",
    "    - Characteristics: \"How much?\", \"What is the total cost?\", \"Calculate ~\"\n",
    "\n",
    "    5. **ANALYZE**: Complex analysis (comparison + explanation, impact assessment, conditional reasoning)\n",
    "    - Characteristics: \"Analyze ~\", \"What is the impact?\", \"What if ~?\", \"Evaluate ~\"\n",
    "\n",
    "    **Few-shot Examples**:\n",
    "\n",
    "    Example 1 (SEARCH):\n",
    "    Question: \"What is the content of Article 5 in Contract A?\"\n",
    "    Analysis: This is a simple lookup question for a specific article (Article 5).\n",
    "    → intent: SEARCH, confidence: 0.95, keywords: [\"Contract A\", \"Article 5\"]\n",
    "\n",
    "    Example 2 (COMPARE):\n",
    "    Question: \"Compare the capital adequacy ratios of Bank A and Bank B\"\n",
    "    Analysis: This question compares financial indicators of two banks.\n",
    "    → intent: COMPARE, confidence: 0.90, keywords: [\"Bank A\", \"Bank B\", \"capital adequacy ratio\"]\n",
    "\n",
    "    Example 3 (ANALYZE):\n",
    "    Question: \"What would be the impact on our portfolio if interest rates rise?\"\n",
    "    Analysis: This is a complex question requiring conditional scenario analysis and impact assessment.\n",
    "    → intent: ANALYZE, confidence: 0.92, keywords: [\"interest rate\", \"rise\", \"portfolio\", \"impact\"]\n",
    "\n",
    "    **Current Question**: {query}\n",
    "\n",
    "    Classify the intent of the question above and respond with confidence, reasoning, and keywords.\n",
    "    \"\"\"\n",
    "    # 프롬프트 생성\n",
    "    prompt = INTENT_CLASSIFICATION_PROMPT.format(query=query)\n",
    "\n",
    "    result: IntentResult = structured_llm.invoke(prompt)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# 테스트\n",
    "print(\"\\nIntent Classification 테스트\\n\" + \"=\" * 60)\n",
    "\n",
    "# LLM 생성 (OpenRouter 헬퍼 사용)\n",
    "test_llm = create_openrouter_llm(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "test_queries = [\n",
    "    \"계약서 A의 제5조 내용이 뭐야?\",\n",
    "    \"자기자본비율이 무슨 뜻이야?\",\n",
    "    \"A은행과 B은행의 자기자본비율을 비교해줘\",\n",
    "    \"이 계약의 총 비용을 계산해줘\",\n",
    "    \"만약 금리가 상승하면 우리 포트폴리오에 미치는 영향은?\",\n",
    "]\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\n[질문 {i}]: {query}\")\n",
    "    try:\n",
    "        result = classify_intent(query, test_llm)\n",
    "        print(f\"  → Intent: {result.intent}\")\n",
    "        print(f\"  → Confidence: {result.confidence:.2f}\")\n",
    "        print(f\"  → Reasoning: {result.reasoning}\")\n",
    "        print(f\"  → Keywords: {', '.join(result.keywords)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  → 분류 실패: {e}\")\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06edaa12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qdrant 연결 성공! 현재 컬렉션 수: 14\n",
      "(\"   기존 컬렉션: ['day2_kiwi_bm25_real_test', 'day2_product', \"\n",
      " \"'day2_productionize_sample_collection', 'day2_int8', 'hybrid_search', \"\n",
      " \"'ranking_test', 'multi_vector_demo', 'day2_kiwi_bm25_hybrid', \"\n",
      " \"'chonkie_e2e_pipeline', 'law_docs_v1', 'mem0migrations', 'docs_te3l', \"\n",
      " \"'chonkie_demo', 'mem0_user']\")\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Qdrant Docker 실행 및 연결 테스트\n",
    "# ============================================================================\n",
    "### TODO: 1~2번 실습에서 사용한 문서를 이용해야합니다.\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "try:\n",
    "    qdrant_client = QdrantClient(url=\"http://localhost:6333\")\n",
    "    collections = qdrant_client.get_collections().collections\n",
    "    print(f\"Qdrant 연결 성공! 현재 컬렉션 수: {len(collections)}\")\n",
    "    if collections:\n",
    "        pprint(f\"   기존 컬렉션: {[c.name for c in collections]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Qdrant 연결 실패: {e}\")\n",
    "    print(\"   Qdrant가 실행 중인지 확인하세요: http://localhost:6333/dashboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1992151f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0563f49c6ed44aa08d0f9f4a4f43341e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인덱싱/검색 실패: Unexpected Response: 404 (Not Found)\n",
      "Raw response content:\n",
      "b''\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j_/l84vhzzn61b0tvhmqfzxn2kc0000gn/T/ipykernel_26581/491099288.py:23: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_results = qdrant_client.search(\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 문서 인덱싱 및 검색 유틸리티\n",
    "# ============================================================================\n",
    "\n",
    "### TODO: 1~2번 실습에서 사용한 문서를 이용해야합니다.\n",
    "\n",
    "\n",
    "def search_documents(query: str, top_k: int = 5) -> list[dict]:\n",
    "    \"\"\"\n",
    "    쿼리로 문서를 검색합니다.\n",
    "\n",
    "    Args:\n",
    "        query: 검색 쿼리\n",
    "        top_k: 반환할 상위 문서 수\n",
    "\n",
    "    Returns:\n",
    "        검색된 문서 리스트 (text, score, metadata)\n",
    "    \"\"\"\n",
    "    # 쿼리 임베딩\n",
    "    query_vector = embeddings.embed_query(query)\n",
    "\n",
    "    # 검색\n",
    "    search_results = qdrant_client.search(\n",
    "        collection_name=\"\",  # TODO: 1~2번 실습에서 사용한 문서를 이용해야합니다.\n",
    "        query_vector=query_vector,\n",
    "        limit=top_k,\n",
    "    )\n",
    "\n",
    "    # 결과 포맷팅\n",
    "    results = []\n",
    "    for hit in search_results:\n",
    "        results.append(\n",
    "            {\n",
    "                \"text\": hit.payload.get(\"text\", \"\"),\n",
    "                \"score\": hit.score,\n",
    "                \"metadata\": {k: v for k, v in hit.payload.items() if k != \"text\"},\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "try:\n",
    "    # indexed_count = index_documents(sample_docs)\n",
    "    # print(f\"{indexed_count}개 문서 인덱싱 완료\")\n",
    "\n",
    "    # 테스트 검색\n",
    "    test_query = \"LangChain이 무엇인가요?\"\n",
    "    results = search_documents(test_query, top_k=2)\n",
    "    print(f\"\\n테스트 검색: '{test_query}'\")\n",
    "    for i, r in enumerate(results, 1):\n",
    "        print(f\"   {i}. [Score: {r['score']:.3f}] {r['text'][:80]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"인덱싱/검색 실패: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d94233",
   "metadata": {},
   "source": [
    "## 3. 복잡도 분류기 (Complexity Classifier)\n",
    "\n",
    "질문 복잡도를 자동으로 분류하여 적절한 RAG 전략을 선택합니다.\n",
    "\n",
    "### 복잡도 레벨\n",
    "- **simple**: 간단한 사실 질문, 인사 → no-retrieval 또는 경량 검색 (K=2)\n",
    "- **medium**: 단일 주제 질문 → 단일 스텝 검색 + 그레이딩\n",
    "- **complex**: 다단계 추론, 비교/분석 → 반복 검색 + 쿼리 분해 (HyDE/Rewrite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea6c15d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "복잡도 분류 테스트\n",
      "============================================================\n",
      "\n",
      "질문: 안녕하세요\n",
      "   복잡도: simple\n",
      "   라우트: no_retrieval\n",
      "   근거: 인삿말(간단한 인사)에 해당하여 복잡한 답변이나 추가 정보가 필요하지 않음.\n",
      "\n",
      "질문: LangChain이 무엇인가요?\n",
      "   복잡도: simple\n",
      "   라우트: no_retrieval\n",
      "   근거: 이 질문은 'LangChain이 무엇인가요?'라는 단순 사실형 질문으로, 한 문장으로 답변이 가능한 주제에 대한 기초적인 정의를 묻고 있습니다. 복잡한 분석이나 다단계 추론이 필요하지 않습니다.\n",
      "\n",
      "질문: Adaptive RAG와 일반 RAG의 차이점과 각각의 장단점을 비교 분석해주세요.\n",
      "   복잡도: complex\n",
      "   라우트: iterative_retrieval\n",
      "   근거: 이 질문은 'Adaptive RAG'와 '일반 RAG'의 차이점을 비교하고, 각각의 장단점을 분석하라는 요구를 담고 있습니다. 이는 단순 정보 제공을 넘어서 두 개념의 특성과 효과까지 비교/분석해야 하며, 다단계 추론 및 정보 종합이 필요합니다.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 복잡도 분류\n",
    "# ============================================================================\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# 복잡도 분류 출력 스키마\n",
    "class ComplexityClassification(BaseModel):\n",
    "    \"\"\"\n",
    "    질문 복잡도 분류 결과\n",
    "\n",
    "    Attributes:\n",
    "        complexity: 질문 복잡도 레벨\n",
    "            - \"simple\": 간단한 사실 질문, 인사\n",
    "            - \"medium\": 단일 주제 질문\n",
    "            - \"complex\": 다단계 추론, 비교/분석\n",
    "        route: 라우팅 경로 구분\n",
    "            - \"no_retrieval\": 검색 없이 직접 생성\n",
    "            - \"single_retrieval\": 단일 검색 + 그레이딩\n",
    "            - \"iterative_retrieval\": 반복 검색 + 쿼리 분해\n",
    "    \"\"\"\n",
    "\n",
    "    complexity: Literal[\"simple\", \"medium\", \"complex\"] = Field(\n",
    "        description=\"질문 복잡도 레벨 (simple/medium/complex)\"\n",
    "    )\n",
    "    reasoning: str = Field(\n",
    "        description=\"분류 근거 (간단한 설명)\"\n",
    "    )  # 실전에선 절대로 reasoning 출력하지 마세요 -> 토큰 낭비\n",
    "    route: Literal[\"no_retrieval\", \"single_retrieval\", \"iterative_retrieval\"] = Field(\n",
    "        description=\"라우팅 경로 구분 (no_retrieval/single_retrieval/iterative_retrieval)\"\n",
    "    )\n",
    "\n",
    "\n",
    "classifier_llm = create_openrouter_llm(\n",
    "    model=\"openai/gpt-4.1\", temperature=0.0\n",
    ").with_structured_output(ComplexityClassification, method=\"function_calling\")\n",
    "\n",
    "\n",
    "def classify_question(question: str) -> ComplexityClassification:\n",
    "    \"\"\"\n",
    "    질문의 복잡도를 분류하여 적절한 RAG 전략을 선택합니다.\n",
    "\n",
    "    이 함수는 질문의 복잡도를 분석하여 다음 3가지 레벨로 분류합니다:\n",
    "    - simple: 간단한 사실 질문, 인사 → no-retrieval 또는 경량 검색 (K=2)\n",
    "    - medium: 단일 주제 질문 → 단일 스텝 검색 + 그레이딩\n",
    "    - complex: 다단계 추론, 비교/분석 → 반복 검색 + 쿼리 분해 (HyDE/Rewrite)\n",
    "\n",
    "    Args:\n",
    "        question: 사용자 질문 문자열\n",
    "\n",
    "    Returns:\n",
    "        ComplexityClassification: 복잡도 분류 결과 객체\n",
    "            - complexity: 질문 복잡도 레벨 (simple/medium/complex)\n",
    "            - route: 라우팅 경로 (no_retrieval/single_retrieval/iterative_retrieval)\n",
    "\n",
    "    Example:\n",
    "        >>> result = classify_question(\"LangChain이 무엇인가요?\")\n",
    "        >>> print(result.complexity)  # \"medium\"\n",
    "        >>> print(result.route)  # \"single_retrieval\"\n",
    "    \"\"\"\n",
    "    # Classification Prompt\n",
    "    classification_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"You are an expert in analyzing question complexity.\n",
    "\n",
    "    Analyze the question and classify it into one of the following 3 complexity levels:\n",
    "\n",
    "    1. **simple**:\n",
    "    - Greetings, thanks, simple confirmation questions\n",
    "    - Simple factual questions (answerable in one sentence)\n",
    "    - Example: \"Hello\", \"What is LangChain?\", \"What is the weather today?\"\n",
    "    → route: 'no_retrieval' (no retrieval needed) or 'single_retrieval' (lightweight retrieval with K=2)\n",
    "\n",
    "    2. **medium**:\n",
    "    - Requests for explanation on a single topic\n",
    "    - Questions about specific concepts/features\n",
    "    - Example: \"What are the main features of LangChain?\", \"What is Adaptive RAG?\"\n",
    "    → route: 'single_retrieval' (single retrieval + document grading)\n",
    "\n",
    "    3. **complex**:\n",
    "    - Requires multi-step reasoning\n",
    "    - Comparison/analysis/synthesis questions\n",
    "    - Requires deep understanding with \"how\", \"why\"\n",
    "    - Example: \"What are the differences between LangChain and LangGraph?\", \"How do you apply Adaptive RAG in practice?\"\n",
    "    → route: 'iterative_retrieval' (iterative retrieval + query decomposition)\n",
    "\n",
    "    Clearly present the classification criteria and\n",
    "    accurately map the route.\"\"\",\n",
    "            ),\n",
    "            (\"human\", \"Question: {question}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    result: ComplexityClassification = classifier_llm.invoke(\n",
    "        classification_prompt.format(question=question)\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "# 테스트\n",
    "print(\"\\n복잡도 분류 테스트\\n\" + \"=\" * 60)\n",
    "\n",
    "test_questions = [\n",
    "    \"안녕하세요\",\n",
    "    \"LangChain이 무엇인가요?\",\n",
    "    \"Adaptive RAG와 일반 RAG의 차이점과 각각의 장단점을 비교 분석해주세요.\",\n",
    "]\n",
    "\n",
    "for q in test_questions:\n",
    "    print(f\"\\n질문: {q}\")\n",
    "    try:\n",
    "        result = classify_question(q)\n",
    "        print(f\"   복잡도: {result.complexity}\")\n",
    "        print(f\"   라우트: {result.route}\")\n",
    "        print(\n",
    "            f\"   근거: {result.reasoning}\"\n",
    "        )  # 실전에선 절대로 reasoning 출력하지 마세요 -> 토큰 낭비\n",
    "    except Exception as e:\n",
    "        print(f\"   분류 실패: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b79f4b",
   "metadata": {},
   "source": [
    "## 4. 질의 변형 (Query Transformation)\n",
    "\n",
    "검색 정확도 향상을 위한 질의 변형 기법들입니다.\n",
    "\n",
    "### HyDE (Hypothetical Document Embeddings)\n",
    "- 가설 답변을 먼저 생성 → 임베딩 → 검색 시드로 사용\n",
    "- 질문-문서 간 의미적 갭 해소\n",
    " > 근데, 이건 과연 얼마나 의미가 있는지 고민해본적 있으신가요?   \n",
    " > 또, 마찬가지로 얼마나 Latency 가 걸리는지 고민해본적은 있으신지요?\n",
    "\n",
    "### Query Rewrite\n",
    "- 질의를 더 명확하고 구체적으로 재작성\n",
    "- 키워드 추출 및 구조화\n",
    "- 구어체 → 정형화된 표현 변환\n",
    "\n",
    "### Multi-Query Expansion\n",
    "- 하나의 질문을 여러 관점으로 확장\n",
    "- 다양한 각도에서 검색하여 recall 향상\n",
    "- 동의어 활용, 다른 관점/각도, 구체화/일반화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca9a1ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HyDE 테스트\n",
      "============================================================\n",
      "원본 질문: Adaptive RAG는 어떻게 동작하나요?\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2278f210404563b7b31d87107000cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyDE 실패: Unexpected Response: 404 (Not Found)\n",
      "Raw response content:\n",
      "b''\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j_/l84vhzzn61b0tvhmqfzxn2kc0000gn/T/ipykernel_26581/491099288.py:23: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_results = qdrant_client.search(\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 질의 변형: HyDE (Hypothetical Document Embeddings)\n",
    "# ============================================================================\n",
    "\n",
    "from langchain.messages import AIMessage\n",
    "\n",
    "hyde_llm = create_openrouter_llm(model=\"openai/gpt-4.1\", temperature=0.1)\n",
    "\n",
    "\n",
    "def hyde_transform(question: str) -> str:\n",
    "    \"\"\"\n",
    "    HyDE 기법으로 가설 답변을 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        question: 원본 질문\n",
    "\n",
    "    Returns:\n",
    "        가설 답변 (검색 시드로 사용)\n",
    "    \"\"\"\n",
    "    # HyDE Prompt: Generate Hypothetical Answer\n",
    "    hyde_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"You are an expert in generating hypothetical answers to questions.\n",
    "\n",
    "    Write a hypothetical answer (Hypothetical Document) that looks like an actual answer to the given question.\n",
    "    The answer should be specific, detailed, and written like an actual document.\n",
    "\n",
    "    **Important**: It is okay if the answer is not accurate. The goal is to create a semantic seed for retrieval.\"\"\",\n",
    "            ),\n",
    "            (\"human\", \"Question: {question}\\n\\nAnswer:\"),\n",
    "        ]\n",
    "    )\n",
    "    hypothetical_doc: AIMessage = hyde_llm.invoke(hyde_prompt.format(question=question))\n",
    "    return hypothetical_doc.content\n",
    "\n",
    "\n",
    "def search_with_hyde(question: str, top_k: int = 5) -> list[dict]:\n",
    "    \"\"\"\n",
    "    HyDE 기법을 사용하여 문서를 검색합니다.\n",
    "\n",
    "    Args:\n",
    "        question: 원본 질문\n",
    "        top_k: 반환할 문서 수\n",
    "\n",
    "    Returns:\n",
    "        검색 결과 리스트\n",
    "    \"\"\"\n",
    "    # 1. 가설 답변 생성\n",
    "    hyde_doc = hyde_transform(question)\n",
    "\n",
    "    # 2. 가설 답변으로 검색 (질문 대신)\n",
    "    results = search_documents(hyde_doc, top_k=top_k)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# 테스트\n",
    "print(\"\\nHyDE 테스트\\n\" + \"=\" * 60)\n",
    "test_q = \"Adaptive RAG는 어떻게 동작하나요?\"\n",
    "\n",
    "print(f\"원본 질문: {test_q}\\n\")\n",
    "try:\n",
    "    results, hyde_doc = search_with_hyde(test_q, top_k=2)\n",
    "    print(f\"생성된 Hypothetical Answer:\\n{hyde_doc}\\n\")\n",
    "    print(\"HyDE 검색 결과:\")\n",
    "    for i, r in enumerate(results, 1):\n",
    "        print(f\"   {i}. [Score: {r['score']:.3f}] {r['text'][:80]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"HyDE 실패: {e}\")\n",
    "\n",
    "\n",
    "# 아쉽게도 이론적 가설은 완벽할지 모르겠지만, 실전에서 HyDE 기법을 쓸 수는 없습니다.\n",
    "# 1. 너무 느리다, Cost 가 2배로 듭니다.\n",
    "# 2. 너무 부정확하다, 비일관적이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edb37bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query Rewrite 테스트\n",
      "============================================================\n",
      "원본 질문: 그게 뭐야?\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a32645f34064f57b527e7b28389ce39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j_/l84vhzzn61b0tvhmqfzxn2kc0000gn/T/ipykernel_26581/491099288.py:23: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_results = qdrant_client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 실패: Unexpected Response: 404 (Not Found)\n",
      "Raw response content:\n",
      "b''\n",
      "재작성된 질문: Definition of that term\n",
      "추출된 키워드: definition, term\n",
      "재작성 근거: The original question '그게 뭐야?' is informal and vague. It has been rewritten to a more formal expression that clearly asks for the definition of a specific term, emphasizing the core keywords 'definition' and 'term'.\n",
      "\n",
      "검색 결과:\n",
      "\n",
      "============================================================\n",
      "Multi-Query Expansion 테스트\n",
      "============================================================\n",
      "원본 질문: 자기자본비율이 뭐야?\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b31a2c69d934d25a83c89d971ab0616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 실패: Unexpected Response: 404 (Not Found)\n",
      "Raw response content:\n",
      "b''\n",
      "확장된 질문들:\n",
      "  1. 자기자본비율의 정의는 무엇인가요?\n",
      "  2. 자기자본비율이란 무엇인지 설명해 주세요.\n",
      "  3. 자기자본비율이 기업의 재무 건전성에 미치는 영향은 무엇인가요?\n",
      "\n",
      "융합된 검색 결과:\n",
      "\n",
      "============================================================\n",
      "Before/After 비교 (구어체 질문)\n",
      "============================================================\n",
      "\n",
      "[Before (원본)]:\n",
      "  저번에 말했던 그 계약서 있잖아, 거기 뭐라고 써있었지?\n",
      "\n",
      "[After (Query Rewrite)]:\n",
      "  재작성: Contract terms and conditions\n",
      "  키워드: contract, terms, conditions\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 질의 변형: Query Rewrite(Query Construction)\n",
    "# ============================================================================\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# QueryRewriteResult Pydantic 모델\n",
    "class QueryRewriteResult(BaseModel):\n",
    "    \"\"\"Query Rewrite 결과\"\"\"\n",
    "\n",
    "    rewritten_query: str = Field(description=\"재작성된 질문\")\n",
    "    extracted_keywords: list[str] = Field(description=\"추출된 핵심 키워드\")\n",
    "    reasoning: str = Field(description=\"재작성 근거\")\n",
    "\n",
    "\n",
    "def rewrite_query(question: str, llm: ChatOpenAI) -> QueryRewriteResult:\n",
    "    \"\"\"\n",
    "    Query Rewrite: 질문을 검색에 최적화된 형태로 재작성합니다.\n",
    "\n",
    "    Args:\n",
    "        question: 원본 질문\n",
    "        llm: LLM 모델\n",
    "\n",
    "    Returns:\n",
    "        QueryRewriteResult: 재작성된 질문과 키워드\n",
    "    \"\"\"\n",
    "    # Query Rewrite 프롬프트\n",
    "    QUERY_REWRITE_PROMPT = \"\"\"You are a search query optimization expert.\n",
    "    Rewrite the following question into a form more suitable for search:\n",
    "\n",
    "    **Rewriting Principles**:\n",
    "    1. Colloquial → Formal expression\n",
    "    2. Ambiguous terms → Clear keywords\n",
    "    3. Remove unnecessary expressions\n",
    "    4. Emphasize core keywords\n",
    "\n",
    "    **Example**:\n",
    "    Original: \"You know that contract we talked about before, what did it say?\"\n",
    "    Rewritten: \"Contract main clauses content\"\n",
    "    Keywords: [\"contract\", \"clauses\", \"content\"]\n",
    "\n",
    "    **Current Question**: {query}\n",
    "\n",
    "    Rewrite the question above and respond with extracted_keywords and reasoning.\n",
    "    \"\"\"\n",
    "    structured_llm = llm.with_structured_output(QueryRewriteResult)\n",
    "    result: QueryRewriteResult = structured_llm.invoke(QUERY_REWRITE_PROMPT.format(query=question))\n",
    "    return result\n",
    "\n",
    "\n",
    "def search_with_rewrite(\n",
    "    question: str,\n",
    "    llm: ChatOpenAI,\n",
    "    top_k: int = 5,\n",
    ") -> tuple[list[dict], QueryRewriteResult]:\n",
    "    \"\"\"\n",
    "    Query Rewrite를 사용하여 문서를 검색합니다.\n",
    "\n",
    "    Args:\n",
    "        question: 원본 질문\n",
    "        llm: LLM 모델\n",
    "        top_k: 반환할 문서 수\n",
    "\n",
    "    Returns:\n",
    "        tuple: (검색 결과 리스트, QueryRewriteResult)\n",
    "    \"\"\"\n",
    "    # 1. 질의 재작성\n",
    "    rewrite_result = rewrite_query(question, llm)\n",
    "\n",
    "    # 2. 재작성된 질의로 검색\n",
    "    try:\n",
    "        results = search_documents(rewrite_result.rewritten_query, top_k=top_k)\n",
    "    except Exception as e:\n",
    "        print(f\"검색 실패: {e}\")\n",
    "        results = []\n",
    "\n",
    "    return results, rewrite_result\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 질의 변형: Multi-Query Expansion\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "# MultiQueryResult Pydantic 모델\n",
    "class MultiQueryResult(BaseModel):\n",
    "    \"\"\"Multi-Query Expansion 결과\"\"\"\n",
    "\n",
    "    expanded_queries: list[str] = Field(description=\"확장된 질문들\")\n",
    "\n",
    "\n",
    "def expand_query(query: str, llm: ChatOpenAI, num_queries: int = 3) -> MultiQueryResult:\n",
    "    \"\"\"\n",
    "    Multi-Query Expansion: 질문을 여러 관점으로 확장합니다.\n",
    "\n",
    "    Args:\n",
    "        query: 원본 질문\n",
    "        llm: LLM 모델\n",
    "        num_queries: 생성할 질문 개수\n",
    "\n",
    "    Returns:\n",
    "        MultiQueryResult: 확장된 질문들\n",
    "    \"\"\"\n",
    "\n",
    "    # Multi-Query Expansion 프롬프트\n",
    "    MULTI_QUERY_EXPANSION_PROMPT = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"You are a search query expansion expert.\n",
    "    Express the following question in {num_queries} different ways:\n",
    "\n",
    "    **Expansion Principles**:\n",
    "    1. Use synonyms\n",
    "    2. Different perspectives/angles\n",
    "    3. Specify/generalize\n",
    "\n",
    "    **Example**:\n",
    "    Original: \"What is capital adequacy ratio?\"\n",
    "    Expanded:\n",
    "    1. \"What is the definition of capital adequacy ratio?\"\n",
    "    2. \"What is BIS ratio?\"\n",
    "    3. \"Explain capital adequacy ratio among bank financial soundness indicators\"\n",
    "\n",
    "    **Current Question**: {query}\n",
    "\n",
    "    Expand the question above into {num_queries} variations.\n",
    "    \"\"\",\n",
    "            ),\n",
    "            (\n",
    "                \"human\",\n",
    "                \"Question: {query}\\n\\nExpanded Queries:\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    structured_llm = llm.with_structured_output(MultiQueryResult)\n",
    "    result: MultiQueryResult = structured_llm.invoke(\n",
    "        MULTI_QUERY_EXPANSION_PROMPT.format(query=query, num_queries=num_queries)\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "def search_with_multi_query(\n",
    "    question: str,\n",
    "    llm: ChatOpenAI,\n",
    "    top_k: int = 5,\n",
    "    num_queries: int = 3,\n",
    ") -> tuple[list[dict], MultiQueryResult]:\n",
    "    \"\"\"\n",
    "    Multi-Query Expansion을 사용하여 문서를 검색합니다.\n",
    "\n",
    "    Args:\n",
    "        question: 원본 질문\n",
    "        llm: LLM 모델\n",
    "        top_k: 각 쿼리당 반환할 문서 수\n",
    "        num_queries: 생성할 질문 개수\n",
    "\n",
    "    Returns:\n",
    "        tuple: (검색 결과 리스트, MultiQueryResult)\n",
    "    \"\"\"\n",
    "    # 1. 질의 확장\n",
    "    expansion_result = expand_query(question, llm, num_queries=num_queries)\n",
    "\n",
    "    # 2. 각 확장된 질의로 검색 후 결과 융합\n",
    "    try:\n",
    "        all_results = []\n",
    "        seen_texts = set()\n",
    "\n",
    "        for expanded_q in expansion_result.expanded_queries:\n",
    "            results = search_documents(expanded_q, top_k=top_k)\n",
    "            for r in results:\n",
    "                text = r[\"text\"]\n",
    "                if text not in seen_texts:\n",
    "                    all_results.append(r)\n",
    "                    seen_texts.add(text)\n",
    "\n",
    "        # 점수 기준 정렬\n",
    "        all_results.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "    except Exception as e:\n",
    "        print(f\"검색 실패: {e}\")\n",
    "        all_results = []\n",
    "\n",
    "    return all_results[: top_k * num_queries], expansion_result\n",
    "\n",
    "\n",
    "# 테스트\n",
    "print(\"\\nQuery Rewrite 테스트\\n\" + \"=\" * 60)\n",
    "test_q = \"그게 뭐야?\"  # 애매한 질문\n",
    "\n",
    "# LLM 생성 (OpenRouter 헬퍼 사용)\n",
    "test_llm = create_openrouter_llm(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "\n",
    "print(f\"원본 질문: {test_q}\\n\")\n",
    "try:\n",
    "    results, rewrite_result = search_with_rewrite(test_q, test_llm, top_k=2)\n",
    "    print(f\"재작성된 질문: {rewrite_result.rewritten_query}\")\n",
    "    print(f\"추출된 키워드: {', '.join(rewrite_result.extracted_keywords)}\")\n",
    "    print(f\"재작성 근거: {rewrite_result.reasoning}\\n\")\n",
    "    print(\"검색 결과:\")\n",
    "    for i, r in enumerate(results, 1):\n",
    "        print(f\"   {i}. [Score: {r['score']:.3f}] {r['text'][:80]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"Query Rewrite 실패: {e}\")\n",
    "\n",
    "# Multi-Query Expansion 테스트\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Multi-Query Expansion 테스트\\n\" + \"=\" * 60)\n",
    "test_q2 = \"자기자본비율이 뭐야?\"\n",
    "\n",
    "print(f\"원본 질문: {test_q2}\\n\")\n",
    "try:\n",
    "    results, expansion_result = search_with_multi_query(test_q2, test_llm, top_k=2, num_queries=3)\n",
    "    print(\"확장된 질문들:\")\n",
    "    for i, expanded in enumerate(expansion_result.expanded_queries, 1):\n",
    "        print(f\"  {i}. {expanded}\")\n",
    "    print(\"\\n융합된 검색 결과:\")\n",
    "    for i, r in enumerate(results, 1):\n",
    "        print(f\"   {i}. [Score: {r['score']:.3f}] {r['text'][:80]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"Multi-Query Expansion 실패: {e}\")\n",
    "\n",
    "# Before/After 비교 예제\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Before/After 비교 (구어체 질문)\\n\" + \"=\" * 60)\n",
    "colloquial_query = \"저번에 말했던 그 계약서 있잖아, 거기 뭐라고 써있었지?\"\n",
    "\n",
    "print(\"\\n[Before (원본)]:\")\n",
    "print(f\"  {colloquial_query}\")\n",
    "\n",
    "print(\"\\n[After (Query Rewrite)]:\")\n",
    "try:\n",
    "    rewrite_result = rewrite_query(colloquial_query, test_llm)\n",
    "    print(f\"  재작성: {rewrite_result.rewritten_query}\")\n",
    "    print(f\"  키워드: {', '.join(rewrite_result.extracted_keywords)}\")\n",
    "except Exception as e:\n",
    "    print(f\"  실패: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8758d79b",
   "metadata": {},
   "source": [
    "## 5. Grader (Hallucination & Relevance Grading)\n",
    "\n",
    "답변 품질을 검증하고, 필요하다면 문서를 다시 검색하거나 질의를 다시 생성하는 `재시도 전략`을 수립합니다.\n",
    "\n",
    "### Relevance Grader (관련성 그레이더)\n",
    "- 검색된 문서가 질문과 관련이 있는지 판단\n",
    "- 관련 없으면 → 재검색 또는 경로 전환\n",
    "\n",
    "### Hallucination Grader (환각 그레이더)\n",
    "- 생성된 답변이 검색 문서에 근거하는지 검증\n",
    "- 환각 감지 시 → 재생성 또는 \"확인 불가\" 명시\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bab9735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: LangChain의 주요 기능은?\n",
      "\n",
      "[1]  관련 문서 테스트:\n",
      "   관련성: True\n",
      "   근거: The document directly lists the main features of LangChain as prompt management, chain construction, and agent implementation, which addresses the core requirement of asking for its 주요 기능.\n",
      "\n",
      "[2]  무관 문서 테스트:\n",
      "   관련성: False\n",
      "   근거: The document only discusses the weather and makes no mention of LangChain or its features.\n",
      "\n",
      "[3]  환각 검증 테스트:\n",
      "   근거 있는 답변: True (답변의 핵심 주장인 'LangChain의 주요 기능이 프롬프트 관리, 체인 구성, 에이전트 구현'은 문서 1에 명시적으로 모두 언급되어 있습니다.)\n",
      "   환각 답변: False ([INTRINSIC] 문서 1은 LangChain이 프롬프트 관리, 체인 구성, 에이전트 구현을 지원한다고 언급하지만, 블록체인 기술 기반이라는 내용은 없으며 오히려 사실을 왜곡하고 있습니다.)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Grader: Relevance(연관성) & Hallucination(환각)\n",
    "# ============================================================================\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# 연관성 출력 스키마\n",
    "class RelevanceGrade(BaseModel):\n",
    "    \"\"\"\n",
    "    문서 관련성 평가 결과\n",
    "\n",
    "    Attributes:\n",
    "        is_relevant: 문서가 질문과 관련 있는지 여부(bool)\n",
    "            - True: 문서가 질문의 핵심 정보욕구를 충족시키는 근거를 포함\n",
    "            - False: 키워드만 공유하거나 실질적 기여가 없음\n",
    "        reasoning: 판단 근거 설명 (디버깅/로깅용, 실전에서는 생략 가능)\n",
    "    \"\"\"\n",
    "\n",
    "    is_relevant: bool = Field(description=\"문서가 질문과 관련 있는지 (True/False)\")\n",
    "    # 실전에선 절대로 reasoning 출력하지 마세요 -> 토큰 낭비\n",
    "    reasoning: str = Field(description=\"판단 근거 (디버깅/로깅용, 실전에서는 생략 가능)\")\n",
    "\n",
    "\n",
    "grader_llm = create_openrouter_llm(model=\"openai/gpt-4.1\", temperature=0.1)\n",
    "\n",
    "\n",
    "# Hallucination(환각) 2가지\n",
    "# 1) Extrinsic(외재): 문서에 없는 내용을 추가로 단정(지원되지 않음)\n",
    "# 2) Intrinsic(내재): 문서 내용과 모순/왜곡(반하는 서술)\n",
    "# RAG에서는 답이 문서로부터 '지원되거나(증거)' 또는 '논리적으로 함의'되는지(추론 가능성)만 검토합니다.\n",
    "class HallucinationGrade(BaseModel):\n",
    "    \"\"\"\n",
    "    환각 검증 결과\n",
    "\n",
    "    Attributes:\n",
    "        is_grounded: 답변이 문서에 근거하는지 여부\n",
    "            - True: 답변의 핵심 주장들이 문서로부터 직접적으로 지원되거나 함의됨\n",
    "            - False: 문서에 없는 내용을 추가하거나 문서 내용과 모순됨\n",
    "        reasoning: 판단 근거 설명 (디버깅/로깅용, 실전에서는 생략 가능)\n",
    "            - [EXTRINSIC] 또는 [INTRINSIC]으로 환각 유형 표시\n",
    "    \"\"\"\n",
    "\n",
    "    is_grounded: bool = Field(description=\"답변이 문서에 근거하는지 (True/False)\")\n",
    "    # 실전에선 절대로 reasoning 출력하지 마세요 -> 토큰 낭비\n",
    "    reasoning: str = Field(\n",
    "        description=\"판단 근거 (디버깅/로깅용, 실전에서는 생략 가능, [EXTRINSIC]/[INTRINSIC] 유형 표시)\"\n",
    "    )\n",
    "\n",
    "\n",
    "def grade_relevance(question: str, document: str) -> RelevanceGrade:\n",
    "    \"\"\"\n",
    "    문서-질문 관련성을 평가합니다.\n",
    "\n",
    "    이 함수는 RAG 파이프라인의 Document Relevance Grader로,\n",
    "    주어진 질문에 비추어 볼 때 제공된 문서가 답변에 직접 기여할 증거를 제공하는지 이진 판단합니다.\n",
    "\n",
    "    평가 기준:\n",
    "    - 관련성(Relevance): 문서가 질문의 핵심 정보욕구를 충족시키는 근거를 포함하거나 강하게 함의\n",
    "    - 비관련(Irrelevance): 키워드만 공유하거나 실질적 기여가 없음\n",
    "\n",
    "    Args:\n",
    "        question: 사용자 질문 문자열\n",
    "        document: 검색된 문서 텍스트\n",
    "\n",
    "    Returns:\n",
    "        RelevanceGrade: 관련성 평가 결과 객체\n",
    "            - is_relevant: 문서가 질문과 관련 있는지 여부 (True/False)\n",
    "            - reasoning: 판단 근거 설명\n",
    "\n",
    "    Example:\n",
    "        >>> grade = grade_relevance(\n",
    "        ...     \"LangChain의 주요 기능은?\", \"LangChain은 프롬프트 관리, 체인 구성, 에이전트 구현을 지원합니다.\"\n",
    "        ... )\n",
    "        >>> print(grade.is_relevant)  # True\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Relevance Grader ---\n",
    "    relevance_grader_llm = grader_llm.with_structured_output(RelevanceGrade)\n",
    "    relevance_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"You are a Document Relevance Grader for the RAG pipeline.\n",
    "    Make a binary judgment on whether the provided 'document' offers evidence that directly contributes to answering the given 'question'.\n",
    "\n",
    "    [Terms/Criteria]\n",
    "    - Relevance: Does the document contain or strongly entail evidence (facts, definitions, procedures, numbers, citations, etc.) that satisfies the core information need of the question?\n",
    "    - Irrelevance: Only shares keywords, or provides peripheral explanations/promotions/indices without substantial contribution to solving the question, or makes no mention at all.\n",
    "    - Partial Match: Cases that only partially address the core requirement (nugget) are considered irrelevant (False) by default. (Policy to increase precision)\n",
    "    - Prohibition: Do not supplement with external common sense/speculation. If not grounded in the document text, do not consider it relevant.\n",
    "\n",
    "    [Evaluation Procedure]\n",
    "    1) Decompose the core requirements of the question into 1-3 atomic elements (nuggets).\n",
    "    2) Check if there are passages in the document that support each element through 'direct statement' or 'strong entailment'.\n",
    "    - Synonyms/paraphrases/unit conversions are allowed.\n",
    "    - Mere keyword mentions, comprehensive background explanations, or only links/table of contents are not accepted.\n",
    "    3) Final Judgment:\n",
    "    - If the document specifically supports one or more core elements, then is_relevant=true.\n",
    "    - Otherwise, is_relevant=false.\n",
    "\n",
    "    [Output Format (JSON only)]\n",
    "    ```json\n",
    "    {{\n",
    "        \"is_relevant\": true | false,\n",
    "        \"reasoning\": \"Concisely in one or two sentences. Point to document id/short passage and explain why (ir)relevant.\"\n",
    "    }}\n",
    "    ```\n",
    "\n",
    "    [Constraints]\n",
    "    - No text other than JSON.\n",
    "    - Do not infer/expand document content with external knowledge.\"\"\",\n",
    "            ),\n",
    "            (\n",
    "                \"human\",\n",
    "                \"\"\"Question: {question}\n",
    "    ---\n",
    "    Document: {document}\"\"\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    result: RelevanceGrade = relevance_grader_llm.invoke(\n",
    "        relevance_prompt.format(question=question, document=document)\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "def grade_hallucination(documents: list[str], answer: str) -> HallucinationGrade:\n",
    "    \"\"\"\n",
    "    답변의 환각 여부를 검증합니다.\n",
    "\n",
    "    이 함수는 RAG의 Hallucination Grader로,\n",
    "    주어진 문서 조각들만을 사실의 기준으로 삼아,\n",
    "    질의에 대한 모델의 답변이 문서에 의해 충분히 지원되는지(grounded) 판정합니다.\n",
    "\n",
    "    환각 유형:\n",
    "    - Extrinsic(외재 환각): 문서에 없는 내용을 추가로 단정하거나 추론 비약으로 만든 경우\n",
    "    - Intrinsic(내재 환각): 문서 내용과 모순되거나 왜곡/오인용하여 잘못된 사실을 말한 경우\n",
    "    - Grounded: 답변의 핵심 주장들이 문서로부터 직접적으로 지원되거나 명시적으로 함의됨\n",
    "\n",
    "    Args:\n",
    "        documents: 참고 문서 리스트 (문자열 리스트)\n",
    "        answer: 생성된 답변 문자열\n",
    "\n",
    "    Returns:\n",
    "        HallucinationGrade: 환각 검증 결과 객체\n",
    "            - is_grounded: 답변이 문서에 근거하는지 여부 (True/False)\n",
    "            - reasoning: 판단 근거 설명 ([EXTRINSIC]/[INTRINSIC] 유형 표시)\n",
    "\n",
    "    Example:\n",
    "        >>> docs = [\"LangChain은 프롬프트 관리, 체인 구성, 에이전트 구현을 지원합니다.\"]\n",
    "        >>> answer = \"LangChain의 주요 기능은 프롬프트 관리, 체인 구성, 에이전트 구현입니다.\"\n",
    "        >>> grade = grade_hallucination(docs, answer)\n",
    "        >>> print(grade.is_grounded)  # True\n",
    "    \"\"\"\n",
    "    docs_text = \"\\n\\n\".join([f\"[문서 {i + 1}] {doc}\" for i, doc in enumerate(documents)])\n",
    "\n",
    "    # --- Hallucination Grader ---\n",
    "    hallucination_grader_llm = grader_llm.with_structured_output(HallucinationGrade)\n",
    "\n",
    "    hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"You are a Hallucination Grader for RAG.\n",
    "    Using only the given document fragments (context) as the standard of fact, determine whether the model's answer to the question is sufficiently grounded in the documents.\n",
    "\n",
    "    [Term Definitions]\n",
    "    - Extrinsic Hallucination: Cases where content not in the document is asserted or created through inferential leaps (lack of support).\n",
    "    - Intrinsic Hallucination: Cases where incorrect facts are stated by contradicting or distorting/misquoting document content (contradiction).\n",
    "    - Grounded: The core claims of the answer are directly supported by or explicitly entailed from the documents.\n",
    "\n",
    "    [Scoring Procedure]\n",
    "    1) Claim Decomposition: Identify and compress the core claims of the answer into 1-3 items.\n",
    "    2) Evidence Matching: For each claim, find explicit sentences or strongly entailed portions in the document.\n",
    "    - Synonyms/paraphrases/unit conversions/decimal rounding are allowed.\n",
    "    - 문서에 전혀 언급이 없거나 일반상식에만 의존하면 “지원 없음(Extrinsic)”.\n",
    "    - 문서 진술과 상충하면 “모순(Intrinsic)”.\n",
    "    3) Final Judgment:\n",
    "    - If all core claims are supported, then is_grounded=true.\n",
    "    - If even one claim lacks support or contradicts, then is_grounded=false.\n",
    "        - If no support, mark [EXTRINSIC] at the beginning of reasoning; if contradiction, mark [INTRINSIC] (can be omitted if no reasoning).\n",
    "    4) Scope/Strictness:\n",
    "    - 문서 범위를 넘는 일반 지식/상식만으로 맞을 “수도” 있는 주장도 지원이 없으면 False(Extrinsic).\n",
    "    - Partial Correctness: If only some of the core claims are supported, consider it False.\n",
    "    - Minor stylistic, summarization, or organizational differences are allowed, but factual value changes are not.\n",
    "\n",
    "    [Output Format]\n",
    "    - Output JSON only.\n",
    "    - Schema:\n",
    "    ```json\n",
    "    {{\n",
    "        \"is_grounded\": true | false,\n",
    "        \"reasoning\": \"(Can be omitted if no reasoning.) Concisely in one or two sentences. Start with [EXTRINSIC] or [INTRINSIC] to indicate type. Citations include only document id/partial passage.\"\n",
    "    }}\n",
    "    ```\n",
    "\n",
    "    [Constraints]\n",
    "    - No speculation/augmentation outside the document.\n",
    "    - No text other than JSON.\"\"\",\n",
    "            ),\n",
    "            (\n",
    "                \"human\",\n",
    "                \"\"\"Reference Documents:\n",
    "    {documents}\n",
    "\n",
    "    Generated Answer:\n",
    "    {answer}\n",
    "\n",
    "    Is this answer grounded in the reference documents?\"\"\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    result: HallucinationGrade = hallucination_grader_llm.invoke(\n",
    "        hallucination_prompt.format(documents=docs_text, answer=answer)\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "# Relevance 테스트\n",
    "test_question = \"LangChain의 주요 기능은?\"\n",
    "test_doc_relevant = \"LangChain은 프롬프트 관리, 체인 구성, 에이전트 구현을 지원합니다.\"\n",
    "test_doc_irrelevant = \"오늘 날씨는 맑고 화창합니다.\"\n",
    "\n",
    "print(f\"질문: {test_question}\")\n",
    "print(\"\\n[1]  관련 문서 테스트:\")\n",
    "try:\n",
    "    rel_result = grade_relevance(test_question, test_doc_relevant)\n",
    "    print(f\"   관련성: {rel_result.is_relevant}\")\n",
    "    print(f\"   근거: {rel_result.reasoning}\")\n",
    "except Exception as e:\n",
    "    print(f\"   실패: {e}\")\n",
    "\n",
    "print(\"\\n[2]  무관 문서 테스트:\")\n",
    "try:\n",
    "    irrel_result = grade_relevance(test_question, test_doc_irrelevant)\n",
    "    print(f\"   관련성: {irrel_result.is_relevant}\")\n",
    "    print(f\"   근거: {irrel_result.reasoning}\")\n",
    "except Exception as e:\n",
    "    print(f\"   실패: {e}\")\n",
    "\n",
    "# Hallucination 테스트\n",
    "print(\"\\n[3]  환각 검증 테스트:\")\n",
    "docs = [test_doc_relevant]\n",
    "grounded_answer = \"LangChain의 주요 기능은 프롬프트 관리, 체인 구성, 에이전트 구현입니다.\"\n",
    "hallucinated_answer = \"LangChain은 블록체인 기술을 기반으로 합니다.\"\n",
    "\n",
    "try:\n",
    "    hall_result1 = grade_hallucination(docs, grounded_answer)\n",
    "    print(f\"   근거 있는 답변: {hall_result1.is_grounded} ({hall_result1.reasoning})\")\n",
    "\n",
    "    hall_result2 = grade_hallucination(docs, hallucinated_answer)\n",
    "    print(f\"   환각 답변: {hall_result2.is_grounded} ({hall_result2.reasoning})\")\n",
    "except Exception as e:\n",
    "    print(f\"   실패: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e268b2b2",
   "metadata": {},
   "source": [
    "## 6. LangGraph Adaptive RAG 오케스트레이션\n",
    "\n",
    "LangGraph를 사용하여 전체 Adaptive RAG 워크플로우를 구성합니다.\n",
    "\n",
    "### 라우팅 전략 비교\n",
    "\n",
    "#### 1. Prompt 기반 라우팅 (Structured Output) - 현재 구현\n",
    "- **개념**: LLM이 Pydantic 모델로 다음 노드 지정\n",
    "- **장점**: 타입 안전성, 명확한 의도, 일관성\n",
    "- **사용 시기**: 정해진 경로가 있는 경우 (복잡도 기반 라우팅)\n",
    "- **구현**: `ComplexityClassification` 모델로 route 결정\n",
    "\n",
    "#### 2. Tool 기반 라우팅 -> [langgraph-supervisor-py 프로젝트](https://github.com/langchain-ai/langgraph-supervisor-py)\n",
    "- **개념**: LLM이 Tool을 선택하면 해당 Tool/노드로 라우팅\n",
    "- **장점**: LLM의 판단을 활용, 유연한 분기\n",
    "- **사용 시기**: 다양한 액션이 필요한 경우\n",
    "- **구현**: Tool calling으로 노드 선택 >> **SLM 에서는 어려운 방식**\n",
    "\n",
    "#### 3. Default Fallback\n",
    "- **중요성**: 예외 상황에서도 시스템이 멈추지 않도록\n",
    "- **구현**: 항상 default 경로 제공, try-except로 에러 핸들링\n",
    "\n",
    "### 그래프 구조\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    A[START] --> B[classify: 복잡도 분류]\n",
    "    B --> C[route: 라우팅 결정]\n",
    "    C -->|no_retrieval| D[generate_direct]\n",
    "    C -->|single_retrieval| E[retrieve]\n",
    "    C -->|iterative_retrieval| F[transform_query]\n",
    "    E --> G[grade_relevance]\n",
    "    G --> H[generate]\n",
    "    H --> I[grade_hallucination]\n",
    "    F --> J[retrieve]\n",
    "    J --> K[generate]\n",
    "    K --> L[grade_hallucination]\n",
    "    D --> M[finalize: 최종 답변]\n",
    "    I --> M\n",
    "    L --> M\n",
    "```\n",
    "\n",
    "### Default Fallback\n",
    "모든 경로에서 최종 답변을 보장하며, 실패 시 \"확인 불가\" 안내와 함께 종료합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69977982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LangGraph State 정의\n",
    "# ============================================================================\n",
    "\n",
    "import operator\n",
    "from collections.abc import Sequence\n",
    "from typing import Annotated, TypedDict\n",
    "\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "\n",
    "class AdaptiveRAGState(TypedDict):\n",
    "    \"\"\"\n",
    "    Adaptive RAG 그래프 상태\n",
    "\n",
    "    LangGraph Checkpointer를 사용하여 Multi-Turn 대화를 지원합니다.\n",
    "    thread_id를 통해 대화 컨텍스트가 자동으로 관리됩니다.\n",
    "    \"\"\"\n",
    "\n",
    "    # 대화 히스토리 (Checkpointer가 자동 관리)\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "\n",
    "    # 현재 질문\n",
    "    question: str\n",
    "\n",
    "    # 복잡도 분류\n",
    "    complexity: str  # simple/medium/complex\n",
    "    route: str  # no_retrieval/single_retrieval/iterative_retrieval\n",
    "\n",
    "    # 질의 변형\n",
    "    transformed_query: str\n",
    "\n",
    "    # 검색 결과\n",
    "    documents: list[dict]\n",
    "\n",
    "    # 생성\n",
    "    answer: str\n",
    "\n",
    "    # 그레이딩\n",
    "    relevance_passed: bool\n",
    "    hallucination_passed: bool\n",
    "\n",
    "    # 재시도\n",
    "    retry_count: int\n",
    "\n",
    "    # 에러\n",
    "    error: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cac07322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LangGraph 노드 함수들\n",
    "# ============================================================================\n",
    "\n",
    "generator_llm = create_openrouter_llm(model=\"openai/gpt-4.1\", temperature=0.1)\n",
    "\n",
    "\n",
    "# --- 노드 1: 복잡도 분류 ---\n",
    "def classify_node(state: AdaptiveRAGState) -> dict:\n",
    "    \"\"\"질문 복잡도를 분류합니다.\"\"\"\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    classification = classify_question(question)\n",
    "\n",
    "    return {\"complexity\": classification.complexity, \"route\": classification.route}\n",
    "\n",
    "\n",
    "# --- 노드 3: 질의 변형 (complex 경로용) ---\n",
    "def transform_query_node(state: AdaptiveRAGState) -> dict:\n",
    "    \"\"\"\n",
    "    복잡한 질문을 HyDE로 변형합니다.\n",
    "\n",
    "    프로덕션 환경에서 HyDE 사용 시 주의사항:\n",
    "    1. Latency 2배 증가: 가설 답변 생성 + 실제 검색으로 인한 응답 시간 증가\n",
    "       - LLM 호출 1회 추가 → 평균 1-3초 추가 지연\n",
    "    2. Cost 2배 증가: LLM 호출이 한 번 더 발생하여 토큰 비용 증가\n",
    "       - gpt-4o-mini 기준: 입력 토큰 $0.15/1M, 출력 토큰 $0.60/1M\n",
    "       - 평균 200토큰 가설 답변 → 호출당 약 $0.0001-0.0002 추가 비용\n",
    "    3. 불확실성: 가설 답변의 품질이 일관적이지 않을 수 있음\n",
    "       - 도메인 특화 용어의 경우 부정확한 가설 생성 가능\n",
    "       - 검색 정확도 향상 효과가 항상 보장되지 않음\n",
    "\n",
    "    → 실무 권장사항:\n",
    "      - complex 질문에만 선택적 적용 (현재 구현)\n",
    "      - Query Rewrite로 대체하여 비용/속도 최적화\n",
    "      - A/B 테스트로 도메인별 효과 검증 후 적용\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    complexity = state.get(\"complexity\", \"\")\n",
    "\n",
    "    # complex 질문이 아니면 원본 반환\n",
    "    if complexity != \"complex\":\n",
    "        return {\"transformed_query\": question}\n",
    "\n",
    "    # HyDE 프롬프트\n",
    "    prompt = f\"\"\"You are an expert in generating hypothetical answers to questions.\n",
    "\n",
    "Write a hypothetical answer (Hypothetical Document) that looks like an actual answer to the given question.\n",
    "The answer should be specific, detailed, and written like an actual document.\n",
    "\n",
    "**Important**: It is okay if the answer is not accurate. The goal is to create a semantic seed for retrieval.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Hypothetical Answer:\"\"\"\n",
    "\n",
    "    try:\n",
    "        hyde_llm = create_openrouter_llm(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "        response = hyde_llm.invoke(prompt)\n",
    "        transformed = response.content\n",
    "    except Exception as e:\n",
    "        print(f\"HyDE 변형 실패: {e}, 원본 질문 사용\")\n",
    "        transformed = question\n",
    "\n",
    "    return {\"transformed_query\": transformed}\n",
    "\n",
    "\n",
    "# --- 노드 4: 검색 ---\n",
    "def retrieve_node(state: AdaptiveRAGState) -> dict:\n",
    "    \"\"\"문서를 검색합니다.\"\"\"\n",
    "    route = state[\"route\"]\n",
    "    question = state[\"question\"]\n",
    "    transformed = state.get(\"transformed_query\", \"\")\n",
    "\n",
    "    # 검색 쿼리 결정\n",
    "    if route == \"iterative_retrieval\" and transformed:\n",
    "        query = transformed\n",
    "    else:\n",
    "        query = question\n",
    "\n",
    "    # top_k 결정\n",
    "    top_k = 2 if route == \"no_retrieval\" else 5\n",
    "\n",
    "    try:\n",
    "        docs = search_documents(query, top_k=top_k)\n",
    "    except Exception as e:\n",
    "        print(f\"검색 실패: {e}\")\n",
    "        docs = []\n",
    "\n",
    "    return {\"documents\": docs}\n",
    "\n",
    "\n",
    "# --- 노드 5: 관련성 그레이딩 ---\n",
    "def grade_relevance_node(state: AdaptiveRAGState) -> dict:\n",
    "    \"\"\"\n",
    "    검색된 문서의 관련성을 평가합니다.\n",
    "\n",
    "    첫 번째 문서를 기준으로 평가하여, 관련 없는 경우 다른 경로로 fallback합니다.\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    documents = state.get(\"documents\", [])\n",
    "\n",
    "    if not documents:\n",
    "        return {\"relevance_passed\": False}\n",
    "\n",
    "    # 관련성 평가 프롬프트\n",
    "    doc_text = documents[0][\"text\"]\n",
    "\n",
    "    prompt = f\"\"\"You are a Document Relevance Grader for the RAG pipeline.\n",
    "Make a binary judgment on whether the provided document offers evidence that directly contributes to answering the given question.\n",
    "\n",
    "[용어/기준]\n",
    "- Relevance: Does the document contain or strongly entail evidence (facts, definitions, procedures, numbers, citations, etc.) that satisfies the core information need of the question?\n",
    "- Irrelevance: Only shares keywords or provides no substantial contribution.\n",
    "\n",
    "Question: {question}\n",
    "---\n",
    "문서: {doc_text}\n",
    "\n",
    "Is this document relevant to the question?\"\"\"\n",
    "\n",
    "    try:\n",
    "        grader_llm = create_openrouter_llm(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "        structured_llm = grader_llm.with_structured_output(RelevanceGrade, method=\"json_mode\")\n",
    "        result = structured_llm.invoke(prompt)\n",
    "        passed = result.is_relevant\n",
    "    except Exception as e:\n",
    "        print(f\"관련성 평가 실패: {e}\")\n",
    "        passed = False\n",
    "\n",
    "    return {\"relevance_passed\": passed}\n",
    "\n",
    "\n",
    "# --- 노드 6: 답변 생성 (검색 기반) ---\n",
    "def generate_node(state: AdaptiveRAGState) -> dict:\n",
    "    \"\"\"\n",
    "    검색 문서와 대화 히스토리를 기반으로 답변을 생성합니다.\n",
    "\n",
    "    LangGraph Checkpointer가 messages를 자동으로 관리하므로,\n",
    "    이전 대화 맥락을 활용하여 자연스러운 Multi-Turn 대화가 가능합니다.\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    documents = state.get(\"documents\", [])\n",
    "    messages = state.get(\"messages\", [])\n",
    "\n",
    "    # 대화 히스토리 구성 (최근 4턴만)\n",
    "    conversation_history = \"\"\n",
    "    if len(messages) > 0:\n",
    "        recent_messages = messages[-8:]  # 4턴 (각 턴 = user + assistant)\n",
    "        history_parts = []\n",
    "        for msg in recent_messages:\n",
    "            role = \"사용자\" if isinstance(msg, HumanMessage) else \"AI\"\n",
    "            history_parts.append(f\"{role}: {msg.content}\")\n",
    "        conversation_history = \"\\n\".join(history_parts)\n",
    "\n",
    "    # 문서 컨텍스트 구성\n",
    "    if documents:\n",
    "        doc_context = \"\\n\\n\".join([f\"[문서 {i + 1}] {d['text']}\" for i, d in enumerate(documents)])\n",
    "    else:\n",
    "        doc_context = \"(No search results)\"\n",
    "\n",
    "    # 프롬프트 구성\n",
    "    prompt = f\"\"\"The following is the previous conversation:\n",
    "{conversation_history}\n",
    "\n",
    "Reference Documents:\n",
    "{doc_context}\n",
    "\n",
    "현재 Question: {question}\n",
    "\n",
    "Answer the question based on the above information. Respond naturally considering the conversation context.\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = generator_llm.invoke(prompt)\n",
    "        answer = response.content\n",
    "\n",
    "        # messages에 현재 턴 추가\n",
    "        new_messages = [HumanMessage(content=question), AIMessage(content=answer)]\n",
    "    except Exception as e:\n",
    "        answer = f\"Sorry. An error occurred while generating the answer: {str(e)}\"\n",
    "        new_messages = [HumanMessage(content=question), AIMessage(content=answer)]\n",
    "\n",
    "    return {\"answer\": answer, \"messages\": new_messages}\n",
    "\n",
    "\n",
    "# --- 노드 7: 직접 생성 (검색 없이) ---\n",
    "def generate_direct_node(state: AdaptiveRAGState) -> dict:\n",
    "    \"\"\"\n",
    "    검색 없이 직접 답변을 생성합니다 (simple 질문용).\n",
    "\n",
    "    대화 히스토리를 활용하여 컨텍스트를 이해합니다.\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    messages = state.get(\"messages\", [])\n",
    "\n",
    "    # 대화 히스토리 구성\n",
    "    conversation_history = \"\"\n",
    "    if len(messages) > 0:\n",
    "        recent_messages = messages[-8:]\n",
    "        history_parts = []\n",
    "        for msg in recent_messages:\n",
    "            role = \"사용자\" if isinstance(msg, HumanMessage) else \"AI\"\n",
    "            history_parts.append(f\"{role}: {msg.content}\")\n",
    "        conversation_history = \"\\n\".join(history_parts)\n",
    "\n",
    "    prompt = f\"\"\"Previous Conversation:\n",
    "{conversation_history}\n",
    "\n",
    "현재 Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = generator_llm.invoke(prompt)\n",
    "        answer = response.content\n",
    "\n",
    "        new_messages = [HumanMessage(content=question), AIMessage(content=answer)]\n",
    "    except Exception as e:\n",
    "        answer = f\"Failed to generate answer: {str(e)}\"\n",
    "        new_messages = [HumanMessage(content=question), AIMessage(content=answer)]\n",
    "\n",
    "    return {\"answer\": answer, \"messages\": new_messages}\n",
    "\n",
    "\n",
    "# --- 노드 8: 환각 그레이딩 ---\n",
    "def grade_hallucination_node(state: AdaptiveRAGState) -> dict:\n",
    "    \"\"\"\n",
    "    답변의 환각 여부를 검증합니다.\n",
    "\n",
    "    Retry 로직: 환각 감지 시 retry_count를 증가시켜 재시도를 제어합니다.\n",
    "    \"\"\"\n",
    "    documents = state.get(\"documents\", [])\n",
    "    answer = state.get(\"answer\", \"\")\n",
    "    retry_count = state.get(\"retry_count\", 0)\n",
    "\n",
    "    if not documents or not answer:\n",
    "        return {\"hallucination_passed\": True, \"retry_count\": retry_count + 1}\n",
    "\n",
    "    # 환각 검증 프롬프트\n",
    "    docs_text = \"\\n\\n\".join([f\"[문서 {i + 1}] {d['text']}\" for i, d in enumerate(documents)])\n",
    "\n",
    "    prompt = f\"\"\"You are a Hallucination Grader for RAG.\n",
    "Using only the reference documents as the standard of fact, determine whether the answer is sufficiently supported by the documents.\n",
    "\n",
    "[용어 정의]\n",
    "- Extrinsic(외재 환각): 문서에 없는 내용을 추가로 단정하거나 추론 비약으로 만든 경우.\n",
    "- Intrinsic(내재 환각): 문서 내용과 모순되거나 왜곡/오인용하여 잘못된 사실을 말한 경우.\n",
    "- Grounded: 답변의 핵심 주장들이 문서로부터 직접적으로 지원되거나 명시적으로 함의됨.\n",
    "\n",
    "Reference Documents:\n",
    "{docs_text}\n",
    "\n",
    "생성된 Answer:\n",
    "{answer}\n",
    "\n",
    "이 답변은 참고 문서에 근거합니까?\"\"\"\n",
    "\n",
    "    try:\n",
    "        grader_llm = create_openrouter_llm(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "        structured_llm = grader_llm.with_structured_output(HallucinationGrade, method=\"json_mode\")\n",
    "        result = structured_llm.invoke(prompt)\n",
    "        passed = result.is_grounded\n",
    "    except Exception as e:\n",
    "        print(f\"환각 검증 실패: {e}\")\n",
    "        passed = False\n",
    "\n",
    "    return {\n",
    "        \"hallucination_passed\": passed,\n",
    "        \"retry_count\": retry_count + 1 if not passed else retry_count,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e33f276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x11c4cdbe0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LangGraph 라우팅 함수 및 그래프 구성\n",
    "# ============================================================================\n",
    "\n",
    "# --- 라우팅 함수 ---\n",
    "def route_after_classify(state: AdaptiveRAGState) -> str:\n",
    "    \"\"\"복잡도 분류 후 경로를 결정합니다.\"\"\"\n",
    "    route = state[\"route\"]\n",
    "\n",
    "    if route == \"no_retrieval\":\n",
    "        return \"generate_direct\"\n",
    "    elif route == \"single_retrieval\":\n",
    "        return \"retrieve\"\n",
    "    elif route == \"iterative_retrieval\":\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        # Default fallback\n",
    "        return \"generate_direct\"\n",
    "\n",
    "\n",
    "def route_after_relevance(state: AdaptiveRAGState) -> str:\n",
    "    \"\"\"관련성 평가 후 경로를 결정합니다.\"\"\"\n",
    "    passed = state.get(\"relevance_passed\", False)\n",
    "\n",
    "    if passed:\n",
    "        return \"generate\"\n",
    "    else:\n",
    "        # 관련 문서 없음 → 직접 생성으로 대체\n",
    "        return \"generate_direct\"\n",
    "\n",
    "\n",
    "def route_after_hallucination(state: AdaptiveRAGState) -> str:\n",
    "    \"\"\"\n",
    "    환각 검증 후 경로를 결정합니다.\n",
    "\n",
    "    Retry 로직: 환각 감지 시 최대 2회까지 재시도, 이후 현재 답변 반환\n",
    "    \"\"\"\n",
    "    passed = state.get(\"hallucination_passed\", True)\n",
    "    retry_count = state.get(\"retry_count\", 0)\n",
    "\n",
    "    if passed:\n",
    "        return \"end\"\n",
    "    elif retry_count >= 2:\n",
    "        print(f\"WARNING:  재시도 한계 도달 (retry={retry_count}), 현재 답변 반환\")\n",
    "        return \"end\"\n",
    "    else:\n",
    "        print(f\"RETRY: 환각 감지, 재검색 시도 {retry_count}/2\")\n",
    "        return \"retrieve\"\n",
    "\n",
    "\n",
    "# --- 그래프 구성 ---\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "\n",
    "workflow = StateGraph(state_schema=AdaptiveRAGState)\n",
    "\n",
    "# 노드 추가\n",
    "workflow.add_node(\"classify\", classify_node)\n",
    "workflow.add_node(\"transform_query\", transform_query_node)\n",
    "workflow.add_node(\"retrieve\", retrieve_node)\n",
    "workflow.add_node(\"grade_relevance\", grade_relevance_node)\n",
    "workflow.add_node(\"generate\", generate_node)\n",
    "workflow.add_node(\"generate_direct\", generate_direct_node)\n",
    "workflow.add_node(\"grade_hallucination\", grade_hallucination_node)\n",
    "\n",
    "# 엣지 구성\n",
    "workflow.add_edge(START, \"classify\")\n",
    "\n",
    "# classify 직후 조건부 라우팅\n",
    "workflow.add_conditional_edges(\n",
    "    \"classify\",\n",
    "    route_after_classify,\n",
    "    {\n",
    "        \"generate_direct\": \"generate_direct\",\n",
    "        \"retrieve\": \"retrieve\",\n",
    "        \"transform_query\": \"transform_query\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# transform_query 후 retrieve\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
    "\n",
    "# retrieve 후 관련성 평가\n",
    "workflow.add_edge(\"retrieve\", \"grade_relevance\")\n",
    "\n",
    "# grade_relevance → generate or generate_direct\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_relevance\",\n",
    "    route_after_relevance,\n",
    "    {\"generate\": \"generate\", \"generate_direct\": \"generate_direct\"},\n",
    ")\n",
    "\n",
    "# generate 후 환각 검증\n",
    "workflow.add_edge(\"generate\", \"grade_hallucination\")\n",
    "\n",
    "# grade_hallucination → END or retrieve (재시도)\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_hallucination\",\n",
    "    route_after_hallucination,\n",
    "    {\"end\": END, \"retrieve\": \"retrieve\"},\n",
    ")\n",
    "\n",
    "# generate_direct 직접 END\n",
    "workflow.add_edge(\"generate_direct\", END)\n",
    "\n",
    "# Checkpointer 생성 (Multi-Turn 대화 관리)\n",
    "# MemorySaver는 메모리에 체크포인트를 저장하여 대화 상태를 유지합니다.\n",
    "# thread_id를 통해 여러 대화 세션을 독립적으로 관리할 수 있습니다.\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# 그래프 컴파일 (Checkpointer 포함)\n",
    "adaptive_rag_graph = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "# 그래프 시각화\n",
    "adaptive_rag_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261caa45",
   "metadata": {},
   "source": [
    "## 7. 그래프 실행 및 테스트\n",
    "\n",
    "Adaptive RAG 그래프를 실행하고 다양한 복잡도의 질문으로 테스트합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a587ddba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "단일 턴 테스트 (각 질문은 독립적인 세션)\n",
      "================================================================================\n",
      "\n",
      "[질문 1] 안녕하세요!\n",
      "--------------------------------------------------------------------------------\n",
      "복잡도: simple\n",
      "라우트: no_retrieval\n",
      "\n",
      "답변:\n",
      "안녕하세요! 무엇을 도와드릴까요? 궁금한 점이나 필요한 정보가 있으시면 말씀해 주세요. 😊\n",
      "\n",
      "\n",
      "[질문 2] LangChain의 주요 기능은 무엇인가요?\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f79b170dde2e4fc7bfd9680a62023988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j_/l84vhzzn61b0tvhmqfzxn2kc0000gn/T/ipykernel_26581/491099288.py:23: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_results = qdrant_client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 실패: Unexpected Response: 404 (Not Found)\n",
      "Raw response content:\n",
      "b''\n",
      "복잡도: medium\n",
      "라우트: single_retrieval\n",
      "\n",
      "답변:\n",
      "LangChain의 주요 기능은 다음과 같습니다:\n",
      "\n",
      "1. **프롬프트 템플릿 관리**  \n",
      "   다양한 LLM(대형 언어 모델)과 대화할 때 사용할 프롬프트를 쉽고 유연하게 생성, 관리할 수 있습니다.\n",
      "\n",
      "2. **체인(Chains) 구성**  \n",
      "   여러 단계를 연결해 복잡한 작업을 처리할 수 있습니다. 예를 들어 입력 → 요약 → 번역 → 출력처럼 여러 처리 과정을 체인으로 연결할 수 있습니다.\n",
      "\n",
      "3. **에이전트(Agents) 지원**  \n",
      "   외부 도구(예: 계산기, 검색 엔진 등)와 연동해 LLM이 다양한 작업을 수행하도록 돕는 에이전트를 쉽게 만들 수 있습니다.\n",
      "\n",
      "4. **메모리 관리**  \n",
      "   대화 이력(콘텍스트)을 자연스럽게 관리해 LLM 기반 챗봇과 같이 이전 대화 내용을 참고하는 어플리케이션을 만들 수 있게 해줍니다.\n",
      "\n",
      "5. **외부 데이터와의 연동(Retrievers/VectorStores)**  \n",
      "   PDF, 웹페이지, 데이터베이스 등 다양한 외부 문서나 데이터와 연동해 검색·질의·응답(RAG, Retrieval Augmented Generation) 시스템을 손쉽게 구축할 수 있습니다.\n",
      "\n",
      "6. **풍부한 통합 및 확장성**  \n",
      "   OpenAI, HuggingFace, AWS 등 다양한 LLM API 및 데이터 소스와의 통합을 기본적으로 제공합니다.\n",
      "\n",
      "요약하자면, LangChain은 LLM을 활용한 어플리케이션(챗봇, Q&A 시스템 등)을 쉽고 빠르게 개발할 수 있도록 돕는 도구/프레임워크입니다.\n",
      "\n",
      "\n",
      "[질문 3] Adaptive RAG와 일반 RAG를 비교하고, 각각의 장단점을 설명해주세요.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647ba0be2a824b95a7983c7a66a72537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 실패: Unexpected Response: 404 (Not Found)\n",
      "Raw response content:\n",
      "b''\n",
      "복잡도: complex\n",
      "라우트: iterative_retrieval\n",
      "\n",
      "답변:\n",
      "Adaptive RAG와 일반 RAG 비교 및 각각의 장단점\n",
      "\n",
      "**1. 일반 RAG (Retrieval-Augmented Generation)**\n",
      "- **개념:**  \n",
      "  일반 RAG는 사전 구축된 벡터 데이터베이스(예: FAISS, Pinecone 등)에서 쿼리와 가장 유사한 문서를 Top-K 방식으로 검색하여, 이 문서들을 컨텍스트로 활용해 LLM을 통해 답변을 생성합니다. 검색 단계(검색기, retriever)와 생성 단계(생성기, generator)가 분리되어 있지만 고정된 검색 전략(보통 절댓값 Top-K)만 사용합니다.\n",
      "\n",
      "- **장점:**  \n",
      "  - **구현이 단순하고 일관성 있음:** 엔드-투-엔드 파이프라인이 단순해 빠르게 구축 가능  \n",
      "  - **일관된 성능 제공:** 검색기 성능에 따라 예측 가능  \n",
      "  - **확장성:** 벡터 DB, LLM 등 개별 모듈 교체, 확장 용이\n",
      "\n",
      "- **단점:**  \n",
      "  - **비효율적 Context 활용:** 항상 K개의 문서를 고정적으로 사용하므로, 필요 없는 정보가 들어갈 때도 있고 중요한 문서를 누락할 수 있음  \n",
      "  - **Query별 문서품질 편차에 대응 어려움:** 쿼리 난이도, 응답 복잡성에 따라 유연하게 대응하지 못함  \n",
      "  - **Non-Adaptive:** 상황별로 검색 전략이나 컨텍스트 크기/품질을 조정하지 못함\n",
      "\n",
      "---\n",
      "\n",
      "**2. Adaptive RAG**\n",
      "- **개념:**  \n",
      "  Adaptive RAG는 쿼리의 특성, 난이도, 요구되는 답변의 정확성/복잡성 등에 따라 검색 단계나 생성 단계의 전략을 동적으로(Adaptive하게) 조정하는 RAG 확장 모델입니다.  \n",
      "  - 대표적 기법: Adaptive context size(동적 컨텍스트 길이/문서 개수), confidence-based retrieval, multi-stage retrieval, query filtering 등\n",
      "\n",
      "- **장점:**  \n",
      "  - **효율적인 컨텍스트 활용:** 쿼리마다 적합한 문서 수, 길이, 필터링 기준을 조절해 더 적합한 컨텍스트 구성  \n",
      "  - **정확도 개선:** 불필요한 정보는 줄이고, 필요한 정보에 집중 가능  \n",
      "  - **Resource 최적화:** 쉽고 짧은 쿼리는 리소스 적게, 복잡한 쿼리는 더 많이 할당하는 등 비용/성능 균형  \n",
      "  - **탄력적 문제 해결:** 다양한 유형의 쿼리에 따라 자동으로 대응\n",
      "\n",
      "- **단점:**  \n",
      "  - **시스템 복잡성 증가:** 검색 및 생성 전략별 동적 결정로직 추가 필요(모델·룰·피드백 등)  \n",
      "  - **추가 튜닝 및 검증 필요:** Adaptive strategy들이 전체 성능 향상에 항상 이롭지만은 않으며, 쿼리별 편차도 큼  \n",
      "  - **성능 예측 어려움:** 상황별로 동적으로 전략이 달라지므로 일관성 있는 리소스 예측·성능 관리가 어려울 수 있음\n",
      "\n",
      "---\n",
      "\n",
      "**정리(비교표):**\n",
      "\n",
      "| 구분           | 일반 RAG                       | Adaptive RAG                           |\n",
      "|----------------|-------------------------------|----------------------------------------|\n",
      "| 검색 컨텍스트  | 고정(TOP-K)                   | 쿼리별 동적 조정                       |\n",
      "| 정확도         | 평균적(고정된 전략)            | 쿼리에 따라 개선 가능                  |\n",
      "| 효율성         | 필요 없는 정보까지 포함 가능   | 적합한 정보만 포함, 리소스 최적화      |\n",
      "| 복잡도         | 단순                           | 복잡(동적 의사결정 로직 필요)          |\n",
      "| 확장성         | 높음                           | 온전히 설계에 따라 다름                 |\n",
      "| 구현 난이도    | 낮음                           | 높음                                   |\n",
      "\n",
      "---\n",
      "\n",
      "**요약:**  \n",
      "일반 RAG는 단순성과 일관성이 강점인 반면, Adaptive RAG는 쿼리 특성에 맞춘 유연함과 자원 최적화, 높은 정확도가 강점입니다. 그러나 Adaptive RAG는 그만큼 설계와 유지보수 난이도가 높다는 단점도 존재합니다. 서비스 상황, 쿼리의 다양성/복잡성에 따라 적절히 선택하는 것이 중요합니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Adaptive RAG 그래프 실행 함수\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def run_adaptive_rag(question: str, thread_id: str = \"default\", config: dict | None = None) -> dict:\n",
    "    \"\"\"\n",
    "    Adaptive RAG를 실행합니다.\n",
    "\n",
    "    LangGraph Checkpointer를 통해 Multi-Turn 대화를 지원합니다.\n",
    "    동일한 thread_id로 실행하면 이전 대화 컨텍스트가 자동으로 로드됩니다.\n",
    "\n",
    "    Args:\n",
    "        question: 사용자 질문\n",
    "        thread_id: 대화 스레드 ID (Multi-Turn 대화 관리용)\n",
    "            - 동일한 thread_id를 사용하면 이전 대화 맥락이 유지됩니다.\n",
    "            - 다른 thread_id를 사용하면 새로운 대화 세션이 시작됩니다.\n",
    "        config: 추가 설정 (선택)\n",
    "\n",
    "    Returns:\n",
    "        최종 상태 딕셔너리\n",
    "\n",
    "    Example:\n",
    "        >>> # Turn 1\n",
    "        >>> result1 = run_adaptive_rag(\"LangChain이 무엇인가요?\", thread_id=\"session_1\")\n",
    "        >>> # Turn 2 - \"그것\"이 LangChain을 가리킴\n",
    "        >>> result2 = run_adaptive_rag(\"그것의 주요 기능은?\", thread_id=\"session_1\")\n",
    "    \"\"\"\n",
    "    # 초기 상태\n",
    "    initial_state = {\n",
    "        \"question\": question,\n",
    "        \"messages\": [],\n",
    "        \"complexity\": \"\",\n",
    "        \"route\": \"\",\n",
    "        \"transformed_query\": \"\",\n",
    "        \"documents\": [],\n",
    "        \"answer\": \"\",\n",
    "        \"relevance_passed\": False,\n",
    "        \"hallucination_passed\": False,\n",
    "        \"retry_count\": 0,\n",
    "        \"error\": \"\",\n",
    "    }\n",
    "\n",
    "    # Config 구성\n",
    "    if config is None:\n",
    "        config = {}\n",
    "\n",
    "    config[\"configurable\"] = {\"thread_id\": thread_id}\n",
    "\n",
    "    # 그래프 실행 (Checkpointer가 자동으로 이전 상태 로드)\n",
    "    result = adaptive_rag_graph.invoke(initial_state, config=config)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 단일 턴 테스트\n",
    "# ============================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"단일 턴 테스트 (각 질문은 독립적인 세션)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_questions = [\n",
    "    \"안녕하세요!\",\n",
    "    \"LangChain의 주요 기능은 무엇인가요?\",\n",
    "    \"Adaptive RAG와 일반 RAG를 비교하고, 각각의 장단점을 설명해주세요.\",\n",
    "]\n",
    "\n",
    "for i, q in enumerate(test_questions, 1):\n",
    "    print(f\"\\n[질문 {i}] {q}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    try:\n",
    "        # 각 질문마다 다른 thread_id 사용 (독립적인 세션)\n",
    "        result = run_adaptive_rag(q, thread_id=f\"test_{i}\")\n",
    "\n",
    "        print(f\"복잡도: {result.get('complexity', 'N/A')}\")\n",
    "        print(f\"라우트: {result.get('route', 'N/A')}\")\n",
    "\n",
    "        if result.get(\"documents\"):\n",
    "            print(f\"검색 문서: {len(result['documents'])}개\")\n",
    "\n",
    "        print(f\"\\n답변:\\n{result.get('answer', 'N/A')}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"실행 실패: {e}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4eac7e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Multi-Turn 대화 테스트 (동일 thread_id로 연속 질문)\n",
      "================================================================================\n",
      "\n",
      "[Turn 1]\n",
      "--------------------------------------------------------------------------------\n",
      "질문: LangChain이 무엇인가요?\n",
      "복잡도: simple\n",
      "라우트: no_retrieval\n",
      "\n",
      "답변:\n",
      "LangChain은 **언어 모델(LLM, Large Language Model, 예: OpenAI의 GPT 시리즈 등)**을 활용하여 다양한 애플리케이션을 개발할 수 있도록 지원하는 파이썬 기반 오픈소스 프레임워크입니다. LangChain의 주요 목적은 LLM의 강력한 능력을 실제 업무, 애플리케이션, 서비스와 쉽게 연결할 수 있도록 돕는 것입니다.\n",
      "\n",
      "### LangChain의 주요 특징\n",
      "\n",
      "1. **체인(Chain) 구조**  \n",
      "   LangChain은 여러 LLM 호출, 툴 사용, 데이터 처리 단계를 유연하게 이어 붙일 수 있도록 체인 형태로 구성할 수 있습니다.\n",
      "\n",
      "2. **에이전트(Agent) 지원**  \n",
      "   단순히 프롬프트만 넘기는 것이 아니라, LLM이 다양한 외부 툴(검색 엔진, 계산기, 데이터베이스 등)에 접근해 스스로 행동을 선택하도록 할 수 있습니다.\n",
      "\n",
      "3. **다양한 데이터 소스와의 연동**  \n",
      "   텍스트, 데이터베이스, 문서 등 다양한 데이터 소스와 쉽게 통합되어 LLM 기반 질문 응답, 챗봇, 검색 등의 개발에 활용할 수 있습니다.\n",
      "\n",
      "4. **프롬프트 관리 및 템플릿**  \n",
      "   프롬프트(질의 내용)의 구성과 버전을 효율적으로 관리할 수 있습니다.\n",
      "\n",
      "### 쉽게 말해,\n",
      "\n",
      "- LangChain은 LLM을 현업 서비스에 접목하고자 할 때, 프롬프트 설계, 툴 연동, 응답 처리 등 복잡한 작업을 간편하게 설계할 수 있도록 도와주는 도구입니다.\n",
      "- 예를 들어 \"PDF를 읽고 질문에 답하는 챗봇 만들기\", \"사내 DB와 연동된 AI 비서 만들기\" 같은 프로젝트를 쉽고 빠르게 구축할 수 있도록 해줍니다.\n",
      "\n",
      "### 참고자료\n",
      "\n",
      "- LangChain 공식 홈페이지: [https://www.langchain.com/](https://www.langchain.com/)\n",
      "- LangChain 문서: [https://python.langchain.com/](https://python.langchain.com/)\n",
      "\n",
      "궁금한 점이 있다면 더 구체적으로 질문해주세요!\n",
      "\n",
      "\n",
      "[Turn 2]\n",
      "--------------------------------------------------------------------------------\n",
      "질문: 그것의 주요 기능은 뭐야?\n",
      "(이전 대화에서 '그것'이 LangChain을 가리킴)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88649d19d9845fdac1c9f91524b6ac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j_/l84vhzzn61b0tvhmqfzxn2kc0000gn/T/ipykernel_26581/491099288.py:23: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_results = qdrant_client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 실패: Unexpected Response: 404 (Not Found)\n",
      "Raw response content:\n",
      "b''\n",
      "복잡도: medium\n",
      "라우트: single_retrieval\n",
      "\n",
      "답변:\n",
      "LangChain의 주요 기능은 다음과 같습니다:\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **체인(Chain) 구성**\n",
      "- 여러 단계의 작업(프롬프트 생성, LLM 호출, 결과 가공 등)을 순차적으로 묶어서 처리할 수 있습니다.\n",
      "- 예: 질문 → LLM에 전달 → 결과 요약 → 사용자에게 전달\n",
      "\n",
      "### 2. **에이전트(Agent)**\n",
      "- LLM이 다양한 외부 도구(검색, 계산, 데이터베이스 질의 등)를 스스로 선택하고 실행할 수 있는 \"에이전트\" 구조를 지원합니다.\n",
      "- 이로써, 단순 프롬프트 답변뿐만 아니라, 외부 작업을 수행할 수 있습니다.\n",
      "\n",
      "### 3. **프롬프트 템플릿 관리**\n",
      "- 프롬프트(LLM에 전달할 입력 내용)를 템플릿으로 관리하여, 다양한 입력 상황에 맞게 쉽게 적용할 수 있습니다.\n",
      "- 반복적인 프롬프트 작성의 번거로움을 줄여줍니다.\n",
      "\n",
      "### 4. **메모리(Memory) 지원**\n",
      "- 이전 대화나 작업 맥락을 기억하고 활용할 수 있게 해줍니다.\n",
      "- 챗봇 같은 지속적 대화 시스템에 매우 유용합니다.\n",
      "\n",
      "### 5. **외부 데이터 연동**\n",
      "- 데이터베이스, PDF, 웹사이트, 엑셀 등 다양한 데이터 소스를 연결해 자연어로 조회, 검색, 요약 작업을 할 수 있습니다.\n",
      "\n",
      "### 6. **Tool 및 플러그인 통합**\n",
      "- 계산, 검색, API 호출 등 다양한 툴을 손쉽게 연결하여 LLM이 풍부한 기능을 발휘할 수 있도록 도와줍니다.\n",
      "\n",
      "### 7. **워크플로우 설계**\n",
      "- 복잡한 작업을 여러 단계로 나눠 체계적으로 처리하는 워크플로우를 쉽게 만들 수 있습니다.\n",
      "\n",
      "---\n",
      "\n",
      "**요약해서:**  \n",
      "LangChain은 LLM을 중심으로 데이터 연결, 툴 통합, 대화 흐름 관리, 자동 워크플로우 설계 등을 지원해, 실무에서 다양한 AI 서비스 및 챗봇, 자동화 도구를 쉽고 빠르게 구축할 수 있게 해주는 라이브러리입니다.\n",
      "\n",
      "궁금한 부분이 더 있으면 추가로 질문해 주세요!\n",
      "\n",
      "\n",
      "[Turn 3]\n",
      "--------------------------------------------------------------------------------\n",
      "질문: Adaptive RAG와 비교해서 설명해줘\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f5bc63ceb144699da4f2197fcb1bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 실패: Unexpected Response: 404 (Not Found)\n",
      "Raw response content:\n",
      "b''\n",
      "복잡도: complex\n",
      "라우트: iterative_retrieval\n",
      "\n",
      "답변:\n",
      "네! **LangChain**과 **Adaptive RAG(Adaptive Retrieval-Augmented Generation)**의 차이를 설명하자면, 두 기술이 목표는 비슷할 수 있어도 접근 방식, 구조, 활용 방향에서 차이가 있습니다. 아래에서 각각이 무엇인지와, **LangChain vs. Adaptive RAG**의 비교 포인트를 설명해 드릴게요.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. **LangChain이란?**\n",
      "- **정의:** LLM(대형언어모델)을 실제 서비스에 활용할 때 필요한 도구/컴포넌트/단계를 연결해주는 파이프라인 및 프레임워크 (즉, 애플리케이션 개발 프레임워크)\n",
      "- **포커스:** 프롬프트 설계, 데이터 소스 연결, 도구 통합, 체인 및 에이전트 구성 등 다양한 AI 워크플로우** \"설계와 실행\" **에 중점\n",
      "- **주요 역할:** LLM 기반 애플리케이션 구성과 통합\n",
      "\n",
      "---\n",
      "\n",
      "## 2. **Adaptive RAG (Adaptive Retrieval-Augmented Generation)란?**\n",
      "- **정의:** RAG는 Retrieval-Augmented Generation의 약자\n",
      "    - **RAG:** 외부 지식(문서, DB 등)을 LLM 답변에 \"첨가\"하는 구조(예: ChatGPT의 웹 검색, PDF 검색 기반 답변 등)\n",
      "    - **Adaptive RAG:** 한 발 더 나아가, 사용자의 질문, 상황, 맥락에 따라 \"가장 적합한 검색/추론 전략\"을 **동적으로** 선택하고 적응(adaptive)하는 RAG 방식\n",
      "      - (예: 쉬운 질문은 단순검색, 어려운 질문은 추가로 세부 쿼리/파인튜닝/Post-processing 등 적용)\n",
      "- **포커스:** LLM이 정보 검색 + 추론에 필요한 최적 방식을 **적응적으로 고르고 동적으로 적용**하는 것\n",
      "\n",
      "---\n",
      "\n",
      "# **비교 요약**\n",
      "\n",
      "| 구분 | LangChain | Adaptive RAG |\n",
      "|-----|-----------|--------------|\n",
      "| **정체성** | LLM 앱 개발 프레임워크 | LLM 검색-생성 구조의 진화된 방식 |\n",
      "| **주요 역할** | 애플리케이션 워크플로우 설계/통합/자동화 | 사용자의 목적·질문·문맥에 따라 최적 검색·생성 방식 적응적으로 선택 |\n",
      "| **초점** | 체인, 에이전트, 데이터 연결 등 플로우 설계 | RAG 구조를 더 똑똑하게(동적 적응 검색/생성) 만드는 것 |\n",
      "| **적용 예시** | 챗봇, 자동화툴, 문서검색 등 다양한 LLM 앱 | 맞춤형 FAQ, 복잡한 질의응답, 개인 맞춤형 정보 제공 등 |\n",
      "| **의존성** | LLM+다양한 툴(or RAG도 연결 가능) | 주로 RAG 구조(검색+LLM) |\n",
      "\n",
      "---\n",
      "\n",
      "## **쉽게 설명하면**\n",
      "- **LangChain**은 \"여러 단계를 손쉽게 연결해주는 설계도/프레임워크\"  \n",
      "  → 여기서 RAG 자체도 langchain의 하나의 체인/에이전트로 포함(구현) 가능\n",
      "\n",
      "- **Adaptive RAG**는 기존 RAG 구조(검색+생성)를 더 스마트하게/상황 맞춤으로** \"진화\" **시킨 답변 방식  \n",
      "  → 워크플로우 자체라기보단, 답변 생성 전략의 고도화임\n",
      "\n",
      "---\n",
      "\n",
      "## **관계성**\n",
      "- 둘은 서로 대체관계보다** \"보완\" **관계입니다.\n",
      "    - LangChain 안에 adaptive RAG 구조를 구현하여 활용할 수도 있습니다.\n",
      "    - Adaptive RAG 구조가 필요하다면, LangChain에서 전체 플로우의 일부로 연결할 수 있음\n",
      "\n",
      "---\n",
      "\n",
      "**정리**\n",
      "- LangChain은 애플리케이션 설계 프레임워크(How to connect everything)\n",
      "- Adaptive RAG는 LLM의 \"더 똑똑한 검색+생성 답변\" 방식(How to better answer with retrieval+generation)\n",
      "- LangChain은 Adaptive RAG를 포함하거나, 도구로 쓸 수 있음\n",
      "\n",
      "추가 설명이 필요하면 예시 코드 or 구체적 사례도 말씀해 주세요!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "새로운 대화 세션 (다른 thread_id)\n",
      "================================================================================\n",
      "\n",
      "[New Thread - Turn 1]\n",
      "--------------------------------------------------------------------------------\n",
      "질문: 그것의 주요 기능은 뭐야?\n",
      "(새로운 세션이므로 '그것'이 무엇인지 모름)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "847324e858874f00882ad16fe36d4ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 실패: Unexpected Response: 404 (Not Found)\n",
      "Raw response content:\n",
      "b''\n",
      "복잡도: medium\n",
      "라우트: single_retrieval\n",
      "\n",
      "답변:\n",
      "물어보신 \"그것\"이 정확히 무엇을 가리키는지 현재 대화 내용만으로는 알 수 없습니다. 이전 대화 내역을 제공해주시면, 더 정확하게 해당 기능에 대해 답변드릴 수 있습니다.  \n",
      "만약 특정 제품, 앱, 서비스, 소프트웨어, 기기 등 무엇을 말씀하시는 건지 알려주시면, 그에 맞는 주요 기능을 자세히 안내해드릴 수 있습니다!\n",
      "\n",
      "================================================================================\n",
      "COMPLETED: Multi-Turn 대화 테스트 완료!\n",
      "동일 thread_id: 이전 대화 컨텍스트 유지됨\n",
      "다른 thread_id: 새로운 대화 세션으로 시작됨\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Multi-Turn 대화 테스트\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Multi-Turn 대화 테스트 (동일 thread_id로 연속 질문)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "thread_id = \"conversation_1\"\n",
    "\n",
    "# Turn 1: 초기 질문\n",
    "print(\"\\n[Turn 1]\")\n",
    "print(\"-\" * 80)\n",
    "q1 = \"LangChain이 무엇인가요?\"\n",
    "print(f\"질문: {q1}\")\n",
    "\n",
    "try:\n",
    "    result1 = run_adaptive_rag(q1, thread_id=thread_id)\n",
    "    print(f\"복잡도: {result1.get('complexity', 'N/A')}\")\n",
    "    print(f\"라우트: {result1.get('route', 'N/A')}\")\n",
    "    print(f\"\\n답변:\\n{result1.get('answer', 'N/A')}\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"실행 실패: {e}\\n\")\n",
    "\n",
    "# Turn 2: 이전 대화 컨텍스트 참조\n",
    "print(\"\\n[Turn 2]\")\n",
    "print(\"-\" * 80)\n",
    "q2 = \"그것의 주요 기능은 뭐야?\"  # \"그것\" = LangChain (이전 대화 참조)\n",
    "print(f\"질문: {q2}\")\n",
    "print(\"(이전 대화에서 '그것'이 LangChain을 가리킴)\")\n",
    "\n",
    "try:\n",
    "    result2 = run_adaptive_rag(q2, thread_id=thread_id)\n",
    "    print(f\"복잡도: {result2.get('complexity', 'N/A')}\")\n",
    "    print(f\"라우트: {result2.get('route', 'N/A')}\")\n",
    "    print(f\"\\n답변:\\n{result2.get('answer', 'N/A')}\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"실행 실패: {e}\\n\")\n",
    "\n",
    "# Turn 3: 추가 질문\n",
    "print(\"\\n[Turn 3]\")\n",
    "print(\"-\" * 80)\n",
    "q3 = \"Adaptive RAG와 비교해서 설명해줘\"\n",
    "print(f\"질문: {q3}\")\n",
    "\n",
    "try:\n",
    "    result3 = run_adaptive_rag(q3, thread_id=thread_id)\n",
    "    print(f\"복잡도: {result3.get('complexity', 'N/A')}\")\n",
    "    print(f\"라우트: {result3.get('route', 'N/A')}\")\n",
    "    print(f\"\\n답변:\\n{result3.get('answer', 'N/A')}\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"실행 실패: {e}\\n\")\n",
    "\n",
    "# 새로운 대화 세션 (다른 thread_id)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"새로운 대화 세션 (다른 thread_id)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "thread_id_2 = \"conversation_2\"\n",
    "\n",
    "print(\"\\n[New Thread - Turn 1]\")\n",
    "print(\"-\" * 80)\n",
    "q4 = \"그것의 주요 기능은 뭐야?\"  # 컨텍스트 없어서 \"그것\"을 모름\n",
    "print(f\"질문: {q4}\")\n",
    "print(\"(새로운 세션이므로 '그것'이 무엇인지 모름)\")\n",
    "\n",
    "try:\n",
    "    result4 = run_adaptive_rag(q4, thread_id=thread_id_2)\n",
    "    print(f\"복잡도: {result4.get('complexity', 'N/A')}\")\n",
    "    print(f\"라우트: {result4.get('route', 'N/A')}\")\n",
    "    print(f\"\\n답변:\\n{result4.get('answer', 'N/A')}\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"실행 실패: {e}\\n\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPLETED: Multi-Turn 대화 테스트 완료!\")\n",
    "print(\"동일 thread_id: 이전 대화 컨텍스트 유지됨\")\n",
    "print(\"다른 thread_id: 새로운 대화 세션으로 시작됨\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eb9466",
   "metadata": {},
   "source": [
    "## Adaptive RAG 구현 항목\n",
    "\n",
    "1. **복잡도 분류기**: LLM 기반 질문 복잡도 분류 노드 (simple/medium/complex)\n",
    "2. **질의 변형**: HyDE (complex 질문 전용) - 프로덕션 환경 고려사항 포함\n",
    "3. **그레이더**: 관련성 및 환각 검증으로 답변 품질 보장\n",
    "4. **LangGraph 오케스트레이션**: 복잡도 기반 동적 라우팅 및 default fallback\n",
    "5. **Multi-Turn 대화**: LangGraph Checkpointer 기반 대화 컨텍스트 관리\n",
    "\n",
    "### 주요 특징\n",
    "\n",
    "- **Adaptive 전략**: 질문 복잡도에 따라 no-retrieval/single/iterative 자동 선택\n",
    "- **품질 보장**: 관련성/환각 그레이딩으로 신뢰도 높은 답변 생성\n",
    "- **Fallback**: 모든 경로에서 최종 답변 보장\n",
    "- **Multi-Turn**: thread_id 기반 대화 히스토리 자동 관리\n",
    "\n",
    "### 고려사항\n",
    "\n",
    "#### HyDE 사용 시 주의점\n",
    "- **Latency 2배**: LLM 호출 1회 추가\n",
    "- **Cost 2배**: 토큰 비용 증가\n",
    "- **불확실성**: 가설 답변 품질 일관성 문제\n",
    "- **권장**: complex 질문에만 선택적 적용 또는 Query Rewrite로 대체(왠만해선 굳이 안쓰는게 좋습니다)\n",
    "\n",
    "#### Checkpointer vs Long-Term Memory\n",
    "- **Checkpointer (현재 구현)**: Thread 단위 Short-Term Memory\n",
    "  - 장점: 구현 단순, LangGraph 네이티브 지원\n",
    "  - 단점: 스레드 간 정보 공유 불가\n",
    "- **Long-Term Memory (선택적)**: 사용자 단위 크로스-스레드 메모리\n",
    "  - 사용 시기: 사용자 선호도, 지식 누적이 필요한 경우\n",
    "  - 구현 방법: `LangGraph Store(LangMem)` 또는 `Mem0`\n",
    "\n",
    "### 개선 방향\n",
    "\n",
    "1. **Hybrid 검색**: BM25 + Dense retrieval 결합으로 검색 정확도 향상\n",
    "2. **Long-Term Memory**: LangGraph Store 통합으로 크로스-스레드 지식 관리\n",
    "3. **평가 자동화**: LangSmith/RAGAS 통합으로 지속적 성능 모니터링\n",
    "4. **프로덕션 최적화**: \n",
    "   - 캐싱: 반복 질문 응답 시간 단축\n",
    "   - 배치 처리: 다중 질문 동시 처리\n",
    "   - 비동기 실행: asyncio 기반 성능 향상\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
