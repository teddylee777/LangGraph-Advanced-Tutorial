{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 04: Agentic RAG & RAG Evaluation(RAGAS)\n",
    "\n",
    "1. LangGraph Agent를 활용한 Agentic RAG를 구현할 수 있습니다\n",
    "2. RAGAS 4대 지표 (Context Precision, Recall, Faithfulness, Relevancy)를 이해합니다\n",
    "3. Tool 통합 및 디버깅 베스트 프랙티스를 적용할 수 있습니다\n",
    "4. RAG 파이프라인의 품질을 정량적으로 평가할 수 있습니다\n",
    "\n",
    "## 참조 문서\n",
    "- [LangGraph Custom RAG Agent](https://docs.langchain.com/oss/python/langgraph/agentic-rag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5571779e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1c5433",
   "metadata": {},
   "source": [
    "## 평가 프레임워크 클래스 정의\n",
    "\n",
    "RAGAS 평가, 자동 개선, 데이터셋 구축에 필요한 모든 클래스를 정의합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1908264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 1. 기본 Enum 및 상수 정의\n",
    "# ============================================================================\n",
    "\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from typing import Any, Literal\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 질문 타입 및 난이도\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "class QuestionType(str, Enum):\n",
    "    \"\"\"질문 유형 분류\"\"\"\n",
    "\n",
    "    FACTUAL = \"factual\"  # 단순 사실 확인\n",
    "    REASONING = \"reasoning\"  # 추론 필요\n",
    "    COMPARISON = \"comparison\"  # 비교/대조\n",
    "    CALCULATION = \"calculation\"  # 계산 필요\n",
    "    AGGREGATION = \"aggregation\"  # 여러 정보 종합\n",
    "\n",
    "\n",
    "class DifficultyLevel(str, Enum):\n",
    "    \"\"\"난이도 레벨\"\"\"\n",
    "\n",
    "    SIMPLE = \"simple\"  # 단일 문서 내 직접 답변 가능\n",
    "    MEDIUM = \"medium\"  # 2-3개 문서 조합 필요\n",
    "    COMPLEX = \"complex\"  # 4개 이상 문서 + 복잡한 추론\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# RAGAS 관련 Enum\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "class RAGASMetric(str, Enum):\n",
    "    \"\"\"RAGAS 지표 이름\"\"\"\n",
    "\n",
    "    CONTEXT_PRECISION = \"context_precision\"\n",
    "    CONTEXT_RECALL = \"context_recall\"\n",
    "    FAITHFULNESS = \"faithfulness\"\n",
    "    ANSWER_RELEVANCY = \"answer_relevancy\"\n",
    "\n",
    "\n",
    "class RAGNode(str, Enum):\n",
    "    \"\"\"RAG 파이프라인의 주요 노드\"\"\"\n",
    "\n",
    "    QUERY_TRANSFORM = \"query_transform\"  # 쿼리 변환/확장\n",
    "    RETRIEVAL = \"retrieval\"  # 검색\n",
    "    RERANKING = \"reranking\"  # 재랭킹\n",
    "    GENERATION = \"generation\"  # 답변 생성\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 개선 액션 관련 Enum\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "class ActionType(str, Enum):\n",
    "    \"\"\"개선 액션 유형\"\"\"\n",
    "\n",
    "    INCREASE_TOP_K = \"increase_top_k\"\n",
    "    DECREASE_TOP_K = \"decrease_top_k\"\n",
    "    CHANGE_RERANKER = \"change_reranker\"\n",
    "    INCREASE_CHUNK_OVERLAP = \"increase_chunk_overlap\"\n",
    "    ADD_QUERY_EXPANSION = \"add_query_expansion\"\n",
    "    CHANGE_EMBEDDING_MODEL = \"change_embedding_model\"\n",
    "    STRENGTHEN_PROMPT = \"strengthen_prompt\"\n",
    "    REDUCE_TEMPERATURE = \"reduce_temperature\"\n",
    "    DISABLE_CONTEXT_COMPRESSION = \"disable_context_compression\"\n",
    "    ADD_FEW_SHOT = \"add_few_shot\"\n",
    "    ADD_HYDE = \"add_hyde\"\n",
    "    IMPROVE_QUERY_REWRITE = \"improve_query_rewrite\"\n",
    "\n",
    "\n",
    "class ActionPriority(str, Enum):\n",
    "    \"\"\"개선 우선순위\"\"\"\n",
    "\n",
    "    CRITICAL = \"critical\"  # 즉시 개선 필수\n",
    "    HIGH = \"high\"  # 높은 우선순위\n",
    "    MEDIUM = \"medium\"  # 중간 우선순위\n",
    "    LOW = \"low\"  # 낮은 우선순위"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb19a65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 2. 평가 데이터 모델 정의\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "class EvaluationQuestion(BaseModel):\n",
    "    \"\"\"평가용 질문 단위\"\"\"\n",
    "\n",
    "    id: str = Field(description=\"질문 고유 ID\")\n",
    "    question: str = Field(description=\"사용자 질문\")\n",
    "    question_type: QuestionType = Field(description=\"질문 유형\")\n",
    "    difficulty: DifficultyLevel = Field(description=\"난이도\")\n",
    "    ground_truth: str = Field(description=\"정답\")\n",
    "    relevant_doc_ids: list[str] = Field(default_factory=list, description=\"관련 문서 ID\")\n",
    "    metadata: dict[str, Any] = Field(default_factory=dict, description=\"추가 메타데이터\")\n",
    "\n",
    "\n",
    "class EvaluationDataset(BaseModel):\n",
    "    \"\"\"평가 데이터셋 전체 구조\"\"\"\n",
    "\n",
    "    name: str = Field(description=\"데이터셋 이름\")\n",
    "    description: str = Field(description=\"데이터셋 설명\")\n",
    "    version: str = Field(default=\"1.0.0\")\n",
    "    questions: list[EvaluationQuestion] = Field(default_factory=list)\n",
    "    metadata: dict[str, Any] = Field(default_factory=dict)\n",
    "\n",
    "    def get_questions_by_type(self, question_type: QuestionType) -> list[EvaluationQuestion]:\n",
    "        return [q for q in self.questions if q.question_type == question_type]\n",
    "\n",
    "    def get_questions_by_difficulty(self, difficulty: DifficultyLevel) -> list[EvaluationQuestion]:\n",
    "        return [q for q in self.questions if q.difficulty == difficulty]\n",
    "\n",
    "\n",
    "class RAGASScore(BaseModel):\n",
    "    \"\"\"단일 질문에 대한 RAGAS 점수\"\"\"\n",
    "\n",
    "    question_id: str\n",
    "    question: str\n",
    "\n",
    "    # 4대 지표\n",
    "    context_precision: float = Field(ge=0.0, le=1.0)\n",
    "    context_recall: float = Field(ge=0.0, le=1.0)\n",
    "    faithfulness: float = Field(ge=0.0, le=1.0)\n",
    "    answer_relevancy: float = Field(ge=0.0, le=1.0)\n",
    "\n",
    "    # 추가 정보\n",
    "    answer: str = Field(description=\"생성된 답변\")\n",
    "    contexts: list[str] = Field(description=\"검색된 컨텍스트\")\n",
    "    ground_truth: str = Field(description=\"정답\")\n",
    "\n",
    "    # 성능 메트릭\n",
    "    retrieval_time_ms: float = 0.0\n",
    "    generation_time_ms: float = 0.0\n",
    "    total_time_ms: float = 0.0\n",
    "\n",
    "    def get_average_score(self) -> float:\n",
    "        return (\n",
    "            self.context_precision + self.context_recall + self.faithfulness + self.answer_relevancy\n",
    "        ) / 4.0\n",
    "\n",
    "    def get_worst_metric(self) -> tuple[RAGASMetric, float]:\n",
    "        scores = {\n",
    "            RAGASMetric.CONTEXT_PRECISION: self.context_precision,\n",
    "            RAGASMetric.CONTEXT_RECALL: self.context_recall,\n",
    "            RAGASMetric.FAITHFULNESS: self.faithfulness,\n",
    "            RAGASMetric.ANSWER_RELEVANCY: self.answer_relevancy,\n",
    "        }\n",
    "        worst_metric = min(scores, key=scores.get)\n",
    "        return worst_metric, scores[worst_metric]\n",
    "\n",
    "\n",
    "class RAGASEvaluationReport(BaseModel):\n",
    "    \"\"\"전체 데이터셋에 대한 RAGAS 평가 리포트\"\"\"\n",
    "\n",
    "    pipeline_name: str\n",
    "    dataset_name: str\n",
    "    num_questions: int\n",
    "\n",
    "    # 평균 점수\n",
    "    avg_context_precision: float\n",
    "    avg_context_recall: float\n",
    "    avg_faithfulness: float\n",
    "    avg_answer_relevancy: float\n",
    "    avg_overall: float\n",
    "\n",
    "    # 개별 질문 점수\n",
    "    question_scores: list[RAGASScore] = Field(default_factory=list)\n",
    "\n",
    "    # 성능 메트릭\n",
    "    avg_retrieval_time_ms: float = 0.0\n",
    "    avg_generation_time_ms: float = 0.0\n",
    "    avg_total_time_ms: float = 0.0\n",
    "\n",
    "    # 메타데이터\n",
    "    timestamp: str\n",
    "    metadata: dict[str, Any] = Field(default_factory=dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9184bd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 3. RAGAS 평가 관련 클래스 정의\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class MetricThreshold:\n",
    "    \"\"\"지표 임계값 및 해석 가이드\"\"\"\n",
    "\n",
    "    metric_name: str\n",
    "    excellent: float  # 우수 (90% 이상)\n",
    "    good: float  # 양호 (70% 이상)\n",
    "    fair: float  # 보통 (50% 이상)\n",
    "\n",
    "    def interpret(self, score: float) -> str:\n",
    "        if score >= self.excellent:\n",
    "            return \"EXCELLENT\"\n",
    "        elif score >= self.good:\n",
    "            return \"GOOD\"\n",
    "        elif score >= self.fair:\n",
    "            return \"FAIR\"\n",
    "        else:\n",
    "            return \"POOR\"\n",
    "\n",
    "    def get_improvement_priority(self, score: float) -> str:\n",
    "        grade = self.interpret(score)\n",
    "        if grade == \"POOR\":\n",
    "            return \"HIGH (즉시 개선 필요)\"\n",
    "        elif grade == \"FAIR\":\n",
    "            return \"MEDIUM (개선 권장)\"\n",
    "        elif grade == \"GOOD\":\n",
    "            return \"LOW (미세 조정)\"\n",
    "        else:\n",
    "            return \"None (우수)\"\n",
    "\n",
    "\n",
    "# 실무 기준 임계값\n",
    "METRIC_THRESHOLDS = {\n",
    "    RAGASMetric.CONTEXT_PRECISION: MetricThreshold(\"Context Precision\", 0.90, 0.75, 0.60),\n",
    "    RAGASMetric.CONTEXT_RECALL: MetricThreshold(\"Context Recall\", 0.85, 0.70, 0.55),\n",
    "    RAGASMetric.FAITHFULNESS: MetricThreshold(\"Faithfulness\", 0.95, 0.85, 0.70),\n",
    "    RAGASMetric.ANSWER_RELEVANCY: MetricThreshold(\"Answer Relevancy\", 0.90, 0.75, 0.60),\n",
    "}\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class NodeMetricMapping:\n",
    "    \"\"\"노드와 평가 지표 매핑\"\"\"\n",
    "\n",
    "    node: RAGNode\n",
    "    primary_metric: RAGASMetric\n",
    "    description: str\n",
    "    low_score_diagnosis: str\n",
    "    primary_action: str\n",
    "    secondary_action: str\n",
    "    expected_impact: str\n",
    "\n",
    "\n",
    "# 노드-지표 매핑 테이블\n",
    "NODE_METRIC_MAPPINGS = [\n",
    "    NodeMetricMapping(\n",
    "        node=RAGNode.RERANKING,\n",
    "        primary_metric=RAGASMetric.CONTEXT_PRECISION,\n",
    "        description=\"재랭킹 노드 - 관련 없는 문서 필터링\",\n",
    "        low_score_diagnosis=\"관련 없는 문서가 많이 혼입됨\",\n",
    "        primary_action=\"• top_k: 10→5로 감소\\\\n• reranker 모델 교체 (cross-encoder)\",\n",
    "        secondary_action=\"• BM25 + Dense 하이브리드 활성화\\\\n• MMR 적용\",\n",
    "        expected_impact=\"+10~15%p Context Precision\",\n",
    "    ),\n",
    "    NodeMetricMapping(\n",
    "        node=RAGNode.RETRIEVAL,\n",
    "        primary_metric=RAGASMetric.CONTEXT_RECALL,\n",
    "        description=\"검색 노드 - 필요한 모든 문서 찾기\",\n",
    "        low_score_diagnosis=\"필요한 문서가 누락됨\",\n",
    "        primary_action=\"• top_k: 5→20으로 증가\\\\n• chunk_overlap: 10%→20% 증가\",\n",
    "        secondary_action=\"• Query Expansion 노드 추가\\\\n• 임베딩 모델 교체\",\n",
    "        expected_impact=\"+15~25%p Context Recall\",\n",
    "    ),\n",
    "    NodeMetricMapping(\n",
    "        node=RAGNode.GENERATION,\n",
    "        primary_metric=RAGASMetric.FAITHFULNESS,\n",
    "        description=\"생성 노드 - 컨텍스트에 충실한 답변\",\n",
    "        low_score_diagnosis=\"환각 (Hallucination) 발생\",\n",
    "        primary_action=\"• 프롬프트 강화 (컨텍스트만 사용)\\\\n• Temperature: 0.7→0.0\",\n",
    "        secondary_action=\"• Context Compression 비활성화\\\\n• Few-shot 예제 3개 추가\",\n",
    "        expected_impact=\"+10~20%p Faithfulness\",\n",
    "    ),\n",
    "    NodeMetricMapping(\n",
    "        node=RAGNode.QUERY_TRANSFORM,\n",
    "        primary_metric=RAGASMetric.ANSWER_RELEVANCY,\n",
    "        description=\"쿼리 변환 노드 - 사용자 의도 파악\",\n",
    "        low_score_diagnosis=\"답변이 질문 의도와 불일치\",\n",
    "        primary_action=\"• HyDE 노드 추가\\\\n• Query Rewrite 프롬프트 개선\",\n",
    "        secondary_action=\"• 질의 분류 노드 추가\\\\n• Multi-Query 전략 적용\",\n",
    "        expected_impact=\"+10~15%p Answer Relevancy\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "def get_problematic_node(metric: RAGASMetric) -> NodeMetricMapping:\n",
    "    \"\"\"특정 지표가 낮을 때 문제가 있는 노드 식별\"\"\"\n",
    "    for mapping in NODE_METRIC_MAPPINGS:\n",
    "        if mapping.primary_metric == metric:\n",
    "            return mapping\n",
    "    raise ValueError(f\"Unknown metric: {metric}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffb438eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 4. 데이터셋 빌더 클래스 정의\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "class SyntheticDatasetGenerator:\n",
    "    \"\"\"LLM 기반 합성 데이터셋 생성기 (간소화 버전)\"\"\"\n",
    "\n",
    "    def __init__(self, llm, num_questions_per_doc=3, question_types=None, difficulty_levels=None):\n",
    "        self.llm = llm\n",
    "        self.num_questions_per_doc = num_questions_per_doc\n",
    "        self.question_types = question_types or [QuestionType.FACTUAL, QuestionType.REASONING]\n",
    "        self.difficulty_levels = difficulty_levels or [\n",
    "            DifficultyLevel.SIMPLE,\n",
    "            DifficultyLevel.MEDIUM,\n",
    "        ]\n",
    "\n",
    "    def generate_dataset(self, documents, document_ids):\n",
    "        \"\"\"문서로부터 합성 데이터셋 생성\"\"\"\n",
    "        dataset = EvaluationDataset(\n",
    "            name=\"synthetic_dataset\",\n",
    "            description=\"LLM 생성 합성 데이터셋\",\n",
    "            metadata={\"method\": \"llm_synthetic\"},\n",
    "        )\n",
    "\n",
    "        # 간단한 질문 생성 (실제로는 LLM 호출)\n",
    "        for i, (doc, doc_id) in enumerate(zip(documents, document_ids, strict=False)):\n",
    "            for j in range(self.num_questions_per_doc):\n",
    "                q_id = f\"Q{(i * self.num_questions_per_doc + j + 1):03d}\"\n",
    "                question = EvaluationQuestion(\n",
    "                    id=q_id,\n",
    "                    question=f\"[생성된 질문 {q_id}] {doc[:50]}...에 대한 질문\",\n",
    "                    question_type=self.question_types[j % len(self.question_types)],\n",
    "                    difficulty=self.difficulty_levels[j % len(self.difficulty_levels)],\n",
    "                    ground_truth=f\"[생성된 답변 {q_id}] 문서 기반 답변\",\n",
    "                    relevant_doc_ids=[doc_id],\n",
    "                    metadata={\"generated\": True},\n",
    "                )\n",
    "                dataset.questions.append(question)\n",
    "\n",
    "        return dataset\n",
    "\n",
    "\n",
    "class SMEDatasetBuilder:\n",
    "    \"\"\"도메인 전문가(SME) 인터뷰 기반 데이터셋 구축 도구\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def create_template(save_path=\"sme_template.csv\", num_examples=5):\n",
    "        \"\"\"전문가용 템플릿 생성\"\"\"\n",
    "        import csv\n",
    "\n",
    "        with open(save_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(\n",
    "                [\n",
    "                    \"질문 ID\",\n",
    "                    \"질문\",\n",
    "                    \"질문 유형\",\n",
    "                    \"난이도\",\n",
    "                    \"정답(Ground Truth)\",\n",
    "                    \"관련 문서 ID\",\n",
    "                    \"비고\",\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # 예시 행\n",
    "            for i in range(num_examples):\n",
    "                writer.writerow(\n",
    "                    [\n",
    "                        f\"Q{i + 1:03d}\",\n",
    "                        f\"[예시 질문 {i + 1}]\",\n",
    "                        \"factual\",\n",
    "                        \"simple\",\n",
    "                        \"[예시 답변]\",\n",
    "                        \"doc_example\",\n",
    "                        \"작성 가이드 참조\",\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "        return save_path\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_from_csv(csv_path):\n",
    "        \"\"\"CSV 파일에서 데이터셋 파싱\"\"\"\n",
    "        import csv\n",
    "\n",
    "        dataset = EvaluationDataset(\n",
    "            name=\"sme_dataset\",\n",
    "            description=\"도메인 전문가 작성 데이터셋\",\n",
    "            metadata={\"method\": \"sme_interview\", \"source\": str(csv_path)},\n",
    "        )\n",
    "\n",
    "        with open(csv_path, encoding=\"utf-8\") as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                try:\n",
    "                    question = EvaluationQuestion(\n",
    "                        id=row[\"질문 ID\"],\n",
    "                        question=row[\"질문\"],\n",
    "                        question_type=QuestionType(row[\"질문 유형\"]),\n",
    "                        difficulty=DifficultyLevel(row[\"난이도\"]),\n",
    "                        ground_truth=row[\"정답(Ground Truth)\"],\n",
    "                        relevant_doc_ids=[doc.strip() for doc in row[\"관련 문서 ID\"].split(\",\")],\n",
    "                        metadata={\"remarks\": row.get(\"비고\", \"\")},\n",
    "                    )\n",
    "                    dataset.questions.append(question)\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️  행 파싱 실패: {e}\")\n",
    "                    continue\n",
    "\n",
    "        return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67e939c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 5. 자동 개선 엔진 클래스 정의\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ImprovementAction:\n",
    "    \"\"\"개선 액션\"\"\"\n",
    "\n",
    "    action_type: ActionType\n",
    "    target_node: RAGNode\n",
    "    target_metric: RAGASMetric\n",
    "    priority: ActionPriority\n",
    "\n",
    "    description: str\n",
    "    rationale: str\n",
    "    parameter_changes: dict[str, Any]\n",
    "\n",
    "    expected_metric_improvement: float  # 예상 점수 향상\n",
    "    expected_side_effects: list[str]\n",
    "\n",
    "    cost_impact: str  # \"None\", \"Low\", \"Medium\", \"High\"\n",
    "    latency_impact: str  # \"None\", \"Low\", \"Medium\", \"High\"\n",
    "\n",
    "\n",
    "class ImprovementPlan(BaseModel):\n",
    "    \"\"\"개선 계획\"\"\"\n",
    "\n",
    "    baseline_report: RAGASEvaluationReport\n",
    "    actions: list[ImprovementAction] = Field(default_factory=list)\n",
    "    summary: str\n",
    "    expected_overall_improvement: float\n",
    "\n",
    "    def sort_by_priority(self) -> None:\n",
    "        \"\"\"우선순위 순으로 정렬\"\"\"\n",
    "        priority_order = {\n",
    "            ActionPriority.CRITICAL: 0,\n",
    "            ActionPriority.HIGH: 1,\n",
    "            ActionPriority.MEDIUM: 2,\n",
    "            ActionPriority.LOW: 3,\n",
    "        }\n",
    "        self.actions.sort(key=lambda a: priority_order[a.priority])\n",
    "\n",
    "    def filter_by_priority(self, min_priority: ActionPriority) -> list[ImprovementAction]:\n",
    "        \"\"\"최소 우선순위 이상의 액션만 필터링\"\"\"\n",
    "        priority_order = {\n",
    "            ActionPriority.CRITICAL: 0,\n",
    "            ActionPriority.HIGH: 1,\n",
    "            ActionPriority.MEDIUM: 2,\n",
    "            ActionPriority.LOW: 3,\n",
    "        }\n",
    "        threshold = priority_order[min_priority]\n",
    "        return [a for a in self.actions if priority_order[a.priority] <= threshold]\n",
    "\n",
    "\n",
    "class AutoImprovementEngine:\n",
    "    \"\"\"RAGAS 결과 기반 자동 개선 엔진\"\"\"\n",
    "\n",
    "    def analyze_and_generate_plan(self, baseline_report: RAGASEvaluationReport) -> ImprovementPlan:\n",
    "        \"\"\"RAGAS 리포트 분석 후 개선 계획 생성\"\"\"\n",
    "        plan = ImprovementPlan(\n",
    "            baseline_report=baseline_report,\n",
    "            actions=[],\n",
    "            summary=\"\",\n",
    "            expected_overall_improvement=0.0,\n",
    "        )\n",
    "\n",
    "        # 1. Context Recall 개선\n",
    "        if baseline_report.avg_context_recall < METRIC_THRESHOLDS[RAGASMetric.CONTEXT_RECALL].fair:\n",
    "            plan.actions.extend(self._improve_context_recall(baseline_report))\n",
    "\n",
    "        # 2. Context Precision 개선\n",
    "        if (\n",
    "            baseline_report.avg_context_precision\n",
    "            < METRIC_THRESHOLDS[RAGASMetric.CONTEXT_PRECISION].fair\n",
    "        ):\n",
    "            plan.actions.extend(self._improve_context_precision(baseline_report))\n",
    "\n",
    "        # 3. Faithfulness 개선\n",
    "        if baseline_report.avg_faithfulness < METRIC_THRESHOLDS[RAGASMetric.FAITHFULNESS].fair:\n",
    "            plan.actions.extend(self._improve_faithfulness(baseline_report))\n",
    "\n",
    "        # 4. Answer Relevancy 개선\n",
    "        if (\n",
    "            baseline_report.avg_answer_relevancy\n",
    "            < METRIC_THRESHOLDS[RAGASMetric.ANSWER_RELEVANCY].fair\n",
    "        ):\n",
    "            plan.actions.extend(self._improve_answer_relevancy(baseline_report))\n",
    "\n",
    "        # 우선순위 정렬\n",
    "        plan.sort_by_priority()\n",
    "\n",
    "        # 예상 개선 효과 계산\n",
    "        plan.expected_overall_improvement = (\n",
    "            sum(a.expected_metric_improvement for a in plan.actions) / 4.0\n",
    "        )\n",
    "\n",
    "        # 요약 생성\n",
    "        critical_count = len([a for a in plan.actions if a.priority == ActionPriority.CRITICAL])\n",
    "        high_count = len([a for a in plan.actions if a.priority == ActionPriority.HIGH])\n",
    "\n",
    "        plan.summary = f\"\"\"\n",
    "총 {len(plan.actions)}개 액션 제안:\n",
    "    - CRITICAL: {critical_count}개\n",
    "    - HIGH: {high_count}개\n",
    "    - MEDIUM: {len([a for a in plan.actions if a.priority == ActionPriority.MEDIUM])}개\n",
    "    - LOW: {len([a for a in plan.actions if a.priority == ActionPriority.LOW])}개\"\"\"\n",
    "\n",
    "        return plan\n",
    "\n",
    "    def _improve_context_recall(self, report: RAGASEvaluationReport) -> list[ImprovementAction]:\n",
    "        \"\"\"Context Recall 개선 액션 생성\"\"\"\n",
    "        actions = []\n",
    "        recall = report.avg_context_recall\n",
    "        threshold = METRIC_THRESHOLDS[RAGASMetric.CONTEXT_RECALL]\n",
    "\n",
    "        priority = ActionPriority.CRITICAL if recall < threshold.fair else ActionPriority.HIGH\n",
    "\n",
    "        actions.append(\n",
    "            ImprovementAction(\n",
    "                action_type=ActionType.INCREASE_TOP_K,\n",
    "                target_node=RAGNode.RETRIEVAL,\n",
    "                target_metric=RAGASMetric.CONTEXT_RECALL,\n",
    "                priority=priority,\n",
    "                description=\"검색 문서 개수 증가 (top_k)\",\n",
    "                rationale=f\"Context Recall이 {recall:.2%}로 낮습니다. 필요한 문서를 충분히 검색하지 못하고 있습니다.\",\n",
    "                parameter_changes={\"retrieval.top_k\": \"5 → 20 (4배 증가)\"},\n",
    "                expected_metric_improvement=0.15,\n",
    "                expected_side_effects=[\n",
    "                    \"재랭킹 부하 증가 (처리 시간 +10~20%)\",\n",
    "                    \"Context Precision 일시적 하락 가능\",\n",
    "                ],\n",
    "                cost_impact=\"Low\",\n",
    "                latency_impact=\"Medium\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return actions\n",
    "\n",
    "    def _improve_context_precision(self, report: RAGASEvaluationReport) -> list[ImprovementAction]:\n",
    "        \"\"\"Context Precision 개선 액션 생성\"\"\"\n",
    "        actions = []\n",
    "        precision = report.avg_context_precision\n",
    "        threshold = METRIC_THRESHOLDS[RAGASMetric.CONTEXT_PRECISION]\n",
    "\n",
    "        priority = ActionPriority.CRITICAL if precision < threshold.fair else ActionPriority.HIGH\n",
    "\n",
    "        actions.append(\n",
    "            ImprovementAction(\n",
    "                action_type=ActionType.CHANGE_RERANKER,\n",
    "                target_node=RAGNode.RERANKING,\n",
    "                target_metric=RAGASMetric.CONTEXT_PRECISION,\n",
    "                priority=priority,\n",
    "                description=\"Cross-Encoder 재랭킹 모델 추가/변경\",\n",
    "                rationale=f\"Context Precision이 {precision:.2%}로 낮습니다. 관련 없는 문서가 많이 혼입되고 있습니다.\",\n",
    "                parameter_changes={\"reranker.model\": \"None → cross-encoder/ms-marco-MiniLM-L-6-v2\"},\n",
    "                expected_metric_improvement=0.12,\n",
    "                expected_side_effects=[\"재랭킹 시간 +50~100% 증가\"],\n",
    "                cost_impact=\"Medium\",\n",
    "                latency_impact=\"High\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return actions\n",
    "\n",
    "    def _improve_faithfulness(self, report: RAGASEvaluationReport) -> list[ImprovementAction]:\n",
    "        \"\"\"Faithfulness 개선 액션 생성\"\"\"\n",
    "        actions = []\n",
    "        faithfulness = report.avg_faithfulness\n",
    "        threshold = METRIC_THRESHOLDS[RAGASMetric.FAITHFULNESS]\n",
    "\n",
    "        priority = ActionPriority.CRITICAL if faithfulness < threshold.good else ActionPriority.HIGH\n",
    "\n",
    "        actions.append(\n",
    "            ImprovementAction(\n",
    "                action_type=ActionType.STRENGTHEN_PROMPT,\n",
    "                target_node=RAGNode.GENERATION,\n",
    "                target_metric=RAGASMetric.FAITHFULNESS,\n",
    "                priority=priority,\n",
    "                description=\"프롬프트에 충실성 강제 지시 추가\",\n",
    "                rationale=f\"Faithfulness가 {faithfulness:.2%}로 낮습니다. LLM이 컨텍스트 외 정보를 생성하고 있습니다.\",\n",
    "                parameter_changes={\"generation.system_prompt\": \"컨텍스트 충실성 명시적 강제\"},\n",
    "                expected_metric_improvement=0.15,\n",
    "                expected_side_effects=[\"답변이 더 보수적이 될 수 있음\"],\n",
    "                cost_impact=\"None\",\n",
    "                latency_impact=\"None\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        actions.append(\n",
    "            ImprovementAction(\n",
    "                action_type=ActionType.REDUCE_TEMPERATURE,\n",
    "                target_node=RAGNode.GENERATION,\n",
    "                target_metric=RAGASMetric.FAITHFULNESS,\n",
    "                priority=ActionPriority.HIGH,\n",
    "                description=\"Temperature를 0으로 낮추기 (결정적 생성)\",\n",
    "                rationale=\"높은 Temperature는 환각을 유발할 수 있습니다.\",\n",
    "                parameter_changes={\"generation.temperature\": \"0.7 → 0.0\"},\n",
    "                expected_metric_improvement=0.10,\n",
    "                expected_side_effects=[\"답변이 덜 다양해질 수 있음\"],\n",
    "                cost_impact=\"None\",\n",
    "                latency_impact=\"None\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return actions\n",
    "\n",
    "    def _improve_answer_relevancy(self, report: RAGASEvaluationReport) -> list[ImprovementAction]:\n",
    "        \"\"\"Answer Relevancy 개선 액션 생성\"\"\"\n",
    "        actions = []\n",
    "        relevancy = report.avg_answer_relevancy\n",
    "        threshold = METRIC_THRESHOLDS[RAGASMetric.ANSWER_RELEVANCY]\n",
    "\n",
    "        priority = ActionPriority.CRITICAL if relevancy < threshold.fair else ActionPriority.HIGH\n",
    "\n",
    "        actions.append(\n",
    "            ImprovementAction(\n",
    "                action_type=ActionType.ADD_HYDE,\n",
    "                target_node=RAGNode.QUERY_TRANSFORM,\n",
    "                target_metric=RAGASMetric.ANSWER_RELEVANCY,\n",
    "                priority=priority,\n",
    "                description=\"HyDE (Hypothetical Document Embeddings) 노드 추가\",\n",
    "                rationale=f\"Answer Relevancy가 {relevancy:.2%}로 낮습니다. 질문-문서 간 semantic gap 해소 필요.\",\n",
    "                parameter_changes={\"query_transform.enable_hyde\": \"False → True\"},\n",
    "                expected_metric_improvement=0.12,\n",
    "                expected_side_effects=[\n",
    "                    \"쿼리당 LLM 호출 1회 추가 (비용 +30~50%)\",\n",
    "                    \"지연시간 +200~500ms\",\n",
    "                ],\n",
    "                cost_impact=\"High\",\n",
    "                latency_impact=\"High\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4db0ecdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# OpenAI / OpenRouter 모델 초기화 헬퍼\n",
    "# ----------------------------------------------------------------------------\n",
    "from typing import Literal\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def _resolve_api_context() -> tuple[str, str]:\n",
    "    \"\"\"선택된 API 키와 베이스 URL 정보를 반환합니다.\"\"\"\n",
    "    api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise RuntimeError(\"OPENROUTER_API_KEY가 필요합니다.\")\n",
    "\n",
    "    base_url = os.getenv(\"OPENROUTER_API_BASE\") or \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "    return (api_key, base_url)\n",
    "\n",
    "\n",
    "def create_openrouter_llm(\n",
    "    model: str = \"openai/gpt-4.1-mini\",\n",
    "    temperature: float = 0.3,\n",
    "    max_tokens: int | None = None,\n",
    "    **kwargs: object,\n",
    ") -> ChatOpenAI:\n",
    "    \"\"\"OpenAI 호환 LLM 생성 헬퍼.\n",
    "\n",
    "    Args:\n",
    "        model: 모델 이름. OpenRouter에서는 provider/model 형식 사용 가능\n",
    "               (예: openai/gpt-4o, anthropic/claude-3-sonnet, google/gemini-pro)\n",
    "        temperature: 생성 온도 (0.0-2.0)\n",
    "        max_tokens: 최대 생성 토큰 수\n",
    "\n",
    "    Returns:\n",
    "        ChatOpenAI: 설정된 LLM 인스턴스\n",
    "    \"\"\"\n",
    "    api_key, base_url = _resolve_api_context()\n",
    "\n",
    "    openai_kwargs: dict = {\n",
    "        \"model\": model,\n",
    "        \"api_key\": api_key,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_retries\": 3,\n",
    "        \"timeout\": 60,\n",
    "        **kwargs,\n",
    "    }\n",
    "    if max_tokens is not None:\n",
    "        openai_kwargs[\"max_tokens\"] = max_tokens\n",
    "    if base_url:\n",
    "        openai_kwargs[\"base_url\"] = base_url\n",
    "    return ChatOpenAI(**openai_kwargs)\n",
    "\n",
    "\n",
    "def create_embedding_model(\n",
    "    model: str = \"openai/text-embedding-3-small\",\n",
    "    **kwargs,\n",
    ") -> OpenAIEmbeddings:\n",
    "    \"\"\"OpenAI 호환 임베딩 모델 생성.\n",
    "\n",
    "    Args:\n",
    "        model: 임베딩 모델 이름. OpenRouter에서는 provider/model 형식 사용 가능\n",
    "               (예: openai/text-embedding-3-small, openai/text-embedding-3-large)\n",
    "        **kwargs: 추가 파라미터 (encoding_format 등은 model_kwargs로 전달됨)\n",
    "\n",
    "    Returns:\n",
    "        OpenAIEmbeddings: 설정된 임베딩 모델 인스턴스\n",
    "    \"\"\"\n",
    "    api_key, base_url = _resolve_api_context()\n",
    "\n",
    "    # 전달받은 kwargs에서 model_kwargs로 전달할 파라미터 분리\n",
    "    # encoding_format, extra_headers 등은 model_kwargs로 전달\n",
    "    model_kwargs: dict = {}\n",
    "    embedding_kwargs: dict = {\n",
    "        \"model\": model,\n",
    "        \"api_key\": api_key,\n",
    "        \"show_progress_bar\": True,\n",
    "        \"skip_empty\": True,\n",
    "    }\n",
    "\n",
    "    # 전달받은 kwargs 처리\n",
    "    for key, value in kwargs.items():\n",
    "        # OpenRouter API 특정 파라미터는 model_kwargs로 전달\n",
    "        if key in (\"encoding_format\"):\n",
    "            model_kwargs[key] = value\n",
    "        else:\n",
    "            # 나머지는 OpenAIEmbeddings에 직접 전달\n",
    "            embedding_kwargs[key] = value\n",
    "\n",
    "    if base_url:\n",
    "        embedding_kwargs[\"base_url\"] = base_url\n",
    "\n",
    "    # model_kwargs가 있으면 전달\n",
    "    if model_kwargs:\n",
    "        embedding_kwargs[\"model_kwargs\"] = model_kwargs\n",
    "\n",
    "    return OpenAIEmbeddings(**embedding_kwargs)\n",
    "\n",
    "\n",
    "def create_embedding_model_direct(\n",
    "    model: str = \"qwen/qwen3-embedding-0.6b\",\n",
    "    encoding_format: Literal[\"float\", \"base64\"] = \"float\",\n",
    "    input_text: str | list[str] = \"\",\n",
    "    **kwargs,\n",
    ") -> list[float] | list[list[float]]:\n",
    "    \"\"\"OpenAI SDK를 직접 사용하여 임베딩 생성 (encoding_format 지원).\n",
    "\n",
    "    LangChain의 OpenAIEmbeddings가 encoding_format을 지원하지 않을 때 사용.\n",
    "\n",
    "    Args:\n",
    "        model: 임베딩 모델 이름\n",
    "        encoding_format: 인코딩 형식 (\"float\")\n",
    "        input_text: 임베딩할 텍스트 (문자열 또는 문자열 리스트)\n",
    "        **kwargs: 추가 파라미터\n",
    "\n",
    "    Returns:\n",
    "        임베딩 벡터 리스트 (단일 텍스트) 또는 리스트의 리스트 (여러 텍스트)\n",
    "    \"\"\"\n",
    "    from openai import OpenAI\n",
    "\n",
    "    api_key, base_url = _resolve_api_context()\n",
    "\n",
    "    client = OpenAI(\n",
    "        base_url=base_url,\n",
    "        api_key=api_key,\n",
    "    )\n",
    "\n",
    "    # input_text가 비어있으면 kwargs에서 가져오기\n",
    "    if not input_text:\n",
    "        input_text = kwargs.get(\"input\", \"\")\n",
    "\n",
    "    response = client.embeddings.create(\n",
    "        model=model,\n",
    "        input=input_text,\n",
    "        encoding_format=encoding_format,\n",
    "    )\n",
    "\n",
    "    # 단일 텍스트인 경우 첫 번째 임베딩 반환\n",
    "    if isinstance(input_text, str):\n",
    "        return response.data[0].embedding\n",
    "    else:\n",
    "        # 여러 텍스트인 경우 모든 임베딩 반환\n",
    "        return [item.embedding for item in response.data]\n",
    "\n",
    "\n",
    "def get_available_model_types() -> dict[str, list[str]]:\n",
    "    \"\"\"OpenRouter에서 사용 가능한 모델 유형을 반환합니다.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, list[str]]: 모델 유형별 모델 목록\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"chat\": [\n",
    "            \"openai/gpt-4.1\",\n",
    "            \"openai/gpt-4.1-mini\",\n",
    "            \"openai/gpt-5\",\n",
    "            \"openai/gpt-5-mini\",\n",
    "            \"anthropic/claude-sonnet-4.5\",\n",
    "            \"anthropic/claude-haiku-4.5\",\n",
    "            \"google/gemini-2.5-flash-preview-09-2025\",\n",
    "            \"google/gemini-pro-2.5\",\n",
    "            \"x-ai/grok-4-fast\",\n",
    "            \"moonshotai/kimi-k2-thinking\",\n",
    "            \"liquid/lfm-2.2-6b\",\n",
    "            \"z-ai/glm-4.6\",\n",
    "        ],\n",
    "        \"embedding\": [\n",
    "            \"openai/text-embedding-3-small\",\n",
    "            \"openai/text-embedding-3-large\",\n",
    "            \"google/gemini-embedding-001\",\n",
    "            \"qwen/qwen3-embedding-0.6b\",\n",
    "            \"qwen/qwen3-embedding-4b\",\n",
    "            \"qwen/qwen3-embedding-8b\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "\n",
    "embeddings = create_embedding_model()\n",
    "llm = create_openrouter_llm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc07419",
   "metadata": {},
   "source": [
    "## 1. RAGAS 이해하기\n",
    "\n",
    "### 1.1 RAGAS란 무엇인가?\n",
    "\n",
    "**RAGAS** (Retrieval Augmented Generation Assessment)는 RAG 시스템을 위한 전문 평가 프레임워크입니다.\n",
    "\n",
    "#### 왜 RAGAS가 필요한가?\n",
    "\n",
    "RAG 시스템의 품질을 평가하려면 다음 질문들에 답할 수 있어야 합니다:\n",
    "- 검색된 문서가 **정말로 관련성이 있는가**? (노이즈는 없는가?)\n",
    "- 필요한 모든 정보를 **충분히 검색했는가**? (누락은 없는가?)\n",
    "- LLM이 검색된 컨텍스트에 **충실한 답변**을 생성했는가? (환각은 없는가?)\n",
    "- 생성된 답변이 **사용자 질문에 직접 답**하는가? (의도와 일치하는가?)\n",
    "\n",
    "전통적인 단일 지표(예: BLEU, ROUGE)로는 이러한 다면적 품질을 측정할 수 없습니다.\n",
    "\n",
    "RAGAS는 **4대 핵심 지표**를 통해 RAG 시스템을 종합적으로 평가합니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.2 RAGAS 4대 핵심 지표\n",
    "\n",
    "#### 1) Context Precision (컨텍스트 정밀도)\n",
    "\n",
    "**측정 대상:** 검색 노드 → **재랭킹 노드**\n",
    "\n",
    "**질문:** 검색된 문서들이 얼마나 관련성이 있는가?\n",
    "\n",
    "**점수 의미:**\n",
    "- **높음 (0.8+)**: 관련 없는 문서가 거의 없음 (노이즈 최소화)\n",
    "- **낮음 (<0.6)**: 관련 없는 문서가 많이 혼입됨 (재랭킹 필요)\n",
    "\n",
    "**계산 방식:**\n",
    "```\n",
    "Context Precision = (관련성 있는 문서 수) / (전체 검색된 문서 수)\n",
    "```\n",
    "\n",
    "**실무 영향:**\n",
    "- 낮으면: LLM이 무관한 정보를 읽느라 토큰 낭비, 답변 품질 저하\n",
    "- 개선 방법: Reranker 모델 추가, top_k 감소, MMR 적용\n",
    "\n",
    "---\n",
    "\n",
    "#### 2) Context Recall (컨텍스트 재현율)\n",
    "\n",
    "**측정 대상:** **검색 노드**\n",
    "\n",
    "**질문:** 필요한 모든 정보를 검색했는가?\n",
    "\n",
    "**점수 의미:**\n",
    "- **높음 (0.8+)**: 필요한 정보를 거의 다 찾음\n",
    "- **낮음 (<0.6)**: 필요한 정보가 많이 누락됨\n",
    "\n",
    "**계산 방식:**\n",
    "```\n",
    "Context Recall = (검색된 Ground Truth 문서 수) / (전체 Ground Truth 문서 수)\n",
    "```\n",
    "\n",
    "**실무 영향:**\n",
    "- 낮으면: LLM이 정보 부족으로 \"모르겠다\" 답변, 부정확한 추론\n",
    "- 개선 방법: top_k 증가, chunk_overlap 증가, 임베딩 모델 변경\n",
    "\n",
    "---\n",
    "\n",
    "#### 3) Faithfulness (충실성)\n",
    "\n",
    "**측정 대상:** **생성 노드** (LLM)\n",
    "\n",
    "**질문:** 생성된 답변이 컨텍스트에 충실한가? (환각은 없는가?)\n",
    "\n",
    "**점수 의미:**\n",
    "- **높음 (0.9+)**: 컨텍스트 기반 답변, 환각 없음\n",
    "- **낮음 (<0.75)**: 컨텍스트 외 정보 생성 (환각)\n",
    "\n",
    "**계산 방식:**\n",
    "```\n",
    "Faithfulness = (컨텍스트에서 확인 가능한 문장 수) / (전체 생성된 문장 수)\n",
    "```\n",
    "\n",
    "**실무 영향:**\n",
    "- 낮으면: 사용자 신뢰 상실, 잘못된 의사결정 유도 (치명적!)\n",
    "- 개선 방법: 프롬프트 강화 (\"컨텍스트만 사용\"), Temperature=0, Few-shot 예제\n",
    "\n",
    "---\n",
    "\n",
    "#### 4) Answer Relevancy (답변 적합성)\n",
    "\n",
    "**측정 대상:** **쿼리 변환 노드** + 생성 노드\n",
    "\n",
    "**질문:** 답변이 질문에 직접 답하는가?\n",
    "\n",
    "**점수 의미:**\n",
    "- **높음 (0.8+)**: 질문 의도와 완벽히 일치하는 답변\n",
    "- **낮음 (<0.6)**: 질문과 무관하거나 애매한 답변\n",
    "\n",
    "**계산 방식:**\n",
    "```\n",
    "Answer Relevancy = 질문과 답변의 의미적 유사도\n",
    "```\n",
    "\n",
    "**실무 영향:**\n",
    "- 낮으면: 사용자 불만, \"질문을 이해하지 못함\"\n",
    "- 개선 방법: HyDE 추가, Query Rewrite 개선, Intent Classification\n",
    "\n",
    "---\n",
    "\n",
    "### 1.3 RAGAS 지표 ↔ RAG 노드 매핑 테이블\n",
    "\n",
    "| RAGAS 지표 | 측정 대상 노드 | 낮을 때 증상 | 주요 개선 방향 |\n",
    "|-----------|--------------|-------------|---------------|\n",
    "| **Context Precision** | 재랭킹 (Reranking) | 무관한 문서 혼입 | Reranker 추가, top_k 감소 |\n",
    "| **Context Recall** | 검색 (Retrieval) | 필요한 문서 누락 | top_k 증가, 임베딩 개선 |\n",
    "| **Faithfulness** | 생성 (Generation) | 환각 발생 | 프롬프트 강화, temp=0 |\n",
    "| **Answer Relevancy** | 쿼리 변환 + 생성 | 의도 불일치 | HyDE, Query Rewrite |\n",
    "\n",
    "**핵심 통찰:**\n",
    "- 각 지표는 특정 **노드의 문제**를 진단합니다\n",
    "- 지표가 낮으면 → 해당 노드를 **집중 개선**\n",
    "- 노드별 독립 평가 → **병목 지점 정확히 식별**\n",
    "\n",
    "---\n",
    "\n",
    "### 1.4 참고 자료\n",
    "\n",
    "- **공식 문서**: https://docs.ragas.io/en/stable/concepts/\n",
    "- **논문**: [RAGAS: Automated Evaluation of Retrieval Augmented Generation](https://arxiv.org/abs/2309.15217)\n",
    "- **지표 상세**: https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/\n",
    "- **사용법**: https://docs.ragas.io/en/stable/howtos/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eceb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# RAGAS 설정\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "try:\n",
    "    from ragas import EvaluationDataset, SingleTurnSample, evaluate\n",
    "    from ragas.metrics import answer_relevancy, context_precision, context_recall, faithfulness\n",
    "\n",
    "    RAGAS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"[경고] RAGAS가 설치되지 않았습니다. 설치: uv add ragas\")\n",
    "    print(\"[실행] uv run\")\n",
    "    RAGAS_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d2f2b9",
   "metadata": {},
   "source": [
    "### 1.5 실습: RAGAS 기본 사용법\n",
    "\n",
    "간단한 예제로 RAGAS 4대 지표를 실제로 계산해봅시다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8df3fa74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "샘플 데이터:\n",
      "  질문: Python에서 리스트 컴프리헨션이란 무엇인가요?\n",
      "  Ground Truth: 리스트 컴프리헨션은 기존 리스트를 기반으로 새로운 리스트를 간결하게 생성하는 파이썬 문법입...\n",
      "  검색된 컨텍스트: 3개\n",
      "  생성된 답변 (좋은 예): 리스트 컴프리헨션은 파이썬에서 리스트를 생성하는 간결한 방법입니다. 기본 문법은 [표현식 ...\n",
      "  생성된 답변 (나쁜 예): 리스트 컴프리헨션은 C++에서 유래된 기능으로, 파이썬 2.0에서 처음 도입되었습니다. N...\n",
      "\n",
      "RAGAS 평가 데이터셋 생성 완료\n",
      "\n",
      "================================================================================\n",
      "RAGAS 평가 실행 중...\n",
      "================================================================================\n",
      "\n",
      "[시나리오 1] 좋은 답변 평가:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24410e44eb2e49a9bb1131e115641bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ee1f98c1324383af502931941cdb01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d437bbdfa541bf9a3d3d1077e5385a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "평가 결과 (좋은 답변):\n",
      "평가 중 오류 발생: unsupported format string passed to list.__format__\n",
      "  (RAGAS 평가는 LLM API 호출이 많아 시간이 걸리거나 오류가 발생할 수 있습니다)\n",
      "\n",
      "[시나리오 2] 나쁜 답변 (환각 포함) 평가:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea39c6e57f64d239d40121c0dd57d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6f7eac7155480b9b2437ac957caadc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b107f76a7647b6804f9bacae327846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "평가 결과 (나쁜 답변):\n",
      "  평가 중 오류 발생: unsupported format string passed to list.__format__\n",
      "\n",
      "================================================================================\n",
      "RAGAS 평가 결과 해석\n",
      "================================================================================\n",
      "\n",
      "RAGAS 각 지표의 의미:\n",
      "\n",
      "1. **Context Precision** (컨텍스트 정밀도)\n",
      "   - 검색된 3개 문서 중 실제로 관련성 있는 문서의 비율\n",
      "   - 높을수록: 노이즈 없는 깨끗한 검색 결과\n",
      "   - 낮을수록: 무관한 문서가 많이 혼입됨\n",
      "\n",
      "2. **Context Recall** (컨텍스트 재현율)\n",
      "   - Ground Truth에 필요한 정보를 얼마나 검색했는가\n",
      "   - 높을수록: 필요한 정보를 충분히 검색\n",
      "   - 낮을수록: 필요한 정보가 누락됨\n",
      "\n",
      "3. **Faithfulness** (충실성)\n",
      "   - 생성된 답변이 컨텍스트에 충실한가\n",
      "   - 높을수록: 환각 없는 신뢰할 수 있는 답변\n",
      "   - 낮을수록: 컨텍스트 외 정보 생성 (환각)\n",
      "\n",
      "4. **Answer Relevancy** (답변 적합성)\n",
      "   - 답변이 질문에 직접 답하는가\n",
      "   - 높을수록: 질문 의도와 완벽히 일치\n",
      "   - 낮을수록: 질문과 무관하거나 애매한 답변\n",
      "\n",
      "\n",
      "[실무 활용]\n",
      "- 이 4가지 지표를 통해 RAG 시스템의 **어느 부분이 문제**인지 정확히 파악\n",
      "- 각 지표에 맞는 **타겟 개선 전략** 수립 가능\n",
      "- 개선 전후 비교를 통한 **정량적 효과 측정**\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# RAGAS 기본 사용법 실습\n",
    "# ============================================================================\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 1: 샘플 데이터 준비\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "# 샘플 질문\n",
    "question = \"Python에서 리스트 컴프리헨션이란 무엇인가요?\"\n",
    "\n",
    "# Ground Truth 답변 (정답)\n",
    "ground_truth = \"리스트 컴프리헨션은 기존 리스트를 기반으로 새로운 리스트를 간결하게 생성하는 파이썬 문법입니다. [표현식 for 항목 in 반복가능객체] 형태로 작성되며, 조건을 추가할 수도 있습니다.\"\n",
    "\n",
    "# 검색된 컨텍스트 (RAG에서 검색한 문서들)\n",
    "contexts = [\n",
    "    # Context 1: 관련성 높음 (정확한 정의)\n",
    "    \"리스트 컴프리헨션(list comprehension)은 파이썬에서 리스트를 생성하는 간결한 방법입니다. 기본 문법은 [표현식 for 항목 in 반복가능객체]이며, if 조건을 추가하여 필터링할 수 있습니다.\",\n",
    "    # Context 2: 관련성 중간 (예제 포함)\n",
    "    \"리스트를 생성하는 여러 방법이 있습니다. for 루프를 사용하거나, map() 함수를 사용하거나, 또는 리스트 컴프리헨션을 사용할 수 있습니다. 예: squares = [x**2 for x in range(10)]\",\n",
    "    # Context 3: 관련성 낮음 (다른 컴프리헨션)\n",
    "    \"파이썬에는 딕셔너리 컴프리헨션과 집합 컴프리헨션도 있습니다. 딕셔너리 컴프리헨션은 {key: value for item in iterable} 형태입니다.\",\n",
    "]\n",
    "\n",
    "# RAG 시스템이 생성한 답변\n",
    "# 시나리오 1: 좋은 답변 (컨텍스트에 충실)\n",
    "answer_good = \"리스트 컴프리헨션은 파이썬에서 리스트를 생성하는 간결한 방법입니다. 기본 문법은 [표현식 for 항목 in 반복가능객체]이며, 예를 들어 squares = [x**2 for x in range(10)]처럼 사용할 수 있습니다.\"\n",
    "\n",
    "# 시나리오 2: 나쁜 답변 (환각 포함)\n",
    "answer_bad = \"리스트 컴프리헨션은 C++에서 유래된 기능으로, 파이썬 2.0에서 처음 도입되었습니다. NumPy 배열보다 3배 빠르게 동작하며, 메모리 효율이 뛰어납니다.\"\n",
    "\n",
    "print(\"\\n샘플 데이터:\")\n",
    "print(f\"  질문: {question}\")\n",
    "print(f\"  Ground Truth: {ground_truth[:50]}...\")\n",
    "print(f\"  검색된 컨텍스트: {len(contexts)}개\")\n",
    "print(f\"  생성된 답변 (좋은 예): {answer_good[:50]}...\")\n",
    "print(f\"  생성된 답변 (나쁜 예): {answer_bad[:50]}...\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 2: RAGAS 평가 데이터셋 생성\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "# RAGAS의 SingleTurnSample 형식으로 변환\n",
    "sample_good = SingleTurnSample(\n",
    "    user_input=question,\n",
    "    response=answer_good,\n",
    "    retrieved_contexts=contexts,\n",
    "    reference=ground_truth,\n",
    ")\n",
    "\n",
    "sample_bad = SingleTurnSample(\n",
    "    user_input=question,\n",
    "    response=answer_bad,\n",
    "    retrieved_contexts=contexts,\n",
    "    reference=ground_truth,\n",
    ")\n",
    "\n",
    "# EvaluationDataset 생성\n",
    "dataset_good = EvaluationDataset(samples=[sample_good])\n",
    "dataset_bad = EvaluationDataset(samples=[sample_bad])\n",
    "\n",
    "print(\"\\nRAGAS 평가 데이터셋 생성 완료\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 3: RAGAS 평가 실행\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RAGAS 평가 실행 중...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 평가 지표 정의\n",
    "metrics = [\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "]\n",
    "\n",
    "# 평가 실행 (좋은 답변)\n",
    "print(\"\\n[시나리오 1] 좋은 답변 평가:\")\n",
    "try:\n",
    "    result_good = evaluate(\n",
    "        dataset=dataset_good,\n",
    "        metrics=metrics,\n",
    "        llm=llm,\n",
    "        embeddings=embeddings,\n",
    "    )\n",
    "\n",
    "    print(\"\\n평가 결과 (좋은 답변):\")\n",
    "    print(f\"  • Context Precision  : {result_good['context_precision']:.3f}\")\n",
    "    print(f\"  • Context Recall     : {result_good['context_recall']:.3f}\")\n",
    "    print(f\"  • Faithfulness       : {result_good['faithfulness']:.3f}\")\n",
    "    print(f\"  • Answer Relevancy   : {result_good['answer_relevancy']:.3f}\")\n",
    "    print(\n",
    "        f\"  • 평균 점수          : {sum([result_good['context_precision'], result_good['context_recall'], result_good['faithfulness'], result_good['answer_relevancy']]) / 4:.3f}\"\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"평가 중 오류 발생: {e}\")\n",
    "    print(\"  (RAGAS 평가는 LLM API 호출이 많아 시간이 걸리거나 오류가 발생할 수 있습니다)\")\n",
    "\n",
    "# 평가 실행 (나쁜 답변)\n",
    "print(\"\\n[시나리오 2] 나쁜 답변 (환각 포함) 평가:\")\n",
    "try:\n",
    "    result_bad = evaluate(\n",
    "        dataset=dataset_bad,\n",
    "        metrics=metrics,\n",
    "        llm=llm,\n",
    "        embeddings=embeddings,\n",
    "    )\n",
    "\n",
    "    print(\"\\n평가 결과 (나쁜 답변):\")\n",
    "    print(f\"  • Context Precision  : {result_bad['context_precision']:.3f}\")\n",
    "    print(f\"  • Context Recall     : {result_bad['context_recall']:.3f}\")\n",
    "    print(f\"  • Faithfulness       : {result_bad['faithfulness']:.3f} ← 낮음!\")\n",
    "    print(f\"  • Answer Relevancy   : {result_bad['answer_relevancy']:.3f}\")\n",
    "    print(\n",
    "        f\"  • 평균 점수          : {sum([result_bad['context_precision'], result_bad['context_recall'], result_bad['faithfulness'], result_bad['answer_relevancy']]) / 4:.3f}\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n해석:\")\n",
    "    print(\"  - 나쁜 답변은 Faithfulness 점수가 낮습니다\")\n",
    "    print(\"  - 이는 LLM이 컨텍스트에 없는 정보(환각)를 생성했음을 의미합니다\")\n",
    "    print(\"  - C++, 파이썬 2.0, NumPy 비교 등은 컨텍스트에 없는 내용입니다\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"  평가 중 오류 발생: {e}\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 4: 결과 해석\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RAGAS 평가 결과 해석\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "RAGAS 각 지표의 의미:\n",
    "\n",
    "1. **Context Precision** (컨텍스트 정밀도)\n",
    "   - 검색된 3개 문서 중 실제로 관련성 있는 문서의 비율\n",
    "   - 높을수록: 노이즈 없는 깨끗한 검색 결과\n",
    "   - 낮을수록: 무관한 문서가 많이 혼입됨\n",
    "\n",
    "2. **Context Recall** (컨텍스트 재현율)\n",
    "   - Ground Truth에 필요한 정보를 얼마나 검색했는가\n",
    "   - 높을수록: 필요한 정보를 충분히 검색\n",
    "   - 낮을수록: 필요한 정보가 누락됨\n",
    "\n",
    "3. **Faithfulness** (충실성)\n",
    "   - 생성된 답변이 컨텍스트에 충실한가\n",
    "   - 높을수록: 환각 없는 신뢰할 수 있는 답변\n",
    "   - 낮을수록: 컨텍스트 외 정보 생성 (환각)\n",
    "\n",
    "4. **Answer Relevancy** (답변 적합성)\n",
    "   - 답변이 질문에 직접 답하는가\n",
    "   - 높을수록: 질문 의도와 완벽히 일치\n",
    "   - 낮을수록: 질문과 무관하거나 애매한 답변\n",
    "\n",
    "\n",
    "[실무 활용]\n",
    "- 이 4가지 지표를 통해 RAG 시스템의 **어느 부분이 문제**인지 정확히 파악\n",
    "- 각 지표에 맞는 **타겟 개선 전략** 수립 가능\n",
    "- 개선 전후 비교를 통한 **정량적 효과 측정**\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd2b747",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Agentic RAG를 Adaptive RAG 기반으로 구현하기\n",
    "\n",
    "### 2.1 Adaptive RAG vs Agentic RAG 개념 비교\n",
    "\n",
    "#### Adaptive RAG\n",
    "- **핵심**: 질문 복잡도에 따라 **검색 전략을 조정**\n",
    "- **분류**: SIMPLE (단일 검색) / MEDIUM (확장 검색) / COMPLEX (Multi-hop 검색)\n",
    "- **특징**: 규칙 기반 분기, 예측 가능한 흐름\n",
    "- **장점**: 구현 간단, 명확한 로직\n",
    "- **단점**: 유연성 제한, 예외 상황 대응 어려움\n",
    "\n",
    "#### Agentic RAG\n",
    "- **핵심**: Tool 기반으로 Agent가 **자율적으로 판단/행동**\n",
    "- **분류**: 검색 Tool, 계산 Tool, API Tool 등을 동적으로 선택\n",
    "- **특징**: LLM의 자율적 의사결정, 동적 워크플로우\n",
    "- **장점**: 유연성 높음, 복잡한 시나리오 대응 가능\n",
    "- **단점**: 예측 불가능성, 디버깅 어려움\n",
    "\n",
    "#### 본 실습에서 Agentic RAG 를 접근하는 방법\n",
    "- **Adaptive 구조** + **Agentic 실행**\n",
    "- **복잡도 분석으로 큰 틀 결정 (Adaptive)**\n",
    "- **각 단계에서 (LLM + tools + System Prompt) = Agent 가 자율적 판단 (Agentic)**\n",
    "- 최적의 AI Agent = 예측 가능성 + 유연성\n",
    "\n",
    "---\n",
    "\n",
    "### 2.2 LangGraph 기반 Agentic RAG 구현\n",
    "\n",
    "우리는 다음과 같은 워크플로우를 구축합니다:\n",
    "\n",
    "```\n",
    "[질문 입력]\n",
    "    ↓\n",
    "[Intent Classification] ← 질문 의도 파악 (SEARCH/EXPLAIN/COMPARE 등)\n",
    "    ↓\n",
    "[Complexity Analysis] ← 복잡도 분석 (SIMPLE/MEDIUM/COMPLEX)\n",
    "    ↓\n",
    "[Adaptive Retrieval] ← 복잡도별 검색 전략\n",
    "    ├─ SIMPLE: 단일 Vector Search\n",
    "    ├─ MEDIUM: Hybrid Search (Dense + Sparse)\n",
    "    └─ COMPLEX: Multi-hop Retrieval\n",
    "    ↓\n",
    "[Generation] ← 답변 생성\n",
    "    ↓\n",
    "[답변 반환]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18c3c5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Agentic RAG 구현 - Step 1: State 정의\n",
    "# ============================================================================\n",
    "\n",
    "from typing import TypedDict\n",
    "\n",
    "from langgraph.graph import END, StateGraph\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class AgenticRAGState(TypedDict, total=False):\n",
    "    \"\"\"Agentic RAG의 전체 상태\"\"\"\n",
    "\n",
    "    # 입력\n",
    "    query: str\n",
    "\n",
    "    # Intent Classification\n",
    "    intent: Literal[\"SEARCH\", \"EXPLAIN\", \"COMPARE\", \"CALCULATE\", \"ANALYZE\"]\n",
    "    intent_confidence: float\n",
    "    intent_reasoning: str\n",
    "\n",
    "    # Complexity Analysis\n",
    "    complexity: Literal[\"SIMPLE\", \"MEDIUM\", \"COMPLEX\"]\n",
    "    complexity_reasoning: str\n",
    "\n",
    "    # Retrieval\n",
    "    retrieved_docs: list[str]  # 검색된 문서들\n",
    "    retrieval_strategy: str  # 사용된 검색 전략\n",
    "\n",
    "    # Generation\n",
    "    answer: str\n",
    "\n",
    "    # Evaluation (RAGAS 점수 저장용)\n",
    "    evaluation_scores: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3973877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Agentic RAG 구현 - Step 2: 핵심 노드 구현\n",
    "# ============================================================================\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2.1 Intent Classification Node\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "class IntentResult(BaseModel):\n",
    "    \"\"\"의도 분류 결과\"\"\"\n",
    "\n",
    "    intent: Literal[\"SEARCH\", \"EXPLAIN\", \"COMPARE\", \"CALCULATE\", \"ANALYZE\"]\n",
    "    confidence: float = Field(ge=0.0, le=1.0, description=\"신뢰도 (0~1)\")\n",
    "    reasoning: str = Field(description=\"분류 근거\")\n",
    "\n",
    "\n",
    "INTENT_PROMPT = \"\"\"사용자 질문의 의도를 다음 5가지 중 하나로 분류하세요:\n",
    "\n",
    "1. SEARCH: 특정 정보를 찾는 질문 (예: \"계약서 제5조 내용은?\")\n",
    "2. EXPLAIN: 개념이나 원리를 설명해달라는 질문 (예: \"리스트 컴프리헨션이란?\")\n",
    "3. COMPARE: 둘 이상을 비교하는 질문 (예: \"A안과 B안의 차이는?\")\n",
    "4. CALCULATE: 계산이 필요한 질문 (예: \"영업이익률은 얼마인가?\")\n",
    "5. ANALYZE: 분석이나 추론이 필요한 질문 (예: \"매출이 감소한 원인은?\")\n",
    "\n",
    "질문: {query}\n",
    "\n",
    "분류 결과를 JSON 형식으로 반환하세요.\"\"\"\n",
    "\n",
    "\n",
    "def intent_classification_node(state: AgenticRAGState) -> dict:\n",
    "    \"\"\"질문 의도 분류 노드\"\"\"\n",
    "    query = state[\"query\"]\n",
    "\n",
    "    print(f\"\\n[Intent Classification] 질문: {query}\")\n",
    "\n",
    "    try:\n",
    "        # LLM으로 의도 분류\n",
    "        structured_llm = llm.with_structured_output(IntentResult)\n",
    "        result = structured_llm.invoke(INTENT_PROMPT.format(query=query))\n",
    "\n",
    "        print(f\"  → 의도: {result.intent} (신뢰도: {result.confidence:.2f})\")\n",
    "        print(f\"  → 근거: {result.reasoning}\")\n",
    "\n",
    "        return {\n",
    "            \"intent\": result.intent,\n",
    "            \"intent_confidence\": result.confidence,\n",
    "            \"intent_reasoning\": result.reasoning,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"의도 분류 실패: {e}\")\n",
    "        return {\n",
    "            \"intent\": \"SEARCH\",\n",
    "            \"intent_confidence\": 0.5,\n",
    "            \"intent_reasoning\": \"기본값 (분류 실패)\",\n",
    "        }\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2.2 Complexity Analysis Node\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "class ComplexityResult(BaseModel):\n",
    "    \"\"\"복잡도 분석 결과\"\"\"\n",
    "\n",
    "    complexity: Literal[\"SIMPLE\", \"MEDIUM\", \"COMPLEX\"] = Field(\n",
    "        description=\"질문의 복잡함을 분석해서 복잡도를 3가지 타입으로 분류합니다\"\n",
    "    )\n",
    "    reasoning: str = Field(description=\"복잡도 판단 근거\")\n",
    "\n",
    "\n",
    "COMPLEXITY_PROMPT = \"\"\"질문의 복잡도를 다음 3가지 중 하나로 분류하세요:\n",
    "\n",
    "1. SIMPLE: 단일 문서에서 직접 답변 가능 (1-hop)\n",
    "   - 예: \"계약 기간은?\" → 계약서 1개 문서만 필요\n",
    "\n",
    "2. MEDIUM: 2-3개 문서를 조합해야 답변 가능 (2-hop)\n",
    "   - 예: \"전년 대비 매출 증가율은?\" → 올해 + 작년 재무제표 필요\n",
    "\n",
    "3. COMPLEX: 4개 이상 문서 + 복잡한 추론 필요 (multi-hop)\n",
    "   - 예: \"3개년 수익성 추이를 분석하고 향후 전망은?\" → 다수 문서 + 추론\n",
    "\n",
    "질문: {query}\n",
    "의도: {intent}\n",
    "\n",
    "복잡도를 판단하고 JSON 형식으로 반환하세요.\"\"\"\n",
    "\n",
    "\n",
    "def complexity_analysis_node(state: AgenticRAGState) -> dict:\n",
    "    \"\"\"복잡도 분석 노드\"\"\"\n",
    "    query = state[\"query\"]\n",
    "    intent = state.get(\"intent\", \"SEARCH\")\n",
    "\n",
    "    print(f\"\\n[Complexity Analysis] 질문: {query}\")\n",
    "\n",
    "    try:\n",
    "        structured_llm = llm.with_structured_output(ComplexityResult)\n",
    "        result = structured_llm.invoke(COMPLEXITY_PROMPT.format(query=query, intent=intent))\n",
    "\n",
    "        print(f\"  → 복잡도: {result.complexity}\")\n",
    "        print(f\"  → 근거: {result.reasoning}\")\n",
    "\n",
    "        return {\n",
    "            \"complexity\": result.complexity,\n",
    "            \"complexity_reasoning\": result.reasoning,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"복잡도 분석 실패: {e}\")\n",
    "        return {\n",
    "            \"complexity\": \"SIMPLE\",\n",
    "            \"complexity_reasoning\": \"기본값 (분석 실패)\",\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e509e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# 2.3 Adaptive Retrieval Node\n",
    "# ----------------------------------------------------------------------------\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "def adaptive_retrieval_node(state: AgenticRAGState) -> dict:\n",
    "    \"\"\"복잡도별 적응형 검색 노드\"\"\"\n",
    "    query = state[\"query\"]\n",
    "    complexity = state.get(\"complexity\", \"SIMPLE\")\n",
    "\n",
    "    print(f\"\\n[Adaptive Retrieval] 복잡도: {complexity}\")\n",
    "\n",
    "    try:\n",
    "        # Qdrant에서 검색\n",
    "        query_vector = embeddings.embed_query(query)\n",
    "\n",
    "        # 복잡도별 검색 전략\n",
    "        if complexity == \"SIMPLE\":\n",
    "            # 단순 검색: top_k=3\n",
    "            top_k = 3\n",
    "            strategy = \"Simple Vector Search\"\n",
    "        elif complexity == \"MEDIUM\":\n",
    "            # 중간 검색: top_k=5\n",
    "            top_k = 5\n",
    "            strategy = \"Extended Vector Search\"\n",
    "        else:  # COMPLEX\n",
    "            # 복잡한 검색: top_k=10\n",
    "            top_k = 10\n",
    "            strategy = \"Multi-hop Vector Search\"\n",
    "\n",
    "        print(f\"  → 전략: {strategy} (top_k={top_k})\")\n",
    "\n",
    "        # Qdrant 검색 실행\n",
    "        search_results = qdrant_client.search(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            query_vector=query_vector,\n",
    "            limit=top_k,\n",
    "        )\n",
    "\n",
    "        # 검색 결과를 텍스트로 변환\n",
    "        retrieved_docs = []\n",
    "        for i, result in enumerate(search_results, 1):\n",
    "            doc_text = result.payload.get(\"text\", result.payload.get(\"content\", \"\"))\n",
    "            if doc_text:\n",
    "                retrieved_docs.append(doc_text)\n",
    "                print(f\"  [{i}] 점수: {result.score:.3f}, 길이: {len(doc_text)} 자\")\n",
    "\n",
    "        if not retrieved_docs:\n",
    "            print(\" 검색 결과 없음 - 샘플 문서 사용\")\n",
    "            retrieved_docs = [\n",
    "                \"이것은 샘플 문서입니다. 실제 Qdrant 컬렉션에 문서가 없어 대체 문서를 사용합니다.\",\n",
    "                \"Notebook 02에서 문서를 먼저 인덱싱하면 실제 검색 결과를 볼 수 있습니다.\",\n",
    "            ]\n",
    "\n",
    "        print(f\"  → 총 {len(retrieved_docs)}개 문서 검색 완료\")\n",
    "\n",
    "        return {\n",
    "            \"retrieved_docs\": retrieved_docs,\n",
    "            \"retrieval_strategy\": strategy,\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" 검색 실패: {e}\")\n",
    "        return {\n",
    "            \"retrieved_docs\": [\"검색 실패로 인한 대체 문서입니다.\"],\n",
    "            \"retrieval_strategy\": \"Fallback\",\n",
    "        }\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2.4 Generation Node\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "GENERATION_PROMPT = \"\"\"당신은 정확하고 신뢰할 수 있는 AI 어시스턴트입니다.\n",
    "\n",
    "주어진 컨텍스트를 **반드시 참고하여** 질문에 답변하세요.\n",
    "\n",
    "**중요 규칙:**\n",
    "1. 컨텍스트에 없는 정보는 절대 만들지 마세요 (환각 금지)\n",
    "2. 컨텍스트만으로 답변이 불가능하면 \"제공된 정보만으로는 답변하기 어렵습니다\"라고 명확히 말하세요\n",
    "3. 답변은 간결하고 명확하게 작성하세요\n",
    "4. 가능하면 컨텍스트의 표현을 그대로 사용하세요\n",
    "\n",
    "질문: {query}\n",
    "\n",
    "컨텍스트:\n",
    "{context}\n",
    "\n",
    "답변:\"\"\"\n",
    "\n",
    "\n",
    "def generation_node(state: AgenticRAGState) -> dict:\n",
    "    \"\"\"답변 생성 노드\"\"\"\n",
    "    query = state[\"query\"]\n",
    "    retrieved_docs = state.get(\"retrieved_docs\", [])\n",
    "\n",
    "    print(\"\\n[Generation] 답변 생성 중...\")\n",
    "\n",
    "    try:\n",
    "        # 컨텍스트 결합\n",
    "        context = \"\\n\\n\".join(\n",
    "            [\n",
    "                f\"[문서 {i + 1}]\\n{doc}\"\n",
    "                for i, doc in enumerate(retrieved_docs[:5])  # 최대 5개\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # LLM으로 답변 생성\n",
    "        prompt = GENERATION_PROMPT.format(query=query, context=context)\n",
    "        response = llm.invoke(prompt)\n",
    "        answer = response.content\n",
    "\n",
    "        print(f\"  → 답변 길이: {len(answer)} 자\")\n",
    "        print(f\"  → 답변 미리보기: {answer[:100]}...\")\n",
    "\n",
    "        return {\"answer\": answer}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠️  생성 실패: {e}\")\n",
    "        return {\"answer\": f\"답변 생성 중 오류가 발생했습니다: {e}\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f8d4163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x131ed97f0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Agentic RAG 구현 - Step 3: LangGraph 그래프 구성\n",
    "# ============================================================================\n",
    "\n",
    "# 그래프 생성\n",
    "agentic_rag_graph = StateGraph(state_schema=AgenticRAGState)\n",
    "\n",
    "# 노드 추가\n",
    "agentic_rag_graph.add_node(\"classify_intent\", intent_classification_node)\n",
    "agentic_rag_graph.add_node(\"analyze_complexity\", complexity_analysis_node)\n",
    "agentic_rag_graph.add_node(\"retrieve\", adaptive_retrieval_node)\n",
    "agentic_rag_graph.add_node(\"generate\", generation_node)\n",
    "\n",
    "# 엣지 정의 (순차적 실행)\n",
    "agentic_rag_graph.set_entry_point(\"classify_intent\")\n",
    "agentic_rag_graph.add_edge(\"classify_intent\", \"analyze_complexity\")\n",
    "agentic_rag_graph.add_edge(\"analyze_complexity\", \"retrieve\")\n",
    "agentic_rag_graph.add_edge(\"retrieve\", \"generate\")\n",
    "agentic_rag_graph.add_edge(\"generate\", END)\n",
    "\n",
    "# 그래프 컴파일\n",
    "agentic_rag_app = agentic_rag_graph.compile()\n",
    "agentic_rag_app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf59d64",
   "metadata": {},
   "source": [
    "### 다양한 질문으로 Agentic RAG 테스트\n",
    "\n",
    "이제 구축한 Agentic RAG 시스템을 다양한 도메인의 질문으로 테스트해봅시다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047fe8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Agentic RAG 테스트 - 혼합 도메인 질문\n",
    "# ============================================================================\n",
    "\n",
    "# 테스트 질문들 (금융/법률/기술 혼합)\n",
    "test_questions = [\n",
    "    {\n",
    "        \"domain\": \"금융\",\n",
    "        \"query\": \"2024년 삼성전자의 영업이익률은 얼마인가?\",\n",
    "        \"expected_complexity\": \"SIMPLE\",\n",
    "        \"expected_intent\": \"CALCULATE\",\n",
    "    },\n",
    "    {\n",
    "        \"domain\": \"법률\",\n",
    "        \"query\": \"근로기준법 제60조에서 정한 연장근로 시간의 상한은?\",\n",
    "        \"expected_complexity\": \"SIMPLE\",\n",
    "        \"expected_intent\": \"SEARCH\",\n",
    "    },\n",
    "    {\n",
    "        \"domain\": \"기술\",\n",
    "        \"query\": \"React 18의 Concurrent Rendering이란 무엇이고, 기존 버전과 어떤 차이가 있나?\",\n",
    "        \"expected_complexity\": \"MEDIUM\",\n",
    "        \"expected_intent\": \"EXPLAIN\",\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Agentic RAG 테스트 시작\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 각 질문에 대해 RAG 실행\n",
    "for i, test_case in enumerate(test_questions, 1):\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"[테스트 {i}/{len(test_questions)}] {test_case['domain']} 도메인\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    print(f\"질문: {test_case['query']}\")\n",
    "    print(f\"예상 복잡도: {test_case['expected_complexity']}\")\n",
    "    print(f\"예상 의도: {test_case['expected_intent']}\")\n",
    "    print()\n",
    "\n",
    "    try:\n",
    "        # Agentic RAG 실행\n",
    "        result = agentic_rag_app.invoke({\"query\": test_case[\"query\"]})\n",
    "\n",
    "        # 결과 출력\n",
    "        print(f\"\\n{'─' * 80}\")\n",
    "        print(f\"실행 결과:\")\n",
    "        print(f\"{'─' * 80}\")\n",
    "        print(f\"✓ 의도: {result.get('intent', 'N/A')} (예상: {test_case['expected_intent']})\")\n",
    "        print(\n",
    "            f\"✓ 복잡도: {result.get('complexity', 'N/A')} (예상: {test_case['expected_complexity']})\"\n",
    "        )\n",
    "        print(f\"✓ 검색 전략: {result.get('retrieval_strategy', 'N/A')}\")\n",
    "        print(f\"✓ 검색된 문서 수: {len(result.get('retrieved_docs', []))}개\")\n",
    "\n",
    "        answer = result.get(\"answer\", \"\")\n",
    "        print(f\"\\n✓ 생성된 답변:\")\n",
    "        print(f\"{answer}\")\n",
    "\n",
    "        # 예측 정확도 체크\n",
    "        correct_intent = result.get(\"intent\") == test_case[\"expected_intent\"]\n",
    "        correct_complexity = result.get(\"complexity\") == test_case[\"expected_complexity\"]\n",
    "\n",
    "        print(f\"\\n✓ 분류 정확도:\")\n",
    "        print(f\"  - 의도 분류: {' 정확' if correct_intent else '❌ 불일치'}\")\n",
    "        print(f\"  - 복잡도 분류: {' 정확' if correct_complexity else '❌ 불일치'}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n 실행 중 오류 발생: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(\"\"\"\n",
    "[관찰 포인트]\n",
    "\n",
    "1. **Intent Classification**\n",
    "   - 각 질문의 의도를 정확히 파악했는가?\n",
    "   - SEARCH/EXPLAIN/CALCULATE 등이 올바르게 분류되었는가?\n",
    "\n",
    "2. **Complexity Analysis**\n",
    "   - 질문의 복잡도를 적절히 판단했는가?\n",
    "   - 단순 질문은 SIMPLE, 비교/추론 질문은 MEDIUM/COMPLEX로 분류되었는가?\n",
    "\n",
    "3. **Adaptive Retrieval**\n",
    "   - 복잡도에 따라 검색 전략이 달라졌는가?\n",
    "   - SIMPLE: top_k=3, MEDIUM: top_k=5, COMPLEX: top_k=10\n",
    "\n",
    "4. **Answer Quality**\n",
    "   - 생성된 답변이 질문에 직접 답하는가?\n",
    "   - 컨텍스트에 충실한 답변인가? (환각 없음)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c21f128",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Agentic RAG Workflow에 RAGAS 평가 추가하기\n",
    "\n",
    "### 3.1 평가 데이터셋 준비\n",
    "\n",
    "RAGAS 평가를 위해서는 다음이 필요합니다:\n",
    "1. **질문 (Question)**: 평가할 질문\n",
    "2. **Ground Truth**: 정답 (참조 답변)\n",
    "3. **생성된 답변 (Answer)**: RAG 시스템이 생성한 답변  \n",
    "4. **검색된 컨텍스트 (Contexts)**: RAG가 검색한 문서들\n",
    "\n",
    "우리는 수동으로 작성한 평가 질문 세트를 사용합니다.  \n",
    "**Q. 실무에서는 수동 / 자동 얼마나 섞어야 할까요?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e97aef3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "EXPLAIN",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# 평가 데이터셋 준비\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 혼합 도메인 평가 질문 세트 (금융/법률/기술)\u001b[39;00m\n\u001b[32m      6\u001b[39m evaluation_questions = [\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# 금융 도메인\u001b[39;00m\n\u001b[32m      8\u001b[39m     EvaluationQuestion(\n\u001b[32m      9\u001b[39m         \u001b[38;5;28mid\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mQ001\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m         question=\u001b[33m\"\u001b[39m\u001b[33mPython에서 리스트 컴프리헨션이란 무엇인가요?\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m         question_type=\u001b[43mQuestionType\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEXPLAIN\u001b[49m,\n\u001b[32m     12\u001b[39m         difficulty=DifficultyLevel.SIMPLE,\n\u001b[32m     13\u001b[39m         ground_truth=\u001b[33m\"\u001b[39m\u001b[33m리스트 컴프리헨션은 기존 리스트를 기반으로 새로운 리스트를 간결하게 생성하는 파이썬 문법입니다. [표현식 for 항목 in 반복가능객체] 형태로 작성되며, 조건을 추가할 수도 있습니다.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     14\u001b[39m         relevant_doc_ids=[\u001b[33m\"\u001b[39m\u001b[33mpython_basics_001\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     15\u001b[39m         metadata={\u001b[33m\"\u001b[39m\u001b[33mdomain\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m기술\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmanual\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m     16\u001b[39m     ),\n\u001b[32m     17\u001b[39m     EvaluationQuestion(\n\u001b[32m     18\u001b[39m         \u001b[38;5;28mid\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mQ002\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     19\u001b[39m         question=\u001b[33m\"\u001b[39m\u001b[33m함수형 프로그래밍의 주요 특징은 무엇인가요?\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     20\u001b[39m         question_type=QuestionType.EXPLAIN,\n\u001b[32m     21\u001b[39m         difficulty=DifficultyLevel.MEDIUM,\n\u001b[32m     22\u001b[39m         ground_truth=\u001b[33m\"\u001b[39m\u001b[33m함수형 프로그래밍의 주요 특징은 불변성(immutability), 순수 함수(pure functions), 고차 함수(higher-order functions), 선언적 프로그래밍 스타일입니다.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m         relevant_doc_ids=[\u001b[33m\"\u001b[39m\u001b[33mfp_basics_001\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfp_basics_002\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     24\u001b[39m         metadata={\u001b[33m\"\u001b[39m\u001b[33mdomain\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m기술\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmanual\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m     25\u001b[39m     ),\n\u001b[32m     26\u001b[39m     EvaluationQuestion(\n\u001b[32m     27\u001b[39m         \u001b[38;5;28mid\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mQ003\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     28\u001b[39m         question=\u001b[33m\"\u001b[39m\u001b[33mRESTful API의 설계 원칙은 무엇인가요?\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     29\u001b[39m         question_type=QuestionType.EXPLAIN,\n\u001b[32m     30\u001b[39m         difficulty=DifficultyLevel.SIMPLE,\n\u001b[32m     31\u001b[39m         ground_truth=\u001b[33m\"\u001b[39m\u001b[33mRESTful API의 주요 설계 원칙은 1) 자원(Resource)의 식별, 2) HTTP 메서드 활용, 3) 무상태성(Stateless), 4) 캐시 가능성, 5) 계층화된 시스템입니다.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     32\u001b[39m         relevant_doc_ids=[\u001b[33m\"\u001b[39m\u001b[33mrest_api_001\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     33\u001b[39m         metadata={\u001b[33m\"\u001b[39m\u001b[33mdomain\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m기술\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmanual\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m     34\u001b[39m     ),\n\u001b[32m     35\u001b[39m ]\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# 평가 데이터셋 생성\u001b[39;00m\n\u001b[32m     38\u001b[39m eval_dataset = EvaluationDataset(\n\u001b[32m     39\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mMixed_Domain_Evaluation_v1\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     40\u001b[39m     description=\u001b[33m\"\u001b[39m\u001b[33m금융/법률/기술 혼합 도메인 평가 데이터셋 (수동 작성)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     47\u001b[39m     },\n\u001b[32m     48\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.14-macos-aarch64-none/lib/python3.11/enum.py:786\u001b[39m, in \u001b[36mEnumType.__getattr__\u001b[39m\u001b[34m(cls, name)\u001b[39m\n\u001b[32m    784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._member_map_[name]\n\u001b[32m    785\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m786\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(name) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: EXPLAIN"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 평가 데이터셋 준비\n",
    "# ============================================================================\n",
    "\n",
    "# 혼합 도메인 평가 질문 세트 (금융/법률/기술)\n",
    "evaluation_questions = [\n",
    "    # 금융 도메인\n",
    "    EvaluationQuestion(\n",
    "        id=\"Q001\",\n",
    "        question=\"Python에서 리스트 컴프리헨션이란 무엇인가요?\",\n",
    "        question_type=QuestionType.EXPLAIN,\n",
    "        difficulty=DifficultyLevel.SIMPLE,\n",
    "        ground_truth=\"리스트 컴프리헨션은 기존 리스트를 기반으로 새로운 리스트를 간결하게 생성하는 파이썬 문법입니다. [표현식 for 항목 in 반복가능객체] 형태로 작성되며, 조건을 추가할 수도 있습니다.\",\n",
    "        relevant_doc_ids=[\"python_basics_001\"],\n",
    "        metadata={\"domain\": \"기술\", \"source\": \"manual\"},\n",
    "    ),\n",
    "    EvaluationQuestion(\n",
    "        id=\"Q002\",\n",
    "        question=\"함수형 프로그래밍의 주요 특징은 무엇인가요?\",\n",
    "        question_type=QuestionType.EXPLAIN,\n",
    "        difficulty=DifficultyLevel.MEDIUM,\n",
    "        ground_truth=\"함수형 프로그래밍의 주요 특징은 불변성(immutability), 순수 함수(pure functions), 고차 함수(higher-order functions), 선언적 프로그래밍 스타일입니다.\",\n",
    "        relevant_doc_ids=[\"fp_basics_001\", \"fp_basics_002\"],\n",
    "        metadata={\"domain\": \"기술\", \"source\": \"manual\"},\n",
    "    ),\n",
    "    EvaluationQuestion(\n",
    "        id=\"Q003\",\n",
    "        question=\"RESTful API의 설계 원칙은 무엇인가요?\",\n",
    "        question_type=QuestionType.EXPLAIN,\n",
    "        difficulty=DifficultyLevel.SIMPLE,\n",
    "        ground_truth=\"RESTful API의 주요 설계 원칙은 1) 자원(Resource)의 식별, 2) HTTP 메서드 활용, 3) 무상태성(Stateless), 4) 캐시 가능성, 5) 계층화된 시스템입니다.\",\n",
    "        relevant_doc_ids=[\"rest_api_001\"],\n",
    "        metadata={\"domain\": \"기술\", \"source\": \"manual\"},\n",
    "    ),\n",
    "]\n",
    "\n",
    "# 평가 데이터셋 생성\n",
    "eval_dataset = EvaluationDataset(\n",
    "    name=\"Mixed_Domain_Evaluation_v1\",\n",
    "    description=\"금융/법률/기술 혼합 도메인 평가 데이터셋 (수동 작성)\",\n",
    "    version=\"1.0.0\",\n",
    "    questions=evaluation_questions,\n",
    "    metadata={\n",
    "        \"creation_method\": \"manual\",\n",
    "        \"num_domains\": 3,\n",
    "        \"author\": \"SDS Class Day2\",\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"\\n평가 데이터셋 준비 완료\")\n",
    "print(f\"  - 총 질문 수: {len(eval_dataset.questions)}개\")\n",
    "print(f\"  - 도메인: {len(set(q.metadata.get('domain') for q in eval_dataset.questions))}개\")\n",
    "\n",
    "# 질문 미리보기\n",
    "print(\"\\n질문 미리보기:\")\n",
    "for q in eval_dataset.questions:\n",
    "    print(f\"  [{q.id}] ({q.metadata.get('domain')}) {q.question[:50]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8cd889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# RAGAS 평가 실행\n",
    "# ============================================================================\n",
    "# RAGAS 평가 결과를 저장할 리스트\n",
    "ragas_results = []\n",
    "\n",
    "# 각 질문에 대해 RAG 실행 및 평가\n",
    "for i, question in enumerate(eval_dataset.questions, 1):\n",
    "    print(f\"\\n[{i}/{len(eval_dataset.questions)}] {question.id}: {question.question[:50]}...\")\n",
    "\n",
    "    try:\n",
    "        # Step 1: Agentic RAG 실행\n",
    "        rag_result = agentic_rag_app.invoke({\"query\": question.question})\n",
    "        answer = rag_result.get(\"answer\", \"\")\n",
    "        contexts = rag_result.get(\"retrieved_docs\", [])\n",
    "\n",
    "        print(f\"  ✓ RAG 실행 완료 ({len(contexts)}개 문서 검색)\")\n",
    "\n",
    "        # Step 2: RAGAS 평가 데이터 생성\n",
    "        sample = SingleTurnSample(\n",
    "            user_input=question.question,\n",
    "            response=answer,\n",
    "            retrieved_contexts=contexts,\n",
    "            reference=question.ground_truth,\n",
    "        )\n",
    "\n",
    "        # Step 3: RAGAS 평가 실행\n",
    "        # 참고: 실제 환경에서는 evaluate()로 배치 평가하는 것이 효율적\n",
    "        # 여기서는 개별 평가 시연\n",
    "        eval_data = EvaluationDataset(samples=[sample])\n",
    "\n",
    "        result = evaluate(\n",
    "            dataset=eval_data,\n",
    "            metrics=[context_precision, context_recall, faithfulness, answer_relevancy],\n",
    "            llm=llm,\n",
    "            embeddings=embeddings,\n",
    "        )\n",
    "\n",
    "        ragas_results.append(\n",
    "            {\n",
    "                \"question_id\": question.id,\n",
    "                \"question\": question.question,\n",
    "                \"answer\": answer,\n",
    "                \"contexts\": contexts,\n",
    "                \"ground_truth\": question.ground_truth,\n",
    "                \"context_precision\": result[\"context_precision\"],\n",
    "                \"context_recall\": result[\"context_recall\"],\n",
    "                \"faithfulness\": result[\"faithfulness\"],\n",
    "                \"answer_relevancy\": result[\"answer_relevancy\"],\n",
    "                \"avg_score\": sum(\n",
    "                    [\n",
    "                        result[\"context_precision\"],\n",
    "                        result[\"context_recall\"],\n",
    "                        result[\"faithfulness\"],\n",
    "                        result[\"answer_relevancy\"],\n",
    "                    ]\n",
    "                )\n",
    "                / 4,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        print(f\"  ✓ RAGAS 평가 완료 (평균: {ragas_results[-1]['avg_score']:.3f})\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" 평가 실패: {e}\")\n",
    "\n",
    "# 전체 평균 계산\n",
    "avg_precision = sum(r[\"context_precision\"] for r in ragas_results) / len(ragas_results)\n",
    "avg_recall = sum(r[\"context_recall\"] for r in ragas_results) / len(ragas_results)\n",
    "avg_faithfulness = sum(r[\"faithfulness\"] for r in ragas_results) / len(ragas_results)\n",
    "avg_relevancy = sum(r[\"answer_relevancy\"] for r in ragas_results) / len(ragas_results)\n",
    "avg_overall = sum(r[\"avg_score\"] for r in ragas_results) / len(ragas_results)\n",
    "\n",
    "print(\"전체 평균 점수:\")\n",
    "print(f\"  • Context Precision  : {avg_precision:.3f}\")\n",
    "print(f\"  • Context Recall     : {avg_recall:.3f}\")\n",
    "print(f\"  • Faithfulness       : {avg_faithfulness:.3f}\")\n",
    "print(f\"  • Answer Relevancy   : {avg_relevancy:.3f}\")\n",
    "print(f\"  • 전체 평균          : {avg_overall:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4af116",
   "metadata": {},
   "source": [
    "## 4. RAGAS 평가 결과 해석하기\n",
    "\n",
    "평가 결과를 분석하고 개선 포인트를 파악합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8188348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Section 4: RAGAS 평가 결과 심층 해석\n",
    "# ============================================================================\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 4.1 전체 평균 점수 해석\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n[전체 평균 점수]\")\n",
    "print(f\"  • Context Precision  : {avg_precision:.3f}\")\n",
    "print(f\"  • Context Recall     : {avg_recall:.3f}\")\n",
    "print(f\"  • Faithfulness       : {avg_faithfulness:.3f}\")\n",
    "print(f\"  • Answer Relevancy   : {avg_relevancy:.3f}\")\n",
    "print(f\"  • 전체 평균          : {avg_overall:.3f}\")\n",
    "\n",
    "# 등급 판정\n",
    "if avg_overall >= 0.85:\n",
    "    grade = \"EXCELLENT - 프로덕션 배포 가능\"\n",
    "elif avg_overall >= 0.70:\n",
    "    grade = \"GOOD - 일부 개선 후 배포 권장\"\n",
    "elif avg_overall >= 0.55:\n",
    "    grade = \"FAIR - 상당한 개선 필요\"\n",
    "else:\n",
    "    grade = \"POOR - 근본적 재설계 필요\"\n",
    "\n",
    "print(f\"\\n전체 평가: {grade}\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 4.2 개별 지표 상세 분석\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "# 각 지표별 해석\n",
    "metrics_analysis = {\n",
    "    \"Context Precision\": {\n",
    "        \"score\": avg_precision,\n",
    "        \"description\": \"검색된 문서의 관련성\",\n",
    "        \"good_threshold\": 0.80,\n",
    "        \"problem\": \"무관한 문서 혼입\",\n",
    "        \"impact\": \"토큰 낭비, 답변 품질 저하\",\n",
    "    },\n",
    "    \"Context Recall\": {\n",
    "        \"score\": avg_recall,\n",
    "        \"description\": \"필요한 정보 검색 정도\",\n",
    "        \"good_threshold\": 0.75,\n",
    "        \"problem\": \"필요한 정보 누락\",\n",
    "        \"impact\": '\"모르겠다\" 답변, 부정확한 추론',\n",
    "    },\n",
    "    \"Faithfulness\": {\n",
    "        \"score\": avg_faithfulness,\n",
    "        \"description\": \"컨텍스트 충실도\",\n",
    "        \"good_threshold\": 0.90,\n",
    "        \"problem\": \"환각 (Hallucination)\",\n",
    "        \"impact\": \"사용자 신뢰 상실, 잘못된 의사결정\",\n",
    "    },\n",
    "    \"Answer Relevancy\": {\n",
    "        \"score\": avg_relevancy,\n",
    "        \"description\": \"질문-답변 일치도\",\n",
    "        \"good_threshold\": 0.80,\n",
    "        \"problem\": \"질문 의도 불일치\",\n",
    "        \"impact\": \"사용자 불만, 재질문 증가\",\n",
    "    },\n",
    "}\n",
    "\n",
    "for metric_name, info in metrics_analysis.items():\n",
    "    print(f\"\\n• {metric_name}: {info['score']:.3f}\")\n",
    "    print(f\"  - 측정 대상: {info['description']}\")\n",
    "\n",
    "    if info[\"score\"] >= info[\"good_threshold\"]:\n",
    "        print(f\"  - 상태: 양호 (임계값 {info['good_threshold']:.2f} 이상)\")\n",
    "    else:\n",
    "        print(f\"  - 상태: 개선 필요 (임계값 {info['good_threshold']:.2f} 미만)\")\n",
    "        print(f\"  - 문제: {info['problem']}\")\n",
    "        print(f\"  - 영향: {info['impact']}\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 4.3 실패 케이스 상세 분석\n",
    "# ----------------------------------------------------------------------------\n",
    "# 점수가 낮은 상위 2개 질문\n",
    "worst_questions = sorted(ragas_results, key=lambda x: x[\"avg_score\"])[:2]\n",
    "\n",
    "for i, result in enumerate(worst_questions, 1):\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"실패 케이스 {i}: {result['question_id']}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    print(\"\\n질문:\")\n",
    "    print(f\"  {result['question']}\")\n",
    "\n",
    "    print(\"\\n점수:\")\n",
    "    print(f\"  - 평균: {result['avg_score']:.3f}\")\n",
    "    print(f\"  - Context Precision: {result['context_precision']:.3f}\")\n",
    "    print(f\"  - Context Recall: {result['context_recall']:.3f}\")\n",
    "    print(f\"  - Faithfulness: {result['faithfulness']:.3f}\")\n",
    "    print(f\"  - Answer Relevancy: {result['answer_relevancy']:.3f}\")\n",
    "\n",
    "    # 가장 낮은 지표 식별\n",
    "    metrics = {\n",
    "        \"Context Precision\": result[\"context_precision\"],\n",
    "        \"Context Recall\": result[\"context_recall\"],\n",
    "        \"Faithfulness\": result[\"faithfulness\"],\n",
    "        \"Answer Relevancy\": result[\"answer_relevancy\"],\n",
    "    }\n",
    "    worst_metric = min(metrics, key=metrics.get)\n",
    "    worst_score = metrics[worst_metric]\n",
    "\n",
    "    print(f\"\\n병목 지표: {worst_metric} ({worst_score:.3f})\")\n",
    "\n",
    "    # 노드별 진단\n",
    "    if \"Precision\" in worst_metric:\n",
    "        problem_node = \"Reranking\"\n",
    "        diagnosis = \"무관한 문서가 많이 혼입됨\"\n",
    "        action = \"• Reranker 모델 추가 (cross-encoder)\\n      • top_k 감소 (10→5)\\n      • MMR 적용\"\n",
    "    elif \"Recall\" in worst_metric:\n",
    "        problem_node = \"Retrieval\"\n",
    "        diagnosis = \"필요한 문서를 충분히 검색하지 못함\"\n",
    "        action = (\n",
    "            \"• top_k 증가 (5→20)\\n      • chunk_overlap 증가 (10%→20%)\\n      • 임베딩 모델 변경\"\n",
    "        )\n",
    "    elif \"Faithfulness\" in worst_metric:\n",
    "        problem_node = \"Generation\"\n",
    "        diagnosis = \"LLM이 환각을 생성함\"\n",
    "        action = \"• 프롬프트 강화 (컨텍스트만 사용)\\n      • Temperature: 0.7→0.0\\n      • Few-shot 예제 추가\"\n",
    "    else:\n",
    "        problem_node = \"Query Transform\"\n",
    "        diagnosis = \"질문 의도를 정확히 파악하지 못함\"\n",
    "        action = \"• HyDE 노드 추가\\n      • Query Rewrite 개선\\n      • Intent Classification 강화\"\n",
    "\n",
    "    print(f\"  → 문제 노드: {problem_node}\")\n",
    "    print(f\"  → 진단: {diagnosis}\")\n",
    "    print(\"  → 권장 액션:\")\n",
    "    print(f\"      {action}\")\n",
    "\n",
    "    # 검색된 컨텍스트 미리보기\n",
    "    print(f\"\\n검색된 컨텍스트: {len(result['contexts'])}개\")\n",
    "    for j, ctx in enumerate(result[\"contexts\"][:2], 1):\n",
    "        preview = ctx[:100].replace(\"\\n\", \" \")\n",
    "        print(f\"  [{j}] {preview}...\")\n",
    "\n",
    "    # 생성된 답변\n",
    "    print(\"\\n생성된 답변:\")\n",
    "    answer_preview = result[\"answer\"][:200].replace(\"\\n\", \" \")\n",
    "    print(f\"  {answer_preview}...\")\n",
    "\n",
    "    # Ground Truth와 비교\n",
    "    print(\"\\nGround Truth:\")\n",
    "    gt_preview = result[\"ground_truth\"][:200].replace(\"\\n\", \" \")\n",
    "    print(f\"  {gt_preview}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407df826",
   "metadata": {},
   "source": [
    "## 5. RAGAS 평가 결과에 따른 개선 방향성 및 전략 수립\n",
    "\n",
    "### 5.1 노드별 개선 액션 매핑\n",
    "\n",
    "RAGAS 지표와 RAG 노드를 매핑하여 자동으로 개선 전략을 수립합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276d0b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Section 5: 자동 개선 계획 생성\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Section 5: 자동 개선 계획 생성 - 노드별 액션 매핑\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from eval.auto_improve import ActionPriority, AutoImprovementEngine\n",
    "from eval.ragas_evaluation import RAGASEvaluationReport\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 5.1 평가 리포트 생성\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n[Step 1] 평가 리포트 생성\")\n",
    "\n",
    "report = RAGASEvaluationReport(\n",
    "    pipeline_name=\"Agentic RAG v1\",\n",
    "    dataset_name=eval_dataset.name,\n",
    "    num_questions=len(ragas_results),\n",
    "    avg_context_precision=avg_precision,\n",
    "    avg_context_recall=avg_recall,\n",
    "    avg_faithfulness=avg_faithfulness,\n",
    "    avg_answer_relevancy=avg_relevancy,\n",
    "    avg_overall=avg_overall,\n",
    "    timestamp=datetime.now().isoformat(),\n",
    "    metadata={\"model\": llm.model_name if hasattr(llm, \"model_name\") else \"unknown\"},\n",
    ")\n",
    "\n",
    "print(f\"  - Pipeline: {report.pipeline_name}\")\n",
    "print(f\"  - 평균 점수: {report.avg_overall:.3f}\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 5.2 자동 개선 엔진으로 개선 계획 생성\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "engine = AutoImprovementEngine()\n",
    "improvement_plan = engine.analyze_and_generate_plan(report)\n",
    "\n",
    "print(f\"  - 총 액션 수: {len(improvement_plan.actions)}개\")\n",
    "print(\n",
    "    f\"  - 예상 개선폭: {improvement_plan.expected_overall_improvement:+.3f} ({improvement_plan.expected_overall_improvement / avg_overall:+.1%})\"\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 5.3 노드-지표-액션 매핑 테이블\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n[Step 3] 노드별 개선 액션 매핑 테이블\")\n",
    "print(f\"{'=' * 80}\")\n",
    "\n",
    "if improvement_plan.actions:\n",
    "    # 노드별 그룹화\n",
    "    from collections import defaultdict\n",
    "\n",
    "    actions_by_node = defaultdict(list)\n",
    "\n",
    "    for action in improvement_plan.actions:\n",
    "        actions_by_node[action.target_node.value].append(action)\n",
    "\n",
    "    print(\"\\n노드별 개선 액션:\")\n",
    "    for node_name, actions in actions_by_node.items():\n",
    "        print(f\"\\n🔹 {node_name.upper()} 노드 ({len(actions)}개 액션)\")\n",
    "\n",
    "        for i, action in enumerate(actions, 1):\n",
    "            priority_emoji = {\n",
    "                \"critical\": \"🔴\",\n",
    "                \"high\": \"🟠\",\n",
    "                \"medium\": \"🟡\",\n",
    "                \"low\": \"🟢\",\n",
    "            }[action.priority.value]\n",
    "\n",
    "            print(f\"\\n  {priority_emoji} [{i}] {action.description}\")\n",
    "            print(f\"      목표 지표: {action.target_metric.value}\")\n",
    "            print(f\"      우선순위: {action.priority.value.upper()}\")\n",
    "            print(f\"      근거: {action.rationale[:80]}...\")\n",
    "            print(f\"      예상 효과: {action.expected_metric_improvement:+.2%}\")\n",
    "            print(\"\\n      파라미터 변경:\")\n",
    "            for key, value in action.parameter_changes.items():\n",
    "                print(f\"        - {key}: {value}\")\n",
    "\n",
    "            print(\"\\n      비용/성능 영향:\")\n",
    "            print(f\"        - 비용 영향: {action.cost_impact}\")\n",
    "            print(f\"        - 지연시간 영향: {action.latency_impact}\")\n",
    "\n",
    "            if action.expected_side_effects:\n",
    "                print(\"\\n      주의사항:\")\n",
    "                for effect in action.expected_side_effects[:2]:\n",
    "                    print(f\"        - {effect}\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 5.4 우선순위별 필터링\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "# CRITICAL + HIGH 우선순위만\n",
    "high_priority_actions = improvement_plan.filter_by_priority(ActionPriority.HIGH)\n",
    "\n",
    "print(f\"\\n최우선 적용 대상 (CRITICAL + HIGH): {len(high_priority_actions)}개\")\n",
    "\n",
    "for i, action in enumerate(high_priority_actions, 1):\n",
    "    print(f\"\\n{i}. {action.description}\")\n",
    "    print(f\"   - 노드: {action.target_node.value}\")\n",
    "    print(f\"   - 지표: {action.target_metric.value}\")\n",
    "    print(f\"   - 예상 효과: {action.expected_metric_improvement:+.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fd4a1e",
   "metadata": {},
   "source": [
    "## 6. RAG Workflow 자동 개선 구조 설계 및 A/B 테스트\n",
    "\n",
    "실제로 개선안을 적용하고 효과를 측정하는 방법을 실습합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056adcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Section 6: RAG Workflow 자동 개선 - A/B 테스트\n",
      "================================================================================\n",
      "\n",
      "[Step 1] Baseline 설정 저장\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'avg_overall' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[Step 1] Baseline 설정 저장\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# 현재 설정을 config_v1으로 저장\u001b[39;00m\n\u001b[32m     16\u001b[39m config_v1 = {\n\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mBaseline (v1)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     18\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mretrieval\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m     19\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtop_k\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m3\u001b[39m,  \u001b[38;5;66;03m# SIMPLE 기준\u001b[39;00m\n\u001b[32m     20\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msearch_strategy\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mvector_search\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     21\u001b[39m     },\n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgeneration\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m     23\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0.3\u001b[39m,\n\u001b[32m     24\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m4096\u001b[39m,\n\u001b[32m     25\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msystem_prompt\u001b[39m\u001b[33m\"\u001b[39m: GENERATION_PROMPT,\n\u001b[32m     26\u001b[39m     },\n\u001b[32m     27\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mavg_score\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mavg_overall\u001b[49m,\n\u001b[32m     29\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m\"\u001b[39m: datetime.now().isoformat(),\n\u001b[32m     30\u001b[39m     },\n\u001b[32m     31\u001b[39m }\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✓ Baseline 설정 저장 완료\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  - Retrieval top_k: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_v1[\u001b[33m'\u001b[39m\u001b[33mretrieval\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mtop_k\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'avg_overall' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Section 6: RAG Workflow 자동 개선 구조 - A/B 테스트\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Section 6: RAG Workflow 자동 개선 - A/B 테스트\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 6.1 Baseline 설정 저장\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n[Step 1] Baseline 설정 저장\")\n",
    "\n",
    "# 현재 설정을 config_v1으로 저장\n",
    "config_v1 = {\n",
    "    \"name\": \"Baseline (v1)\",\n",
    "    \"retrieval\": {\n",
    "        \"top_k\": 3,  # SIMPLE 기준\n",
    "        \"search_strategy\": \"vector_search\",\n",
    "    },\n",
    "    \"generation\": {\n",
    "        \"temperature\": 0.3,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"system_prompt\": GENERATION_PROMPT,\n",
    "    },\n",
    "    \"metadata\": {\n",
    "        \"avg_score\": avg_overall,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"✓ Baseline 설정 저장 완료\")\n",
    "print(f\"  - Retrieval top_k: {config_v1['retrieval']['top_k']}\")\n",
    "print(f\"  - Generation temperature: {config_v1['generation']['temperature']}\")\n",
    "print(f\"  - Baseline 점수: {config_v1['metadata']['avg_score']:.3f}\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 6.2 개선안 적용 (config_v2 생성)\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n[Step 2] 개선안 적용\")\n",
    "\n",
    "# 최우선 액션들을 적용한 새로운 설정\n",
    "config_v2 = {\n",
    "    \"name\": \"Improved (v2)\",\n",
    "    \"retrieval\": {\n",
    "        \"top_k\": 10,  # Context Recall 개선: 3 → 10\n",
    "        \"search_strategy\": \"hybrid_search\",  # Context Precision 개선\n",
    "    },\n",
    "    \"generation\": {\n",
    "        \"temperature\": 0.0,  # Faithfulness 개선: 0.3 → 0.0\n",
    "        \"max_tokens\": 4096,\n",
    "        \"system_prompt\": \"\"\"당신은 정확하고 신뢰할 수 있는 AI 어시스턴트입니다.\n",
    "\n",
    "**중요 규칙:**\n",
    "1. 제공된 정보에 없는 정보는 절대 만들지 마세요 (환각 금지)\n",
    "2. 컨텍스트만으로 답변이 불가능하면 \"제공된 정보만으로는 답변하기 어렵습니다\"라고 명확히 말하세요\n",
    "3. 답변은 간결하고 명확하게 작성하세요\n",
    "4. 가능하면 컨텍스트의 표현을 그대로 사용하세요\n",
    "\n",
    "질문: {query}\n",
    "\n",
    "컨텍스트:\n",
    "{context}\n",
    "\n",
    "답변:\"\"\",  # 프롬프트 강화\n",
    "    },\n",
    "    \"metadata\": {\n",
    "        \"improvements_applied\": [\n",
    "            \"top_k 증가 (3→10) for Context Recall\",\n",
    "            \"Temperature 감소 (0.3→0.0) for Faithfulness\",\n",
    "            \"프롬프트 강화 for Faithfulness\",\n",
    "        ],\n",
    "        \"expected_improvement\": improvement_plan.expected_overall_improvement,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\n",
    "    f\"  - Retrieval top_k: {config_v2['retrieval']['top_k']} (↑ {config_v2['retrieval']['top_k'] - config_v1['retrieval']['top_k']})\"\n",
    ")\n",
    "print(\n",
    "    f\"  - Generation temperature: {config_v2['generation']['temperature']} (↓ {config_v1['generation']['temperature'] - config_v2['generation']['temperature']})\"\n",
    ")\n",
    "print(f\"  - 적용된 개선 사항: {len(config_v2['metadata']['improvements_applied'])}개\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 6.3 A/B 테스트 시뮬레이션\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n[Step 3] A/B 테스트 시뮬레이션\")\n",
    "print(f\"{'─' * 80}\")\n",
    "\n",
    "print(\"\"\"\n",
    "💡 실제 A/B 테스트 프로세스:\n",
    "\n",
    "1. **동일 데이터셋 사용**\n",
    "   - Baseline (v1)과 Improved (v2)를 동일한 평가 질문으로 테스트\n",
    "   - 공정한 비교를 위해 동일한 조건 유지\n",
    "\n",
    "2. **병렬 실행**\n",
    "   - 두 설정을 동시에 실행하여 시간 요인 제거\n",
    "   - 각각 독립적인 RAG 파이프라인 생성\n",
    "\n",
    "3. **지표별 비교**\n",
    "   - Context Precision, Recall, Faithfulness, Relevancy 개별 비교\n",
    "   - 통계적 유의성 검증 (t-test 등)\n",
    "\n",
    "4. **비용/성능 분석**\n",
    "   - 토큰 사용량 비교\n",
    "   - 응답 시간 비교\n",
    "   - 비용 대비 효과 분석\n",
    "\n",
    "5. **배포 결정**\n",
    "   - 개선폭 > 5%p AND 부작용 없음 → 배포\n",
    "   - 개선폭 < 5%p → 추가 개선 시도\n",
    "   - 부작용 있음 → 롤백 후 재검토\n",
    "\"\"\")\n",
    "\n",
    "# Context Recall 개선 (+15%p 예상)\n",
    "expected_recall_v2 = min(1.0, avg_recall + 0.15)\n",
    "\n",
    "# Faithfulness 개선 (+10%p 예상)\n",
    "expected_faithfulness_v2 = min(1.0, avg_faithfulness + 0.10)\n",
    "\n",
    "# Context Precision은 유지 또는 소폭 감소 가능 (top_k 증가로 인해)\n",
    "expected_precision_v2 = max(0, avg_precision - 0.03)\n",
    "\n",
    "# Answer Relevancy는 유지\n",
    "expected_relevancy_v2 = avg_relevancy\n",
    "\n",
    "# 전체 평균\n",
    "expected_overall_v2 = (\n",
    "    expected_precision_v2 + expected_recall_v2 + expected_faithfulness_v2 + expected_relevancy_v2\n",
    ") / 4\n",
    "\n",
    "print(\"\\nBaseline (v1) vs Improved (v2) 예상 점수:\")\n",
    "print(f\"{'─' * 80}\")\n",
    "print(f\"{'지표':<20} {'Baseline':>12} {'Improved':>12} {'변화량':>12}\")\n",
    "print(f\"{'─' * 80}\")\n",
    "print(\n",
    "    f\"{'Context Precision':<20} {avg_precision:>12.3f} {expected_precision_v2:>12.3f} {expected_precision_v2 - avg_precision:>+12.3f}\"\n",
    ")\n",
    "print(\n",
    "    f\"{'Context Recall':<20} {avg_recall:>12.3f} {expected_recall_v2:>12.3f} {expected_recall_v2 - avg_recall:>+12.3f}\"\n",
    ")\n",
    "print(\n",
    "    f\"{'Faithfulness':<20} {avg_faithfulness:>12.3f} {expected_faithfulness_v2:>12.3f} {expected_faithfulness_v2 - avg_faithfulness:>+12.3f}\"\n",
    ")\n",
    "print(\n",
    "    f\"{'Answer Relevancy':<20} {avg_relevancy:>12.3f} {expected_relevancy_v2:>12.3f} {expected_relevancy_v2 - avg_relevancy:>+12.3f}\"\n",
    ")\n",
    "print(f\"{'─' * 80}\")\n",
    "print(\n",
    "    f\"{'전체 평균':<20} {avg_overall:>12.3f} {expected_overall_v2:>12.3f} {expected_overall_v2 - avg_overall:>+12.3f}\"\n",
    ")\n",
    "print(f\"{'=' * 80}\")\n",
    "\n",
    "# 개선 효과 평가\n",
    "improvement_pct = ((expected_overall_v2 - avg_overall) / avg_overall) * 100\n",
    "\n",
    "print(\"\\n개선 효과:\")\n",
    "print(f\"  - 절대 개선폭: {expected_overall_v2 - avg_overall:+.3f}점\")\n",
    "print(f\"  - 상대 개선률: {improvement_pct:+.1f}%\")\n",
    "\n",
    "if improvement_pct >= 5:\n",
    "    print(\"  - 판정:  배포 권장 (5% 이상 개선)\")\n",
    "elif improvement_pct >= 2:\n",
    "    print(\"  - 판정: 🟡 조건부 배포 (2-5% 개선, 추가 검증 필요)\")\n",
    "else:\n",
    "    print(\"  - 판정: ❌ 배포 보류 (2% 미만 개선, 추가 개선 필요)\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 6.4 실제 적용 시 주의사항\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "\"\"\"\n",
    "1. 카나리 배포 (Canary Deployment)\n",
    "   - 특정 사용자 그룹에게만 먼저 적용\n",
    "   - 내부 테스터 → 파워 유저 → 일반 사용자\n",
    "\n",
    "2. 모니터링 지표\n",
    "   - RAGAS 점수 (주기적 평가)\n",
    "   - 사용자 만족도 (피드백 점수)\n",
    "   - 응답 시간 (지연시간 증가 확인)\n",
    "   - 오류율 (환각 발생 빈도)\n",
    "\n",
    "3. 롤백 계획\n",
    "   - 1분 내 롤백 가능한 구조\n",
    "   - 이전 Configuration 으로 즉시 복원 가능하도록\n",
    "   - 롤백 시나리오 사전 테스트\n",
    "\n",
    "4. 지속적 개선\n",
    "   - 주 1회 RAGAS 평가\n",
    "   - 신규 실패 케이스 수집\n",
    "   - 분기별 대규모 개선\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0767446",
   "metadata": {},
   "source": [
    "## 7. Ground Truth 데이터셋 구축 실전 가이드\n",
    "\n",
    "### 7.1 3가지 데이터셋 구축 방법\n",
    "\n",
    "실무에서 활용 가능한 3가지 Ground Truth 구축 방법을 실습합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a509515e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_builder\n"
     ]
    }
   ],
   "source": [
    "\"\"\"평가 데이터셋 구축 프레임워크.\n",
    "\n",
    "실무에서 RAG 시스템을 평가하기 위한 데이터셋을 구축하는 3가지 방법을 제공합니다:\n",
    "1. 실제 사용자 질문 수집 (Production 로그 기반)\n",
    "2. 도메인 전문가 인터뷰 (SME - Subject Matter Expert)\n",
    "3. LLM 기반 합성 데이터 생성 + 검증\n",
    "\n",
    "References:\n",
    "- Anthropic: \"Building Effective Agents\" - Evaluation Best Practices\n",
    "- OpenAI: \"Evals\" Framework\n",
    "- DeepEval: Dataset Generation Patterns\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "from typing import Any, Literal\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "logger = print(\"dataset_builder\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 데이터 모델 정의\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "class QuestionType(str, Enum):\n",
    "    \"\"\"질문 유형 분류.\n",
    "\n",
    "    실무 가이드:\n",
    "    - FACTUAL: 단순 사실 확인 (예: \"2024년 매출액은?\")\n",
    "    - REASONING: 추론 필요 (예: \"매출 증가 원인은?\")\n",
    "    - COMPARISON: 비교/대조 (예: \"전년 대비 차이는?\")\n",
    "    - CALCULATION: 계산 필요 (예: \"영업이익률은?\")\n",
    "    - AGGREGATION: 여러 정보 종합 (예: \"주요 리스크 요인들은?\")\n",
    "    \"\"\"\n",
    "\n",
    "    FACTUAL = \"factual\"\n",
    "    REASONING = \"reasoning\"\n",
    "    COMPARISON = \"comparison\"\n",
    "    EXPLAIN = \"explain\"\n",
    "    CALCULATION = \"calculation\"\n",
    "    AGGREGATION = \"aggregation\"\n",
    "\n",
    "\n",
    "class DifficultyLevel(str, Enum):\n",
    "    \"\"\"난이도 레벨.\n",
    "\n",
    "    - SIMPLE: 단일 문서 내 직접 답변 가능 (1-hop)\n",
    "    - MEDIUM: 2-3개 문서 조합 필요 (2-hop)\n",
    "    - COMPLEX: 4개 이상 문서 + 복잡한 추론 (multi-hop)\n",
    "    \"\"\"\n",
    "\n",
    "    SIMPLE = \"simple\"\n",
    "    MEDIUM = \"medium\"\n",
    "    COMPLEX = \"complex\"\n",
    "\n",
    "\n",
    "class EvaluationQuestion(BaseModel):\n",
    "    \"\"\"평가용 질문 단위.\"\"\"\n",
    "\n",
    "    id: str = Field(description=\"질문 고유 ID (예: Q001)\")\n",
    "    question: str = Field(description=\"사용자 질문\")\n",
    "    question_type: QuestionType = Field(description=\"질문 유형\")\n",
    "    difficulty: DifficultyLevel = Field(description=\"난이도\")\n",
    "\n",
    "    ground_truth: str = Field(description=\"정답 (Ground Truth)\")\n",
    "    relevant_doc_ids: list[str] = Field(\n",
    "        default_factory=list, description=\"관련 문서 ID 리스트 (Context Recall 계산용)\"\n",
    "    )\n",
    "\n",
    "    metadata: dict[str, Any] = Field(\n",
    "        default_factory=dict, description=\"추가 메타데이터 (도메인, 작성자, 검증 상태 등)\"\n",
    "    )\n",
    "\n",
    "\n",
    "class EvaluationDataset(BaseModel):\n",
    "    \"\"\"평가 데이터셋 전체 구조.\"\"\"\n",
    "\n",
    "    name: str = Field(description=\"데이터셋 이름\")\n",
    "    description: str = Field(description=\"데이터셋 설명\")\n",
    "    version: str = Field(default=\"1.0.0\")\n",
    "\n",
    "    questions: list[EvaluationQuestion] = Field(default_factory=list)\n",
    "\n",
    "    metadata: dict[str, Any] = Field(\n",
    "        default_factory=dict, description=\"데이터셋 메타데이터 (생성 방법, 검증자 등)\"\n",
    "    )\n",
    "\n",
    "    def save_to_json(self, path: Path) -> None:\n",
    "        \"\"\"JSON 파일로 저장.\"\"\"\n",
    "        path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "            import json\n",
    "\n",
    "            data = self.model_dump()\n",
    "            f.write(json.dumps(data, indent=2, ensure_ascii=False))\n",
    "        logger.info(f\"Saved dataset to {path}\")\n",
    "\n",
    "    @classmethod\n",
    "    def load_from_json(cls, path: Path) -> EvaluationDataset:\n",
    "        \"\"\"JSON 파일에서 로드.\"\"\"\n",
    "        with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        return cls(**data)\n",
    "\n",
    "    def get_questions_by_type(self, question_type: QuestionType) -> list[EvaluationQuestion]:\n",
    "        \"\"\"특정 유형의 질문만 필터링.\"\"\"\n",
    "        return [q for q in self.questions if q.question_type == question_type]\n",
    "\n",
    "    def get_questions_by_difficulty(self, difficulty: DifficultyLevel) -> list[EvaluationQuestion]:\n",
    "        \"\"\"특정 난이도의 질문만 필터링.\"\"\"\n",
    "        return [q for q in self.questions if q.difficulty == difficulty]\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# LLM 기반 합성 데이터 생성\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "class SyntheticQuestion(BaseModel):\n",
    "    \"\"\"LLM이 생성한 질문.\"\"\"\n",
    "\n",
    "    question: str = Field(description=\"생성된 질문\")\n",
    "    question_type: QuestionType = Field(description=\"질문 유형\")\n",
    "    difficulty: DifficultyLevel = Field(description=\"난이도\")\n",
    "    ground_truth: str = Field(description=\"예상 정답\")\n",
    "    reasoning: str = Field(description=\"이 질문을 생성한 이유/의도\")\n",
    "\n",
    "\n",
    "class SyntheticDatasetGenerator:\n",
    "    \"\"\"LLM 기반 합성 데이터셋 생성기.\n",
    "\n",
    "    실무 노하우:\n",
    "    1. 실제 문서에서 샘플링한 컨텍스트 기반으로 생성\n",
    "    2. 다양한 난이도와 질문 유형 골고루 생성\n",
    "    3. Ground Truth는 문서 내용 기반으로 검증 가능하게\n",
    "    4. 생성 후 반드시 도메인 전문가 검증 필요\n",
    "    \"\"\"\n",
    "\n",
    "    GENERATION_PROMPT = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"당신은 RAG 시스템 평가를 위한 고품질 질문을 생성하는 전문가입니다.\n",
    "\n",
    "주어진 문서 컨텍스트를 읽고, 다음 기준에 맞는 평가 질문을 생성하세요:\n",
    "\n",
    "**질문 유형:**\n",
    "- factual: 단순 사실 확인\n",
    "- reasoning: 추론이 필요한 질문\n",
    "- comparison: 비교/대조\n",
    "- calculation: 계산이 필요한 질문\n",
    "- aggregation: 여러 정보를 종합해야 하는 질문\n",
    "\n",
    "**난이도:**\n",
    "- simple: 주어진 컨텍스트에서 직접 답변 가능\n",
    "- medium: 컨텍스트의 2-3개 부분을 조합해야 답변 가능\n",
    "- complex: 깊은 추론과 여러 정보 종합 필요\n",
    "\n",
    "**중요:**\n",
    "- Ground Truth는 주어진 컨텍스트에서 직접 추출 가능해야 함\n",
    "- 질문은 명확하고 구체적이어야 함\n",
    "- 실제 사용자가 물을 법한 자연스러운 질문이어야 함\n",
    "\n",
    "{format_instructions}\"\"\",\n",
    "            ),\n",
    "            (\n",
    "                \"user\",\n",
    "                \"\"\"문서 컨텍스트:\n",
    "---\n",
    "{context}\n",
    "---\n",
    "\n",
    "요청 사항:\n",
    "- 질문 유형: {question_type}\n",
    "- 난이도: {difficulty}\n",
    "\n",
    "위 컨텍스트를 기반으로 고품질 평가 질문 1개를 생성하세요.\"\"\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    def __init__(self, llm: BaseChatModel):\n",
    "        \"\"\"초기화.\n",
    "\n",
    "        Args:\n",
    "            llm: 질문 생성에 사용할 LLM\n",
    "        \"\"\"\n",
    "        self.llm = llm\n",
    "        self.parser = PydanticOutputParser(pydantic_object=SyntheticQuestion)\n",
    "\n",
    "    def generate_question(\n",
    "        self,\n",
    "        context: str,\n",
    "        question_type: QuestionType,\n",
    "        difficulty: DifficultyLevel,\n",
    "    ) -> SyntheticQuestion:\n",
    "        \"\"\"단일 질문 생성.\n",
    "\n",
    "        Args:\n",
    "            context: 문서 컨텍스트\n",
    "            question_type: 생성할 질문 유형\n",
    "            difficulty: 난이도\n",
    "\n",
    "        Returns:\n",
    "            생성된 질문\n",
    "        \"\"\"\n",
    "        prompt = self.GENERATION_PROMPT.format_messages(\n",
    "            context=context,\n",
    "            question_type=question_type.value,\n",
    "            difficulty=difficulty.value,\n",
    "            format_instructions=self.parser.get_format_instructions(),\n",
    "        )\n",
    "\n",
    "        response = self.llm.invoke(prompt)\n",
    "        return self.parser.parse(response.content)\n",
    "\n",
    "    def generate_dataset(\n",
    "        self,\n",
    "        documents: list[Document],\n",
    "        num_questions_per_type: int = 2,\n",
    "        num_questions_per_difficulty: int = 3,\n",
    "    ) -> EvaluationDataset:\n",
    "        \"\"\"문서 집합으로부터 데이터셋 생성.\n",
    "\n",
    "        Args:\n",
    "            documents: 소스 문서 리스트\n",
    "            num_questions_per_type: 각 질문 유형당 생성할 개수\n",
    "            num_questions_per_difficulty: 각 난이도당 생성할 개수\n",
    "\n",
    "        Returns:\n",
    "            생성된 평가 데이터셋\n",
    "        \"\"\"\n",
    "        dataset = EvaluationDataset(\n",
    "            name=\"synthetic_evaluation_dataset\",\n",
    "            description=\"LLM 기반 자동 생성된 평가 데이터셋\",\n",
    "            metadata={\n",
    "                \"generation_method\": \"llm_synthetic\",\n",
    "                \"llm_model\": getattr(self.llm, \"model_name\", \"unknown\"),\n",
    "                \"num_source_documents\": len(documents),\n",
    "            },\n",
    "        )\n",
    "\n",
    "        question_id = 1\n",
    "\n",
    "        # 난이도별로 고르게 분포\n",
    "        for difficulty in DifficultyLevel:\n",
    "            for question_type in QuestionType:\n",
    "                for _ in range(num_questions_per_type):\n",
    "                    try:\n",
    "                        # 랜덤하게 문서 선택\n",
    "                        import random\n",
    "\n",
    "                        doc = random.choice(documents)\n",
    "\n",
    "                        synthetic_q = self.generate_question(\n",
    "                            context=doc.page_content,\n",
    "                            question_type=question_type,\n",
    "                            difficulty=difficulty,\n",
    "                        )\n",
    "\n",
    "                        eval_q = EvaluationQuestion(\n",
    "                            id=f\"Q{question_id:03d}\",\n",
    "                            question=synthetic_q.question,\n",
    "                            question_type=synthetic_q.question_type,\n",
    "                            difficulty=synthetic_q.difficulty,\n",
    "                            ground_truth=synthetic_q.ground_truth,\n",
    "                            relevant_doc_ids=[doc.metadata.get(\"id\", f\"doc_{question_id}\")],\n",
    "                            metadata={\n",
    "                                \"generation_method\": \"llm_synthetic\",\n",
    "                                \"reasoning\": synthetic_q.reasoning,\n",
    "                            },\n",
    "                        )\n",
    "\n",
    "                        dataset.questions.append(eval_q)\n",
    "                        question_id += 1\n",
    "\n",
    "                        logger.info(\n",
    "                            f\"Generated Q{question_id - 1:03d}: \"\n",
    "                            f\"{question_type.value}/{difficulty.value}\"\n",
    "                        )\n",
    "\n",
    "                    except Exception as e:\n",
    "                        logger.warning(f\"Failed to generate question: {e}\")\n",
    "                        continue\n",
    "\n",
    "        return dataset\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 도메인 전문가 인터뷰 기반 데이터셋 구축\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "class SMEDatasetBuilder:\n",
    "    \"\"\"도메인 전문가(SME) 인터뷰 기반 데이터셋 구축 도구.\n",
    "\n",
    "    실무 프로세스:\n",
    "    1. 도메인 전문가에게 실제 업무에서 자주 하는 질문 수집\n",
    "    2. 각 질문에 대한 정확한 답변과 근거 문서 요청\n",
    "    3. 난이도와 질문 유형 분류\n",
    "    4. 검증 프로세스: 다른 전문가가 답변 확인\n",
    "\n",
    "    템플릿 제공:\n",
    "    - Excel/CSV 템플릿으로 전문가가 직접 작성 가능\n",
    "    - 작성 가이드라인 문서 제공\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def create_template() -> dict[str, Any]:\n",
    "        \"\"\"전문가용 템플릿 생성.\n",
    "\n",
    "        Returns:\n",
    "            템플릿 구조 (CSV/Excel 변환 가능)\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"columns\": [\n",
    "                \"질문 ID\",\n",
    "                \"질문\",\n",
    "                \"질문 유형 (factual/reasoning/comparison/calculation/aggregation)\",\n",
    "                \"난이도 (simple/medium/complex)\",\n",
    "                \"정답\",\n",
    "                \"관련 문서 ID (쉼표로 구분)\",\n",
    "                \"비고\",\n",
    "            ],\n",
    "            \"example_rows\": [\n",
    "                {\n",
    "                    \"질문 ID\": \"Q001\",\n",
    "                    \"질문\": \"2024년 연결 매출액은 얼마입니까?\",\n",
    "                    \"질문 유형\": \"factual\",\n",
    "                    \"난이도\": \"simple\",\n",
    "                    \"정답\": \"500억원\",\n",
    "                    \"관련 문서 ID\": \"재무제표_2024_손익계산서\",\n",
    "                    \"비고\": \"감사보고서 3페이지 참조\",\n",
    "                },\n",
    "                {\n",
    "                    \"질문 ID\": \"Q002\",\n",
    "                    \"질문\": \"전년 대비 영업이익률이 개선된 주요 원인은 무엇입니까?\",\n",
    "                    \"질문 유형\": \"reasoning\",\n",
    "                    \"난이도\": \"medium\",\n",
    "                    \"정답\": \"원가율 3%p 개선 및 판관비율 2%p 절감\",\n",
    "                    \"관련 문서 ID\": \"경영진분석_2024, 재무제표_2024_손익계산서\",\n",
    "                    \"비고\": \"여러 문서 종합 필요\",\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_from_csv(csv_path: Path) -> EvaluationDataset:\n",
    "        \"\"\"CSV 파일에서 데이터셋 파싱.\n",
    "\n",
    "        Args:\n",
    "            csv_path: CSV 파일 경로\n",
    "\n",
    "        Returns:\n",
    "            파싱된 평가 데이터셋\n",
    "        \"\"\"\n",
    "        import csv\n",
    "\n",
    "        dataset = EvaluationDataset(\n",
    "            name=csv_path.stem,\n",
    "            description=\"도메인 전문가 인터뷰 기반 데이터셋\",\n",
    "            metadata={\n",
    "                \"generation_method\": \"sme_interview\",\n",
    "                \"source_file\": str(csv_path),\n",
    "            },\n",
    "        )\n",
    "\n",
    "        with csv_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                try:\n",
    "                    question = EvaluationQuestion(\n",
    "                        id=row[\"질문 ID\"],\n",
    "                        question=row[\"질문\"],\n",
    "                        question_type=QuestionType(row[\"질문 유형\"]),\n",
    "                        difficulty=DifficultyLevel(row[\"난이도\"]),\n",
    "                        ground_truth=row[\"정답\"],\n",
    "                        relevant_doc_ids=[\n",
    "                            doc_id.strip() for doc_id in row[\"관련 문서 ID\"].split(\",\")\n",
    "                        ],\n",
    "                        metadata={\"remarks\": row.get(\"비고\", \"\")},\n",
    "                    )\n",
    "                    dataset.questions.append(question)\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Failed to parse row {row}: {e}\")\n",
    "                    continue\n",
    "\n",
    "        logger.info(f\"Loaded {len(dataset.questions)} questions from {csv_path}\")\n",
    "        return dataset\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 실제 사용자 질문 수집\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "class ProductionLogAnalyzer:\n",
    "    \"\"\"프로덕션 로그에서 사용자 질문 추출.\n",
    "\n",
    "    실무 시나리오:\n",
    "    - Chatbot 로그에서 자주 묻는 질문 추출\n",
    "    - 답변 실패 케이스 우선 수집 (개선 필요 영역)\n",
    "    - 사용자 만족도 낮은 질문 우선 (피드백 기반)\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_from_logs(\n",
    "        log_file: Path,\n",
    "        min_frequency: int = 3,\n",
    "    ) -> list[dict[str, Any]]:\n",
    "        \"\"\"로그 파일에서 질문 추출.\n",
    "\n",
    "        Args:\n",
    "            log_file: 로그 파일 경로\n",
    "            min_frequency: 최소 등장 빈도\n",
    "\n",
    "        Returns:\n",
    "            추출된 질문 리스트\n",
    "        \"\"\"\n",
    "        # 실제 구현은 로그 포맷에 따라 달라짐\n",
    "        # 여기서는 예시 구조만 제공\n",
    "        questions = []\n",
    "\n",
    "        # TODO: 실제 로그 파싱 로직\n",
    "        # - 질문 추출\n",
    "        # - 빈도 계산\n",
    "        # - 답변 성공/실패 분석\n",
    "        # - 사용자 만족도 추출\n",
    "\n",
    "        return questions\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 데이터셋 검증 도구\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "class DatasetValidator:\n",
    "    \"\"\"데이터셋 품질 검증 도구.\n",
    "\n",
    "    검증 항목:\n",
    "    1. 균형성: 질문 유형/난이도가 고르게 분포되어 있는가\n",
    "    2. 완성도: Ground Truth와 관련 문서 ID가 모두 있는가\n",
    "    3. 명확성: 질문이 모호하지 않은가\n",
    "    4. 검증 가능성: Ground Truth가 문서에서 확인 가능한가\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset: EvaluationDataset):\n",
    "        \"\"\"초기화.\n",
    "\n",
    "        Args:\n",
    "            dataset: 검증할 데이터셋\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def validate(self) -> dict[str, Any]:\n",
    "        \"\"\"데이터셋 검증.\n",
    "\n",
    "        Returns:\n",
    "            검증 결과 리포트\n",
    "        \"\"\"\n",
    "        report = {\n",
    "            \"total_questions\": len(self.dataset.questions),\n",
    "            \"completeness\": self._check_completeness(),\n",
    "            \"balance\": self._check_balance(),\n",
    "            \"issues\": [],\n",
    "        }\n",
    "\n",
    "        # 완성도 체크\n",
    "        for q in self.dataset.questions:\n",
    "            if not q.ground_truth:\n",
    "                report[\"issues\"].append(f\"{q.id}: Ground Truth 누락\")\n",
    "            if not q.relevant_doc_ids:\n",
    "                report[\"issues\"].append(f\"{q.id}: 관련 문서 ID 누락\")\n",
    "\n",
    "        return report\n",
    "\n",
    "    def _check_completeness(self) -> float:\n",
    "        \"\"\"완성도 점수 (0~1).\"\"\"\n",
    "        if not self.dataset.questions:\n",
    "            return 0.0\n",
    "\n",
    "        complete = sum(1 for q in self.dataset.questions if q.ground_truth and q.relevant_doc_ids)\n",
    "        return complete / len(self.dataset.questions)\n",
    "\n",
    "    def _check_balance(self) -> dict[str, Any]:\n",
    "        \"\"\"균형성 체크.\"\"\"\n",
    "        type_counts = {}\n",
    "        difficulty_counts = {}\n",
    "\n",
    "        for q in self.dataset.questions:\n",
    "            type_counts[q.question_type] = type_counts.get(q.question_type, 0) + 1\n",
    "            difficulty_counts[q.difficulty] = difficulty_counts.get(q.difficulty, 0) + 1\n",
    "\n",
    "        return {\n",
    "            \"question_types\": type_counts,\n",
    "            \"difficulties\": difficulty_counts,\n",
    "        }\n",
    "\n",
    "    def print_report(self) -> None:\n",
    "        \"\"\"검증 리포트 출력.\"\"\"\n",
    "        report = self.validate()\n",
    "\n",
    "        print(\"=\" * 60)\n",
    "        print(\"📊 데이터셋 검증 리포트\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"총 질문 수: {report['total_questions']}\")\n",
    "        print(f\"완성도: {report['completeness']:.1%}\")\n",
    "        print()\n",
    "        print(\"질문 유형 분포:\")\n",
    "        for qtype, count in report[\"balance\"][\"question_types\"].items():\n",
    "            print(f\"  - {qtype}: {count}개\")\n",
    "        print()\n",
    "        print(\"난이도 분포:\")\n",
    "        for diff, count in report[\"balance\"][\"difficulties\"].items():\n",
    "            print(f\"  - {diff}: {count}개\")\n",
    "\n",
    "        if report[\"issues\"]:\n",
    "            print()\n",
    "            print(\"⚠️ 발견된 문제:\")\n",
    "            for issue in report[\"issues\"]:\n",
    "                print(f\"  - {issue}\")\n",
    "\n",
    "        print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3812acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[방법 1] LLM 기반 합성 데이터 생성\n",
      "================================================================================\n",
      "\n",
      "⚙️  적용 시나리오:\n",
      "- 초기 프로토타입 개발 단계\n",
      "- 다양성 확보를 위한 보조 데이터\n",
      "- 전문가 검증 전제 하에 활용\n",
      "\n",
      "⚠️  주의사항:\n",
      "- LLM이 생성한 Ground Truth는 반드시 검증 필요\n",
      "- 환각(Hallucination)으로 인한 오답 가능성\n",
      "- 단독 사용 금지, 보조 수단으로만 활용\n",
      "\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "실습: 합성 질문 생성\n",
      "────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'SyntheticDatasetGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# 샘플 문서 (실제로는 실제 문서를 사용)\u001b[39;00m\n\u001b[32m     30\u001b[39m sample_document = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[33m2024년 회사 실적 보고서\u001b[39m\n\u001b[32m     32\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     46\u001b[39m \u001b[33m- 직원 수 200명 (전년 대비 +25명)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m generator = \u001b[43mSyntheticDatasetGenerator\u001b[49m(\n\u001b[32m     50\u001b[39m     llm=llm,\n\u001b[32m     51\u001b[39m     num_questions_per_doc=\u001b[32m3\u001b[39m,\n\u001b[32m     52\u001b[39m     question_types=[QuestionType.FACTUAL, QuestionType.REASONING],\n\u001b[32m     53\u001b[39m     difficulty_levels=[DifficultyLevel.SIMPLE, DifficultyLevel.MEDIUM],\n\u001b[32m     54\u001b[39m )\n\u001b[32m     56\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m📝 생성 중...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'SyntheticDatasetGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Section 7: Ground Truth 데이터셋 구축 실전\n",
    "# ============================================================================\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 방법 1: LLM 기반 자동 생성 (보조 수단)\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n[방법 1] LLM 기반 합성 데이터 생성\")\n",
    "print(f\"{'=' * 80}\")\n",
    "\n",
    "print(\"\"\"\n",
    "⚙️  적용 시나리오:\n",
    "- 초기 프로토타입 개발 단계\n",
    "- 다양성 확보를 위한 보조 데이터\n",
    "- 전문가 검증 전제 하에 활용\n",
    "\n",
    "⚠️  주의사항:\n",
    "- LLM이 생성한 Ground Truth는 반드시 검증 필요\n",
    "- 환각(Hallucination)으로 인한 오답 가능성\n",
    "- 단독 사용 금지, 보조 수단으로만 활용\n",
    "\"\"\")\n",
    "\n",
    "# 실습: LLM으로 합성 데이터 생성\n",
    "print(f\"\\n{'─' * 80}\")\n",
    "print(\"실습: 합성 질문 생성\")\n",
    "print(f\"{'─' * 80}\")\n",
    "\n",
    "# 샘플 문서 (실제로는 실제 문서를 사용)\n",
    "sample_document = \"\"\"\n",
    "2024년 회사 실적 보고서\n",
    "\n",
    "1. 재무 실적\n",
    "- 총 매출: 500억원 (전년 대비 +15%)\n",
    "- 영업이익: 75억원 (영업이익률 15%)\n",
    "- 당기순이익: 50억원\n",
    "\n",
    "2. 사업 부문별 실적\n",
    "- AI 솔루션 사업: 300억원 (60%)\n",
    "- 클라우드 서비스: 150억원 (30%)\n",
    "- 컨설팅: 50억원 (10%)\n",
    "\n",
    "3. 주요 성과\n",
    "- 신규 고객 50개사 확보\n",
    "- 특허 출원 12건\n",
    "- 직원 수 200명 (전년 대비 +25명)\n",
    "\"\"\"\n",
    "\n",
    "generator = SyntheticDatasetGenerator(\n",
    "    llm=llm,\n",
    "    num_questions_per_doc=3,\n",
    "    question_types=[QuestionType.FACTUAL, QuestionType.REASONING],\n",
    "    difficulty_levels=[DifficultyLevel.SIMPLE, DifficultyLevel.MEDIUM],\n",
    ")\n",
    "\n",
    "print(\"\\n📝 생성 중...\")\n",
    "try:\n",
    "    synthetic_questions = generator.generate_dataset(\n",
    "        documents=[sample_document],\n",
    "        document_ids=[\"report_2024\"],\n",
    "    )\n",
    "\n",
    "    print(f\"\\n✓ 생성 완료: {len(synthetic_questions.questions)}개 질문\")\n",
    "\n",
    "    for i, q in enumerate(synthetic_questions.questions[:2], 1):\n",
    "        print(f\"\\n[{i}] {q.question}\")\n",
    "        print(f\"    유형: {q.question_type.value} | 난이도: {q.difficulty.value}\")\n",
    "        print(f\"    Ground Truth: {q.ground_truth[:100]}...\")\n",
    "        print(f\"    ⚠️  검증 필요: 전문가 검토 전까지 사용 금지\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n⚠️  생성 실패: {e}\")\n",
    "    print(\"    (실제 환경에서는 LLM 설정 확인 필요)\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 방법 2: 도메인 전문가 인터뷰 ⭐ (최우선 권장)\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "print(f\"\\n\\n{'=' * 80}\")\n",
    "print(\"[방법 2] 도메인 전문가 (SME) 인터뷰 ⭐ 최우선 권장\")\n",
    "print(f\"{'=' * 80}\")\n",
    "\n",
    "print(\"\"\"\n",
    "🎯 적용 시나리오:\n",
    "- 프로덕션 배포 준비 단계\n",
    "- 고품질 평가 데이터 확보\n",
    "- 도메인 특화 질문 수집\n",
    "\n",
    " 장점:\n",
    "- 가장 높은 신뢰도\n",
    "- 실제 업무 시나리오 반영\n",
    "- 명확한 Ground Truth\n",
    "\n",
    "📋 준비 사항:\n",
    "- SME 인터뷰 시간 확보 (2-4시간)\n",
    "- 템플릿 CSV 파일 사전 제공\n",
    "- 인터뷰 가이드라인 준비\n",
    "\"\"\")\n",
    "\n",
    "# 실습: SME 템플릿 생성\n",
    "print(f\"\\n{'─' * 80}\")\n",
    "print(\"실습: SME 인터뷰 템플릿 생성\")\n",
    "print(f\"{'─' * 80}\")\n",
    "\n",
    "sme_builder = SMEDatasetBuilder()\n",
    "\n",
    "# 템플릿 CSV 생성\n",
    "template_path = sme_builder.create_template(\n",
    "    save_path=\"sme_questions_template.csv\",\n",
    "    num_examples=5,\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ 템플릿 생성 완료: {template_path}\")\n",
    "print(\"\\n📧 SME에게 전달할 이메일 템플릿:\")\n",
    "print(f\"{'─' * 80}\")\n",
    "\n",
    "print(\"\"\"\n",
    "제목: [RAG 평가] 전문가 질문 작성 요청\n",
    "\n",
    "안녕하세요,\n",
    "\n",
    "RAG 시스템의 품질 평가를 위한 Ground Truth 데이터셋 구축에 협조 부탁드립니다.\n",
    "\n",
    "**작업 내용:**\n",
    "- 첨부된 CSV 파일의 질문/답변 작성\n",
    "- 목표: 20-30개 질문 (실제 업무에서 자주 받는 질문 위주)\n",
    "- 소요 시간: 약 2-3시간\n",
    "\n",
    "**작성 가이드라인:**\n",
    "\n",
    "1. 질문 선정 기준\n",
    "   ✓ 실제 고객/동료가 자주 묻는 질문\n",
    "   ✓ 문서에서 명확히 답변 가능한 질문\n",
    "   ✓ 비즈니스 임팩트가 큰 질문\n",
    "   ✗ 애매하거나 해석이 갈리는 질문\n",
    "   ✗ 문서에 없는 정보가 필요한 질문\n",
    "\n",
    "2. Ground Truth 작성 기준\n",
    "   ✓ 문서의 정보만 사용 (추측 금지)\n",
    "   ✓ 명확하고 간결하게 작성\n",
    "   ✓ 가능하면 문서 표현 그대로 사용\n",
    "   ✗ \"약\", \"정도\", \"추정\" 등 모호한 표현 지양\n",
    "\n",
    "3. 난이도 구분\n",
    "   - SIMPLE: 단일 정보 조회 (예: \"2024년 매출은?\")\n",
    "   - MEDIUM: 2-3개 정보 조합 (예: \"영업이익률은?\")\n",
    "   - COMPLEX: 추론 필요 (예: \"전년 대비 개선 원인은?\")\n",
    "\n",
    "4. 질문 유형\n",
    "   - FACTUAL: 사실 확인\n",
    "   - REASONING: 추론/분석\n",
    "   - COMPARISON: 비교\n",
    "   - PROCEDURAL: 절차/방법\n",
    "\n",
    "**예시:**\n",
    "\n",
    "질문 ID: Q001\n",
    "질문: 2024년 총 매출액은 얼마인가요?\n",
    "질문 유형: factual\n",
    "난이도: simple\n",
    "정답(Ground Truth): 500억원\n",
    "관련 문서 ID: report_2024_financial\n",
    "비고: 재무제표 3페이지\n",
    "\n",
    "---\n",
    "\n",
    "첨부: sme_questions_template.csv\n",
    "\n",
    "감사합니다.\n",
    "\"\"\")\n",
    "\n",
    "# SME 인터뷰 진행 방법\n",
    "print(f\"\\n{'─' * 80}\")\n",
    "print(\"SME 인터뷰 진행 가이드 (실무)\")\n",
    "print(f\"{'─' * 80}\")\n",
    "\n",
    "print(\"\"\"\n",
    "📅 인터뷰 프로세스 (총 3단계):\n",
    "\n",
    "**1단계: 사전 준비 (1주 전)**\n",
    "   1. 인터뷰 목적 및 소요 시간 공지\n",
    "   2. 템플릿 CSV 파일 전달\n",
    "   3. 작성 가이드라인 공유\n",
    "   4. 샘플 질문 5개 제공 (참고용)\n",
    "\n",
    "   💡 Tip: 너무 많이 요청하지 말 것 (20-30개가 적당)\n",
    "\n",
    "**2단계: 1차 작성 및 검토 (인터뷰 당일)**\n",
    "   1. SME가 작성한 질문 리뷰\n",
    "   2. 애매한 부분 명확화\n",
    "   3. Ground Truth 검증\n",
    "   4. 추가 질문 필요 시 현장 작성\n",
    "\n",
    "   체크리스트:\n",
    "   □ 모든 Ground Truth가 문서에서 확인 가능한가?\n",
    "   □ 질문이 명확하고 해석 여지가 없는가?\n",
    "   □ 난이도 분포가 적절한가? (Simple 50%, Medium 30%, Complex 20%)\n",
    "   □ 유형 다양성이 확보되었는가?\n",
    "\n",
    "**3단계: 후속 검증 (1주 후)**\n",
    "   1. 작성된 질문으로 RAG 시스템 테스트\n",
    "   2. 예상과 다른 결과가 나온 질문 재검토\n",
    "   3. SME에게 피드백 요청\n",
    "   4. 최종 데이터셋 확정\n",
    "\n",
    "   검증 기준:\n",
    "   • RAG 시스템이 Ground Truth와 유사한 답변을 내놓는가?\n",
    "   • Ground Truth가 너무 간략하거나 장황하지 않은가?\n",
    "   • 실제 비즈니스 상황을 잘 반영하는가?\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\n{'─' * 80}\")\n",
    "print(\"SME 섭외 및 동기부여 방법\")\n",
    "print(f\"{'─' * 80}\")\n",
    "\n",
    "print(\"\"\"\n",
    "🤝 SME 섭외 전략:\n",
    "\n",
    "**1. 적절한 인센티브 제공**\n",
    "   - 업무 시간으로 인정 (2-3시간)\n",
    "   - 결과물 공유 (개선된 RAG 시스템 우선 사용권)\n",
    "   - 기여 인정 (내부 보고서에 명시)\n",
    "\n",
    "**2. 업무 관련성 강조**\n",
    "   - \"귀하의 업무를 자동화할 수 있습니다\"\n",
    "   - \"반복 질문에 대한 부담이 줄어듭니다\"\n",
    "   - \"팀 전체의 생산성이 향상됩니다\"\n",
    "\n",
    "**3. 부담 최소화**\n",
    "   - 점진적 작성 가능 (5개씩 나눠서)\n",
    "   - 비동기 작업 가능 (편한 시간에)\n",
    "   - 완벽함보다 실용성 강조\n",
    "\n",
    "**4. 피드백 루프 형성**\n",
    "   - 중간 결과 공유\n",
    "   - 개선 효과 정량화하여 보고\n",
    "   - 지속적인 협력 관계 구축\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 방법 3: 프로덕션 로그 분석 (실무 최적)\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "print(f\"\\n\\n{'=' * 80}\")\n",
    "print(\"[방법 3] 프로덕션 로그 분석 🚀 실무 최적\")\n",
    "print(f\"{'=' * 80}\")\n",
    "\n",
    "print(\"\"\"\n",
    "🎯 적용 시나리오:\n",
    "- 이미 운영 중인 RAG 시스템\n",
    "- 실사용자 데이터 확보 가능\n",
    "- 지속적인 개선 필요\n",
    "\n",
    " 장점:\n",
    "- 실제 사용자 질문 기반\n",
    "- 빈도 높은 질문 우선 개선\n",
    "- 비즈니스 임팩트 명확\n",
    "\n",
    "📊 필요 데이터:\n",
    "- 사용자 질문 로그\n",
    "- 사용자 만족도 점수 (피드백)\n",
    "- 응답 시간, 오류 발생 여부\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\n{'─' * 80}\")\n",
    "print(\"실습: 프로덕션 로그 기반 우선순위 산정\")\n",
    "print(f\"{'─' * 80}\")\n",
    "\n",
    "# 샘플 로그 데이터\n",
    "import pandas as pd\n",
    "\n",
    "production_logs = pd.DataFrame(\n",
    "    {\n",
    "        \"question\": [\n",
    "            \"2024년 총 매출은?\",\n",
    "            \"영업이익률 계산 방법은?\",\n",
    "            \"AI 솔루션 매출 비중은?\",\n",
    "            \"직원 수 증가율은?\",\n",
    "            \"신규 고객은 몇 개사?\",\n",
    "        ],\n",
    "        \"frequency\": [45, 32, 28, 15, 12],\n",
    "        \"satisfaction_score\": [4.2, 3.1, 4.5, 4.0, 3.8],  # 5점 만점\n",
    "        \"avg_response_time_ms\": [1200, 2500, 1100, 1400, 1300],\n",
    "    }\n",
    ")\n",
    "\n",
    "# 우선순위 계산: frequency * (5 - satisfaction_score)\n",
    "production_logs[\"priority_score\"] = production_logs[\"frequency\"] * (\n",
    "    5 - production_logs[\"satisfaction_score\"]\n",
    ")\n",
    "production_logs = production_logs.sort_values(\"priority_score\", ascending=False)\n",
    "\n",
    "print(\"\\n📊 우선순위 기반 질문 선정:\")\n",
    "print(f\"{'─' * 80}\")\n",
    "print(\n",
    "    production_logs[[\"question\", \"frequency\", \"satisfaction_score\", \"priority_score\"]].to_string(\n",
    "        index=False\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"\\n💡 해석:\")\n",
    "print(f\"  1순위: {production_logs.iloc[0]['question']}\")\n",
    "print(\n",
    "    f\"     → 빈도 {production_logs.iloc[0]['frequency']:.0f}회, 만족도 {production_logs.iloc[0]['satisfaction_score']:.1f}\"\n",
    ")\n",
    "print(f\"     → 우선순위 점수: {production_logs.iloc[0]['priority_score']:.1f}\")\n",
    "print(f\"     → 이유: 빈도는 높으나 만족도 낮음 → 즉시 개선 필요\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f1f77c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Modular Agentic RAG \n",
    "\n",
    "### 5.1 개요\n",
    "\n",
    "지금까지 구현한 Agentic RAG를 **Modular 시스템**으로 재구성합니다.\n",
    "\n",
    "**주요 개선사항:**\n",
    "-  **LangChain v1 `create_agent` 패턴** 적용\n",
    "-  **Tool 기반 검색**: 모든 검색 기능을 Tool로 노출\n",
    "-  **미들웨어**: 오류 처리, 로깅, 재귀 한도 제어\n",
    "-  **체크포인터**: SQLite 기반 대화 이력 유지\n",
    "-  **RAGAS 통합 평가**: `AgenticRAGEvaluator` 클래스\n",
    "-  **자동 개선 엔진**: 평가 결과 → 개선 계획 자동 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b709957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Step 1: LLM/임베딩 초기화\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Step 1: LLM 및 임베딩 모델 초기화\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# LLM 생성 (OpenRouter/OpenAI 자동 감지)\n",
    "modular_llm = create_openrouter_llm(model=\"gpt-4.1\", temperature=0.1)\n",
    "\n",
    "# Qdrant 클라이언트 초기화\n",
    "modular_qdrant_client = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "# 컬렉션 확인/생성\n",
    "collection_name = \"modular_agentic_rag_documents\"\n",
    "\n",
    "# 임베딩 모델\n",
    "# NOTE: Qwen 임베딩 모델은 OpenRouter 에서 사용하려면, 바로 Text 넣고 Return 받아야합니다.\n",
    "prod_embeddings = create_embedding_model_direct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "488027ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Step 1: Qdrant 벡터스토어 설정\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26e080eb3b9409eb845bad554d93847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 임베딩 차원: 1536\n",
      "✓ 컬렉션 생성: agentic_rag_docs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4502c2c7b9fb44e8822509f1c1a8da47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cfd8eb381ee4de1ba89e58ea9c9d154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 3개 샘플 문서 추가\n",
      "✓ Retrieval Tool 생성 완료\n",
      "  - Tool 이름: retriever_tool\n",
      "  - Tool 설명: 문서 검색 도구. 질문과 관련된 문서를 벡터 데이터베이스에서 검색합니다.\n",
      "\n",
      "    Args...\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TODO 구현 1: Qdrant 벡터스토어 설정 및 Retrieval Tool 생성\n",
    "# ============================================================================\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.documents import Document\n",
    "from typing import List\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Step 1: Qdrant 벡터스토어 설정\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Qdrant 클라이언트 초기화 (in-memory 모드)\n",
    "qdrant_client = QdrantClient(\":memory:\")\n",
    "\n",
    "# 컬렉션 이름\n",
    "collection_name = \"agentic_rag_docs\"\n",
    "\n",
    "# 임베딩 차원 확인\n",
    "vector_size = len(embeddings.embed_query(\"sample text\"))\n",
    "print(f\"✓ 임베딩 차원: {vector_size}\")\n",
    "\n",
    "# 컬렉션 생성\n",
    "if not qdrant_client.collection_exists(collection_name):\n",
    "    qdrant_client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=VectorParams(size=vector_size, distance=Distance.COSINE)\n",
    "    )\n",
    "    print(f\"✓ 컬렉션 생성: {collection_name}\")\n",
    "\n",
    "# QdrantVectorStore 초기화\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=qdrant_client,\n",
    "    collection_name=collection_name,\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "# 샘플 문서 추가 (테스트용)\n",
    "sample_docs = [\n",
    "    Document(\n",
    "        page_content=\"리스트 컴프리헨션은 파이썬에서 리스트를 간결하게 생성하는 방법입니다. [표현식 for 항목 in 반복가능객체] 형태로 작성됩니다.\",\n",
    "        metadata={\"source\": \"python_basics\", \"topic\": \"list_comprehension\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"함수형 프로그래밍의 주요 특징은 불변성(immutability), 순수 함수(pure functions), 고차 함수(higher-order functions)입니다.\",\n",
    "        metadata={\"source\": \"fp_basics\", \"topic\": \"functional_programming\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"RESTful API 설계 원칙: 자원 식별, HTTP 메서드 활용, 무상태성(Stateless), 캐시 가능성, 계층화된 시스템입니다.\",\n",
    "        metadata={\"source\": \"rest_api\", \"topic\": \"api_design\"}\n",
    "    ),\n",
    "]\n",
    "\n",
    "vector_store.add_documents(sample_docs)\n",
    "print(f\"✓ {len(sample_docs)}개 샘플 문서 추가\")\n",
    "\n",
    "# Retrieval Tool 생성\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retriever_tool(query: str) -> tuple[str, List[Document]]:\n",
    "    \"\"\"문서 검색 도구. 질문과 관련된 문서를 벡터 데이터베이스에서 검색합니다.\n",
    "    \n",
    "    Args:\n",
    "        query: 검색 쿼리\n",
    "        \n",
    "    Returns:\n",
    "        tuple[str, List[Document]]: (문서 텍스트, 원본 Document 리스트)\n",
    "    \"\"\"\n",
    "    # 유사도 검색\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=3)\n",
    "    \n",
    "    # 직렬화된 텍스트 생성\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        f\"[문서 {i+1}]\\n출처: {doc.metadata.get('source', 'unknown')}\\n내용: {doc.page_content}\"\n",
    "        for i, doc in enumerate(retrieved_docs)\n",
    "    )\n",
    "    \n",
    "    return serialized, retrieved_docs\n",
    "\n",
    "print(\"✓ Retrieval Tool 생성 완료\")\n",
    "print(f\"  - Tool 이름: {retriever_tool.name}\")\n",
    "print(f\"  - Tool 설명: {retriever_tool.description[:50]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d26e9b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Step 2: AgentState 스키마 정의\n",
      "================================================================================\n",
      "✓ AgenticRAGState 스키마 정의 완료\n",
      "  - 필수 키: query\n",
      "  - 선택 키: intent, complexity, retrieved_docs, doc_grade, rewrite_count, answer\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TODO 구현 2: AgentState 스키마 정의\n",
    "# ============================================================================\n",
    "\n",
    "from typing import TypedDict, Literal, Optional\n",
    "from typing_extensions import NotRequired\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Step 2: AgentState 스키마 정의\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class AgenticRAGState(TypedDict):\n",
    "    \"\"\"Agentic RAG 그래프의 상태를 정의하는 스키마.\n",
    "    \n",
    "    Attributes:\n",
    "        query: 사용자 질문\n",
    "        intent: 질문 의도 분류 결과 (SEARCH, EXPLAIN, COMPARE 등)\n",
    "        complexity: 질문 복잡도 (SIMPLE, MEDIUM, COMPLEX)\n",
    "        retrieved_docs: 검색된 문서 리스트\n",
    "        doc_grade: 문서 관련성 평가 (\"yes\" 또는 \"no\")\n",
    "        rewrite_count: 쿼리 재작성 횟수\n",
    "        answer: 최종 생성된 답변\n",
    "    \"\"\"\n",
    "    query: str\n",
    "    intent: NotRequired[str]\n",
    "    complexity: NotRequired[str]\n",
    "    retrieved_docs: NotRequired[List[Document]]\n",
    "    doc_grade: NotRequired[str]\n",
    "    rewrite_count: NotRequired[int]\n",
    "    answer: NotRequired[str]\n",
    "\n",
    "print(\"✓ AgenticRAGState 스키마 정의 완료\")\n",
    "print(\"  - 필수 키: query\")\n",
    "print(\"  - 선택 키: intent, complexity, retrieved_docs, doc_grade, rewrite_count, answer\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8705c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Step 3: LangGraph 노드 구현\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TODO 구현 3: 6개 LangGraph 노드 구현\n",
    "# ============================================================================\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Step 3: LangGraph 노드 구현\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 노드 1: classify_intent - 질문 의도 분류\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "class IntentClassification(BaseModel):\n",
    "    \"\"\"질문 의도 분류 결과\"\"\"\n",
    "    intent: Literal[\"SEARCH\", \"EXPLAIN\", \"COMPARE\", \"CALCULATE\", \"GENERAL\"] = Field(\n",
    "        description=\"질문의 주요 의도. SEARCH: 정보 검색, EXPLAIN: 설명 요청, COMPARE: 비교, CALCULATE: 계산, GENERAL: 일반 대화\"\n",
    "    )\n",
    "    reasoning: str = Field(description=\"분류 근거\")\n",
    "\n",
    "def classify_intent_node(state: AgenticRAGState) -> dict:\n",
    "    \"\"\"질문 의도를 분류하는 노드.\n",
    "    \n",
    "    Args:\n",
    "        state: 현재 그래프 상태\n",
    "        \n",
    "    Returns:\n",
    "        dict: intent 키가 업데이트된 딕셔너리\n",
    "    \"\"\"\n",
    "    print(\"\\n[classify_intent] 의도 분류 시작...\")\n",
    "    \n",
    "    query = state[\"query\"]\n",
    "    \n",
    "    # Structured output으로 의도 분류\n",
    "    llm_with_structure = llm.with_structured_output(IntentClassification)\n",
    "    \n",
    "    result = llm_with_structure.invoke(\n",
    "        f\"다음 질문의 의도를 분류하세요:\\n\\n질문: {query}\"\n",
    "    )\n",
    "    \n",
    "    print(f\"  → 의도: {result.intent}\")\n",
    "    print(f\"  → 근거: {result.reasoning[:50]}...\")\n",
    "    \n",
    "    return {\"intent\": result.intent}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f06a2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# 노드 2: analyze_complexity - 복잡도 분석\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "class ComplexityAnalysis(BaseModel):\n",
    "    \"\"\"질문 복잡도 분석 결과\"\"\"\n",
    "    complexity: Literal[\"SIMPLE\", \"MEDIUM\", \"COMPLEX\"] = Field(\n",
    "        description=\"질문의 복잡도. SIMPLE: 단일 정보 조회, MEDIUM: 2-3개 정보 조합, COMPLEX: 다단계 추론 필요\"\n",
    "    )\n",
    "    reasoning: str = Field(description=\"분석 근거\")\n",
    "    recommended_top_k: int = Field(description=\"권장 검색 문서 개수\")\n",
    "\n",
    "def analyze_complexity_node(state: AgenticRAGState) -> dict:\n",
    "    \"\"\"질문 복잡도를 분석하는 노드.\n",
    "    \n",
    "    Args:\n",
    "        state: 현재 그래프 상태\n",
    "        \n",
    "    Returns:\n",
    "        dict: complexity 키가 업데이트된 딕셔너리\n",
    "    \"\"\"\n",
    "    print(\"\\n[analyze_complexity] 복잡도 분석 시작...\")\n",
    "    \n",
    "    query = state[\"query\"]\n",
    "    \n",
    "    # Structured output으로 복잡도 분석\n",
    "    llm_with_structure = llm.with_structured_output(ComplexityAnalysis)\n",
    "    \n",
    "    result = llm_with_structure.invoke(\n",
    "        f\"\"\"다음 질문의 복잡도를 분석하세요.\n",
    "\n",
    "질문: {query}\n",
    "\n",
    "분석 기준:\n",
    "- SIMPLE: 단일 개념이나 정보만 필요 (예: \"X란 무엇인가?\")\n",
    "- MEDIUM: 2-3개의 정보를 조합해야 함 (예: \"X와 Y의 차이는?\")\n",
    "- COMPLEX: 다단계 추론이나 여러 개념 종합 필요 (예: \"X가 Y에 미치는 영향과 그 이유는?\")\n",
    "\"\"\"\n",
    "    )\n",
    "    \n",
    "    print(f\"  → 복잡도: {result.complexity}\")\n",
    "    print(f\"  → 권장 top_k: {result.recommended_top_k}\")\n",
    "    print(f\"  → 근거: {result.reasoning[:50]}...\")\n",
    "    \n",
    "    return {\"complexity\": result.complexity}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221f80bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# 노드 3: agent - Tool 기반 검색 에이전트\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "def agent_node(state: AgenticRAGState) -> dict:\n",
    "    \"\"\"Tool을 사용하여 문서를 검색하는 에이전트 노드.\n",
    "    \n",
    "    Args:\n",
    "        state: 현재 그래프 상태\n",
    "        \n",
    "    Returns:\n",
    "        dict: retrieved_docs 키가 업데이트된 딕셔너리\n",
    "    \"\"\"\n",
    "    print(\"\\n[agent] Tool 기반 검색 시작...\")\n",
    "    \n",
    "    query = state[\"query\"]\n",
    "    \n",
    "    # Tool을 모델에 바인딩\n",
    "    llm_with_tools = llm.bind_tools([retriever_tool])\n",
    "    \n",
    "    # Tool call 생성\n",
    "    response = llm_with_tools.invoke(\n",
    "        f\"다음 질문에 답하기 위해 필요한 정보를 검색하세요:\\n\\n{query}\"\n",
    "    )\n",
    "    \n",
    "    # Tool call이 있는지 확인\n",
    "    if response.tool_calls:\n",
    "        tool_call = response.tool_calls[0]\n",
    "        print(f\"  → Tool 호출: {tool_call['name']}\")\n",
    "        print(f\"  → 검색 쿼리: {tool_call['args'].get('query', '')[:50]}...\")\n",
    "        \n",
    "        # Tool 실행\n",
    "        serialized, docs = retriever_tool.invoke(tool_call['args'])\n",
    "        \n",
    "        print(f\"  → {len(docs)}개 문서 검색 완료\")\n",
    "        \n",
    "        return {\"retrieved_docs\": docs}\n",
    "    else:\n",
    "        print(\"  ⚠ Tool call이 생성되지 않음. 빈 리스트 반환\")\n",
    "        return {\"retrieved_docs\": []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9e63b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# 노드 4: grade - 문서 관련성 평가\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "class DocumentGrade(BaseModel):\n",
    "    \"\"\"문서 관련성 평가 결과\"\"\"\n",
    "    binary_score: Literal[\"yes\", \"no\"] = Field(\n",
    "        description=\"문서가 질문과 관련이 있으면 'yes', 없으면 'no'\"\n",
    "    )\n",
    "    reasoning: str = Field(description=\"평가 근거\")\n",
    "\n",
    "def grade_node(state: AgenticRAGState) -> dict:\n",
    "    \"\"\"검색된 문서의 관련성을 평가하는 노드.\n",
    "    \n",
    "    Args:\n",
    "        state: 현재 그래프 상태\n",
    "        \n",
    "    Returns:\n",
    "        dict: doc_grade 키가 업데이트된 딕셔너리\n",
    "    \"\"\"\n",
    "    print(\"\\n[grade] 문서 관련성 평가 시작...\")\n",
    "    \n",
    "    query = state[\"query\"]\n",
    "    docs = state.get(\"retrieved_docs\", [])\n",
    "    \n",
    "    if not docs:\n",
    "        print(\"  ⚠ 검색된 문서가 없습니다.\")\n",
    "        return {\"doc_grade\": \"no\"}\n",
    "    \n",
    "    # 문서 내용 결합\n",
    "    doc_contents = \"\\n\\n\".join([\n",
    "        f\"[문서 {i+1}] {doc.page_content[:200]}...\"\n",
    "        for i, doc in enumerate(docs)\n",
    "    ])\n",
    "    \n",
    "    # Structured output으로 관련성 평가\n",
    "    llm_with_structure = llm.with_structured_output(DocumentGrade)\n",
    "    \n",
    "    result = llm_with_structure.invoke(\n",
    "        f\"\"\"다음 문서들이 질문에 답하기에 관련이 있는지 평가하세요.\n",
    "\n",
    "질문: {query}\n",
    "\n",
    "검색된 문서:\n",
    "{doc_contents}\n",
    "\n",
    "평가 기준:\n",
    "- 문서에 질문에 대한 직접적이거나 간접적인 정보가 있으면 'yes'\n",
    "- 문서가 질문과 전혀 관련이 없으면 'no'\n",
    "\"\"\"\n",
    "    )\n",
    "    \n",
    "    print(f\"  → 관련성: {result.binary_score}\")\n",
    "    print(f\"  → 근거: {result.reasoning[:50]}...\")\n",
    "    \n",
    "    return {\"doc_grade\": result.binary_score}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147d16d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# 노드 5: rewrite - 쿼리 재작성\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "def rewrite_node(state: AgenticRAGState) -> dict:\n",
    "    \"\"\"문서 관련성이 낮을 때 쿼리를 재작성하는 노드.\n",
    "    \n",
    "    Args:\n",
    "        state: 현재 그래프 상태\n",
    "        \n",
    "    Returns:\n",
    "        dict: query와 rewrite_count가 업데이트된 딕셔너리\n",
    "    \"\"\"\n",
    "    print(\"\\n[rewrite] 쿼리 재작성 시작...\")\n",
    "    \n",
    "    query = state[\"query\"]\n",
    "    rewrite_count = state.get(\"rewrite_count\", 0)\n",
    "    \n",
    "    # 쿼리 재작성\n",
    "    response = llm.invoke(\n",
    "        f\"\"\"다음 질문을 더 명확하고 검색 가능한 형태로 재작성하세요.\n",
    "검색 시스템이 관련 문서를 찾기 쉽도록 핵심 키워드를 포함하세요.\n",
    "\n",
    "원래 질문: {query}\n",
    "\n",
    "재작성된 질문만 출력하세요.\"\"\"\n",
    "    )\n",
    "    \n",
    "    rewritten_query = response.content.strip()\n",
    "    new_count = rewrite_count + 1\n",
    "    \n",
    "    print(f\"  → 원래 쿼리: {query[:50]}...\")\n",
    "    print(f\"  → 재작성: {rewritten_query[:50]}...\")\n",
    "    print(f\"  → 재작성 횟수: {new_count}\")\n",
    "    \n",
    "    return {\n",
    "        \"query\": rewritten_query,\n",
    "        \"rewrite_count\": new_count\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5cf79b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# 노드 6: generate - 최종 답변 생성\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# RAG 프롬프트 템플릿\n",
    "RAG_PROMPT = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"당신은 정확하고 도움이 되는 AI 어시스턴트입니다.\n",
    "제공된 컨텍스트를 기반으로 질문에 답변하세요.\n",
    "\n",
    "**중요 규칙:**\n",
    "1. 제공된 컨텍스트에 있는 정보만 사용하세요\n",
    "2. 컨텍스트에 없는 정보는 만들지 마세요\n",
    "3. 답변이 불가능하면 \"제공된 정보만으로는 답변하기 어렵습니다\"라고 말하세요\n",
    "4. 답변은 명확하고 간결하게 작성하세요\"\"\"),\n",
    "    (\"user\", \"\"\"컨텍스트:\n",
    "{context}\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "답변:\"\"\")\n",
    "])\n",
    "\n",
    "def generate_node(state: AgenticRAGState) -> dict:\n",
    "    \"\"\"최종 답변을 생성하는 노드.\n",
    "    \n",
    "    Args:\n",
    "        state: 현재 그래프 상태\n",
    "        \n",
    "    Returns:\n",
    "        dict: answer 키가 업데이트된 딕셔너리\n",
    "    \"\"\"\n",
    "    print(\"\\n[generate] 최종 답변 생성 시작...\")\n",
    "    \n",
    "    query = state[\"query\"]\n",
    "    docs = state.get(\"retrieved_docs\", [])\n",
    "    \n",
    "    if not docs:\n",
    "        answer = \"죄송합니다. 관련 문서를 찾을 수 없어 답변하기 어렵습니다.\"\n",
    "        print(f\"  ⚠ 문서 없음: {answer}\")\n",
    "        return {\"answer\": answer}\n",
    "    \n",
    "    # 컨텍스트 생성\n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"[문서 {i+1}]\\n{doc.page_content}\"\n",
    "        for i, doc in enumerate(docs)\n",
    "    ])\n",
    "    \n",
    "    # RAG 체인 실행\n",
    "    chain = RAG_PROMPT | llm\n",
    "    response = chain.invoke({\"context\": context, \"question\": query})\n",
    "    \n",
    "    answer = response.content.strip()\n",
    "    \n",
    "    print(f\"  → 답변 길이: {len(answer)} 문자\")\n",
    "    print(f\"  → 답변 미리보기: {answer[:100]}...\")\n",
    "    \n",
    "    return {\"answer\": answer}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aaa16aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import wrap_tool_call, ModelCallLimitMiddleware\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 미들웨어 1: log_tool_calls - Tool 호출 로깅\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "@wrap_tool_call\n",
    "def log_tool_calls(request, handler):\n",
    "    \"\"\"Tool 호출을 로깅하는 미들웨어.\n",
    "    \n",
    "    Args:\n",
    "        request: ToolCallRequest 객체 (tool_call 딕셔너리 포함)\n",
    "        handler: 실제 도구를 실행하는 콜러블\n",
    "        \n",
    "    Returns:\n",
    "        ToolMessage 또는 Command: 도구 실행 결과\n",
    "    \"\"\"\n",
    "    print(f\"[Tool Call] Executing: {request.tool_call['name']}\")\n",
    "    print(f\"[Tool Call] Arguments: {request.tool_call['args']}\")\n",
    "    \n",
    "    try:\n",
    "        result = handler(request)\n",
    "        print(f\"[Tool Call] Success: {request.tool_call['name']}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"[Tool Call] Failed: {request.tool_call['name']} - {e}\")\n",
    "        raise\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 미들웨어 2: handle_tool_errors - Tool 오류 안전 처리\n",
    "# ----------------------------------------------------------------------------\n",
    "@wrap_tool_call\n",
    "def handle_tool_error(request, handler):\n",
    "    \"\"\"Tool 실행 오류를 안전하게 처리하는 미들웨어.\n",
    "    \n",
    "    Args:\n",
    "        request: ToolCallRequest 객체 (tool_call 딕셔너리 포함)\n",
    "        handler: 실제 도구를 실행하는 콜러블\n",
    "        \n",
    "    Returns:\n",
    "        ToolMessage: 도구 실행 결과 또는 에러 메시지\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return handler(request)\n",
    "    except Exception as e:\n",
    "        # ToolMessage로 에러를 반환하여 모델이 인식하고 대응할 수 있도록 함\n",
    "        return ToolMessage(\n",
    "            content=f\"도구 실행 오류: 입력을 확인하고 다시 시도해주세요. ({str(e)})\",\n",
    "            tool_call_id=request.tool_call[\"id\"]\n",
    "        )\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 미들웨어 3: ModelCallLimitMiddleware - 모델 호출 횟수 제한\n",
    "# ----------------------------------------------------------------------------\n",
    "# thread_limit: 스레드당 최대 호출 횟수 (대화 세션 전체)\n",
    "# run_limit: 단일 실행당 최대 호출 횟수 (옵션)\n",
    "# exit_behavior: \"end\" (정상 종료) 또는 \"error\" (예외 발생)\n",
    "model_call_limit_middleware = ModelCallLimitMiddleware(thread_limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d4f0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[컴파일]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x11f475990>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Modular Agentic RAG 그래프 빌드\n",
    "# ============================================================================\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from typing import Literal\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 체크포인터 추가 (대화 이력 유지)\n",
    "# ----------------------------------------------------------------------------\n",
    "modular_rag_checkpointer = InMemorySaver()\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# StateGraph 초기화\n",
    "# ----------------------------------------------------------------------------\n",
    "workflow = StateGraph(AgenticRAGState)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 노드 추가\n",
    "# ----------------------------------------------------------------------------\n",
    "workflow.add_node(\"classify_intent\", classify_intent_node)\n",
    "workflow.add_node(\"analyze_complexity\", analyze_complexity_node)\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "workflow.add_node(\"grade\", grade_node)\n",
    "workflow.add_node(\"rewrite\", rewrite_node)\n",
    "workflow.add_node(\"generate\", generate_node)\n",
    "# ----------------------------------------------------------------------------\n",
    "# 엣지 연결\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "# START → classify_intent\n",
    "workflow.add_edge(START, \"classify_intent\")\n",
    "\n",
    "# classify_intent → analyze_complexity 또는 generate (조건부)\n",
    "def decide_after_intent(state: AgenticRAGState) -> Literal[\"analyze_complexity\", \"generate\"]:\n",
    "    \"\"\"의도 분류 후 다음 노드 결정.\n",
    "    \n",
    "    Args:\n",
    "        state: 현재 상태\n",
    "        \n",
    "    Returns:\n",
    "        다음 노드 이름\n",
    "    \"\"\"\n",
    "    intent = state.get(\"intent\", \"SEARCH\")\n",
    "    \n",
    "    # GENERAL 의도면 검색 없이 바로 답변\n",
    "    if intent == \"GENERAL\":\n",
    "        print(\"  [ROUTE] GENERAL 의도 → generate로 직접 이동\")\n",
    "        return \"generate\"\n",
    "    \n",
    "    # 그 외는 RAG 워크플로우 진행\n",
    "    return \"analyze_complexity\"\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"classify_intent\",\n",
    "    decide_after_intent,\n",
    "    {\n",
    "        \"analyze_complexity\": \"analyze_complexity\",\n",
    "        \"generate\": \"generate\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# analyze_complexity → agent (항상)\n",
    "workflow.add_edge(\"analyze_complexity\", \"agent\")\n",
    "\n",
    "# agent → grade (항상)\n",
    "workflow.add_edge(\"agent\", \"grade\")\n",
    "\n",
    "# grade → generate 또는 rewrite (조건부)\n",
    "def decide_after_grade(state: AgenticRAGState) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    \"\"\"문서 관련성 평가 후 다음 노드 결정.\n",
    "    \n",
    "    Args:\n",
    "        state: 현재 상태\n",
    "        \n",
    "    Returns:\n",
    "        다음 노드 이름\n",
    "    \"\"\"\n",
    "    doc_grade = state.get(\"doc_grade\", \"no\")\n",
    "    rewrite_count = state.get(\"rewrite_count\", 0)\n",
    "    \n",
    "    # 문서가 관련있으면 generate로\n",
    "    if doc_grade == \"yes\":\n",
    "        print(\"  [ROUTE] 문서 관련성 양호 → generate\")\n",
    "        return \"generate\"\n",
    "    \n",
    "    print(f\"재작성 횟수: {rewrite_count}\")\n",
    "    \n",
    "    return \"rewrite\"\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade\",\n",
    "    decide_after_grade,\n",
    "    {\n",
    "        \"generate\": \"generate\",\n",
    "        \"rewrite\": \"rewrite\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# rewrite → agent (재검색 루프)\n",
    "workflow.add_edge(\"rewrite\", \"agent\")\n",
    "\n",
    "# generate → END\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "prod_workflow: CompiledStateGraph = workflow.compile(\n",
    "    checkpointer=modular_rag_checkpointer,\n",
    ")\n",
    "\n",
    "prod_workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1c1bdd",
   "metadata": {},
   "source": [
    "### 5.2 RAGAS 통합 평가\n",
    "\n",
    "이제 `AgenticRAGEvaluator`를 사용하여 전체 평가 파이프라인을 실행합니다.\n",
    "\n",
    "**워크플로우:**\n",
    "1. 평가 데이터셋 준비\n",
    "2. `AgenticRAGEvaluator.run_full_evaluation()`\n",
    "3. RAGAS 점수 계산\n",
    "4. `AutoImprovementEngine`으로 개선 계획 생성\n",
    "5. 결과 분석 및 개선안 적용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81c4a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Step 5: AgenticRAGEvaluator 초기화 및 평가 실행\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Step 5: RAGAS 통합 평가\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Evaluator 초기화\n",
    "evaluator = AgenticRAGEvaluator(\n",
    "    graph=prod_graph,\n",
    "    llm=prod_llm,\n",
    "    embeddings=prod_embeddings,\n",
    ")\n",
    "\n",
    "# 평가 데이터셋 재사용 (Section 3에서 생성한 것)\n",
    "print(f\"\\n평가 데이터셋: {eval_dataset.name}\")\n",
    "print(f\"  - 질문 수: {len(eval_dataset.questions)}개\")\n",
    "\n",
    "# 전체 평가 실행 (평가 + 개선 계획)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"전체 평가 시작 (RAGAS + AutoImprovement)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    report, improvement_plan = evaluator.run_full_evaluation(\n",
    "        dataset=eval_dataset,\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    print(\"\\n전체 평가 완료\")\n",
    "\n",
    "    # 평가 리포트 출력\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"RAGAS 평가 리포트\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    print(\"\\n평균 점수:\")\n",
    "    for metric, score in report.average_scores.items():\n",
    "        print(f\"  • {metric.value:20s}: {score:.3f}\")\n",
    "\n",
    "    # 개선 계획 출력\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"자동 개선 계획\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    print(f\"\\n{improvement_plan.summary}\")\n",
    "\n",
    "    print(\"\\n우선순위별 액션:\")\n",
    "    for action in improvement_plan.actions[:3]:  # 상위 3개\n",
    "        print(f\"\\n  {action.priority.value.upper()}: {action.description}\")\n",
    "        print(f\"    - 대상 노드: {action.target_node.value}\")\n",
    "        print(f\"    - 목표 지표: {action.target_metric.value}\")\n",
    "        print(f\"    - 예상 개선: +{action.expected_metric_improvement:.2%}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n 평가 중 오류: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be2833f",
   "metadata": {},
   "source": [
    "## 6. 마무리 및 핵심 요약\n",
    "\n",
    "### 6.1 학습 목표 달성\n",
    "\n",
    "**1. Agentic RAG 구현**\n",
    "- LangGraph StateGraph로 Intent → Complexity → Retrieve → Generate 워크플로우 구축\n",
    "- LangChain v1 `create_agent` 패턴 적용\n",
    "- Tool 기반 검색 (vector_search, web_search, query_rewrite 등)\n",
    "\n",
    "**2. RAGAS 4대 지표 이해 및 평가**\n",
    "- Context Precision/Recall, Faithfulness, Answer Relevancy 측정\n",
    "- 노드별 지표 매핑 (Retrieval→Recall, Reranking→Precision 등)\n",
    "\n",
    "**3. 프로덕션 패턴 적용**\n",
    "- 미들웨어 (오류 처리, 로깅, 재귀 한도)\n",
    "- 체크포인터 (대화 이력 유지)\n",
    "- 모듈화 (tools.py, middleware.py, graph.py, evaluation.py)\n",
    "\n",
    "**4. 자동 개선 엔진**\n",
    "- RAGAS 결과 → 개선 액션 자동 생성\n",
    "- 우선순위별 개선 계획 (CRITICAL/HIGH/MEDIUM/LOW)\n",
    "- A/B 테스트 준비\n",
    "\n",
    "\n",
    "### 6.2 핵심 아키텍처 패턴\n",
    "\n",
    "```\n",
    "[사용자 질문]\n",
    "       ↓\n",
    "[Intent Classification] ← 의도 파악\n",
    "       ↓\n",
    "[Complexity Analysis] ← 복잡도 분석\n",
    "       ↓\n",
    "[Agent (Tools)] ← 자율적 검색/실행\n",
    "       ↓\n",
    "[Grade Documents] ← 관련성 평가\n",
    "       ↓\n",
    " (필요시) [Rewrite] → 재검색 루프\n",
    "       ↓\n",
    "[Generate Answer] ← 최종 답변\n",
    "       ↓\n",
    "[RAGAS Evaluation] ← 4대 지표 평가\n",
    "       ↓\n",
    "[AutoImprovement] ← 개선 계획 생성\n",
    "```\n",
    "\n",
    "### 6.3 실무 적용 가이드\n",
    "\n",
    "**Phase 1: 기본 RAG 구축**\n",
    "- Simple Vector Search → Hybrid Search\n",
    "- 기본 프롬프트 엔지니어링\n",
    "\n",
    "**Phase 2: Agentic RAG 도입**\n",
    "- Intent Classification 추가\n",
    "- Adaptive Retrieval (복잡도별 전략)\n",
    "- Tool 기반 확장\n",
    "\n",
    "**Phase 3: 평가 및 개선**\n",
    "- RAGAS 4대 지표 정기 측정\n",
    "- AutoImprovementEngine으로 병목 식별\n",
    "- A/B 테스트로 개선 효과 검증\n",
    "\n",
    "**Phase 4: 프로덕션 운영**\n",
    "- LangFuse 등 LLMOps 도구로 추적/모니터링\n",
    "- 체크포인터, Mem0 로 대화 이력, 장기메모리 관리\n",
    "- 미들웨어로 안정성 강화\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
