{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72b75262",
   "metadata": {},
   "source": [
    "# Making Retrievers\n",
    "\n",
    "`langchain-core.retrievers`의 `BaseRetriever`를 상속하여 여러가지 개념의 커스텀 리트리버를 구현합니다.  \n",
    "왜 직접 구현하냐?  \n",
    "LangChain V1.0 이 되면서 모든 구현체들이 langchain-classic 으로 묶음이 되었습니다.  \n",
    "더이상 지원하지 않겠다는 뜻이고, V2.0 이 언제될진 모르겠으나 그때 지워진다는 의미로 보시면 됩니다.  \n",
    "\n",
    "## 학습 목표\n",
    "\n",
    "1. **MultiQueryRetriever**: LLM으로 쿼리를 여러 버전으로 변형하여 검색 재현율 향상\n",
    "2. **ConvexEnsembleRetriever**: 여러 검색기의 결과를 가중 결합(Convex Combination)\n",
    "3. **MultiVectorRetriever**: 여러 벡터를 활용해 검색을 다중으로 수행할 수 있는 구조\n",
    "4. **EnsembleRetriever**: Convex Combination, RRF 를 동시에 쓸 수 있는 EnsembleRetriever 구현체\n",
    "5. **점수 정규화 전략**: Min-Max, Reciprocal Rank, Softmax 비교\n",
    "\n",
    "## 참고 자료\n",
    "\n",
    "- [Multi-Query 개념](https://wikidocs.net/234109)\n",
    "- [Multi-Vector 개념](https://wikidocs.net/234281)\n",
    "- [Convex Combination](https://wikidocs.net/263833)\n",
    "\n",
    "## langchain-classic vs langchain-core\n",
    "\n",
    "본 구현은 `langchain-classic`을 사용하지 않고 `langchain-core`의 `BaseRetriever`만으로 구현합니다.\n",
    "\n",
    "| 패키지 | 상태 | 사용 여부 |\n",
    "|--------|------|-----------|\n",
    "| langchain-classic | Legacy | 사용 안함 - LangChain v0.X 버전용 |\n",
    "| langchain-core | 최신 | O 사용 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23814f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_core.runnables import Runnable\n",
    "from pydantic import ConfigDict, Field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71e39bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# OpenAI / OpenRouter 모델 초기화 헬퍼\n",
    "# ----------------------------------------------------------------------------\n",
    "from typing import Literal\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def _resolve_api_context() -> tuple[str, str]:\n",
    "    \"\"\"선택된 API 키와 베이스 URL 정보를 반환합니다.\"\"\"\n",
    "    api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise RuntimeError(\"OPENROUTER_API_KEY가 필요합니다.\")\n",
    "\n",
    "    base_url = os.getenv(\"OPENROUTER_API_BASE\") or \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "    return (api_key, base_url)\n",
    "\n",
    "\n",
    "def create_openrouter_llm(\n",
    "    model: str = \"openai/gpt-4.1-mini\",\n",
    "    temperature: float = 0.3,\n",
    "    max_tokens: int | None = None,\n",
    "    **kwargs,\n",
    ") -> ChatOpenAI:\n",
    "    \"\"\"OpenAI 호환 LLM 생성 헬퍼.\n",
    "\n",
    "    Args:\n",
    "        model: 모델 이름. OpenRouter에서는 provider/model 형식 사용 가능\n",
    "               (예: openai/gpt-4o, anthropic/claude-3-sonnet, google/gemini-pro)\n",
    "        temperature: 생성 온도 (0.0-2.0)\n",
    "        max_tokens: 최대 생성 토큰 수\n",
    "\n",
    "    Returns:\n",
    "        ChatOpenAI: 설정된 LLM 인스턴스\n",
    "    \"\"\"\n",
    "    api_key, base_url = _resolve_api_context()\n",
    "\n",
    "    openai_kwargs: dict = {\n",
    "        \"model\": model,\n",
    "        \"api_key\": api_key,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_retries\": 3,\n",
    "        \"timeout\": 60,\n",
    "        **kwargs,\n",
    "    }\n",
    "    if max_tokens is not None:\n",
    "        openai_kwargs[\"max_tokens\"] = max_tokens\n",
    "    if base_url:\n",
    "        openai_kwargs[\"base_url\"] = base_url\n",
    "    return ChatOpenAI(**openai_kwargs)\n",
    "\n",
    "\n",
    "def create_embedding_model(\n",
    "    model: str = \"openai/text-embedding-3-small\",\n",
    "    **kwargs,\n",
    ") -> OpenAIEmbeddings:\n",
    "    \"\"\"OpenAI 호환 임베딩 모델 생성.\n",
    "\n",
    "    Args:\n",
    "        model: 임베딩 모델 이름. OpenRouter에서는 provider/model 형식 사용 가능\n",
    "               (예: openai/text-embedding-3-small, openai/text-embedding-3-large)\n",
    "        **kwargs: 추가 파라미터 (encoding_format 등은 model_kwargs로 전달됨)\n",
    "\n",
    "    Returns:\n",
    "        OpenAIEmbeddings: 설정된 임베딩 모델 인스턴스\n",
    "    \"\"\"\n",
    "    api_key, base_url = _resolve_api_context()\n",
    "\n",
    "    # 전달받은 kwargs에서 model_kwargs로 전달할 파라미터 분리\n",
    "    # encoding_format, extra_headers 등은 model_kwargs로 전달\n",
    "    model_kwargs: dict = {}\n",
    "    embedding_kwargs: dict = {\n",
    "        \"model\": model,\n",
    "        \"api_key\": api_key,\n",
    "        \"show_progress_bar\": True,\n",
    "        \"skip_empty\": True,\n",
    "    }\n",
    "\n",
    "    # 전달받은 kwargs 처리\n",
    "    for key, value in kwargs.items():\n",
    "        # OpenRouter API 특정 파라미터는 model_kwargs로 전달\n",
    "        if key in (\"encoding_format\"):\n",
    "            model_kwargs[key] = value\n",
    "        else:\n",
    "            # 나머지는 OpenAIEmbeddings에 직접 전달\n",
    "            embedding_kwargs[key] = value\n",
    "\n",
    "    if base_url:\n",
    "        embedding_kwargs[\"base_url\"] = base_url\n",
    "\n",
    "    # model_kwargs가 있으면 전달\n",
    "    if model_kwargs:\n",
    "        embedding_kwargs[\"model_kwargs\"] = model_kwargs\n",
    "\n",
    "    return OpenAIEmbeddings(**embedding_kwargs)\n",
    "\n",
    "\n",
    "def create_embedding_model_direct(\n",
    "    model: str = \"qwen/qwen3-embedding-0.6b\",\n",
    "    encoding_format: Literal[\"float\", \"base64\"] = \"float\",\n",
    "    input_text: str | list[str] = \"\",\n",
    "    **kwargs,\n",
    ") -> list[float] | list[list[float]]:\n",
    "    \"\"\"OpenAI SDK를 직접 사용하여 임베딩 생성 (encoding_format 지원).\n",
    "\n",
    "    LangChain의 OpenAIEmbeddings가 encoding_format을 지원하지 않을 때 사용.\n",
    "\n",
    "    Args:\n",
    "        model: 임베딩 모델 이름\n",
    "        encoding_format: 인코딩 형식 (\"float\")\n",
    "        input_text: 임베딩할 텍스트 (문자열 또는 문자열 리스트)\n",
    "        **kwargs: 추가 파라미터\n",
    "\n",
    "    Returns:\n",
    "        임베딩 벡터 리스트 (단일 텍스트) 또는 리스트의 리스트 (여러 텍스트)\n",
    "    \"\"\"\n",
    "    from openai import OpenAI\n",
    "\n",
    "    api_key, base_url = _resolve_api_context()\n",
    "\n",
    "    client = OpenAI(\n",
    "        base_url=base_url,\n",
    "        api_key=api_key,\n",
    "    )\n",
    "\n",
    "    # input_text가 비어있으면 kwargs에서 가져오기\n",
    "    if not input_text:\n",
    "        input_text = kwargs.get(\"input\", \"\")\n",
    "\n",
    "    response = client.embeddings.create(\n",
    "        model=model,\n",
    "        input=input_text,\n",
    "        encoding_format=encoding_format,\n",
    "    )\n",
    "\n",
    "    # 단일 텍스트인 경우 첫 번째 임베딩 반환\n",
    "    if isinstance(input_text, str):\n",
    "        return response.data[0].embedding\n",
    "    else:\n",
    "        # 여러 텍스트인 경우 모든 임베딩 반환\n",
    "        return [item.embedding for item in response.data]\n",
    "\n",
    "\n",
    "def get_available_model_types() -> dict[str, list[str]]:\n",
    "    \"\"\"OpenRouter에서 사용 가능한 모델 유형을 반환합니다.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, list[str]]: 모델 유형별 모델 목록\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"chat\": [\n",
    "            \"openai/gpt-4.1\",\n",
    "            \"openai/gpt-4.1-mini\",\n",
    "            \"openai/gpt-5\",\n",
    "            \"openai/gpt-5-mini\",\n",
    "            \"anthropic/claude-sonnet-4.5\",\n",
    "            \"anthropic/claude-haiku-4.5\",\n",
    "            \"google/gemini-2.5-flash-preview-09-2025\",\n",
    "            \"google/gemini-pro-2.5\",\n",
    "            \"x-ai/grok-4-fast\",\n",
    "            \"moonshotai/kimi-k2-thinking\",\n",
    "            \"liquid/lfm-2.2-6b\",\n",
    "            \"z-ai/glm-4.6\",\n",
    "        ],\n",
    "        \"embedding\": [\n",
    "            \"openai/text-embedding-3-small\",\n",
    "            \"openai/text-embedding-3-large\",\n",
    "            \"google/gemini-embedding-001\",\n",
    "            \"qwen/qwen3-embedding-0.6b\",\n",
    "            \"qwen/qwen3-embedding-4b\",\n",
    "            \"qwen/qwen3-embedding-8b\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "\n",
    "embeddings = create_embedding_model()\n",
    "llm = create_openrouter_llm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31158fc6",
   "metadata": {},
   "source": [
    "### MultiQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2de946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiQueryRetriever(BaseRetriever):\n",
    "    \"\"\"\n",
    "    Multi-Query Retriever: LLM을 사용하여 쿼리를 여러 버전으로 변형하고\n",
    "    각각 검색한 결과를 결합합니다.\n",
    "\n",
    "    장점:\n",
    "    - 단일 쿼리의 한계를 극복\n",
    "    - 다양한 표현으로 재현율(Recall) 향상\n",
    "    - 쿼리 의도의 다각적 해석\n",
    "\n",
    "    단점:\n",
    "    - LLM 호출 비용\n",
    "    - 레이턴시 증가\n",
    "    \"\"\"\n",
    "\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "\n",
    "    base_retriever: BaseRetriever = Field(description=\"기본 검색기\")\n",
    "    llm: Runnable = Field(description=\"쿼리 생성용 LLM\")\n",
    "    num_queries: int = Field(default=4, description=\"생성할 쿼리 개수\")\n",
    "    merge_strategy: str = Field(default=\"rrf\", description=\"결합 전략: rrf, max, sum\")\n",
    "    rrf_k: int = Field(default=60, description=\"RRF 상수\")\n",
    "    include_original: bool = Field(default=True, description=\"원본 쿼리 포함 여부\")\n",
    "\n",
    "    def _generate_queries(self, query: str) -> list[str]:\n",
    "        \"\"\"LLM으로 쿼리 변형 생성\"\"\"\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\n",
    "                    \"system\",\n",
    "                    \"\"\"당신은 검색 쿼리 전문가입니다.\n",
    "사용자의 질문을 다양한 관점에서 재구성하여 {num} 개의 문서 검색용 질문을 생성하세요.\n",
    "\n",
    "[요구사항]\n",
    "- 원본 질문의 핵심 의도를 유지하되, 다른 표현 사용\n",
    "- 구체적이고 명확한 쿼리\n",
    "- 각 쿼리는 한 줄로 작성\n",
    "- 번호나 불릿 없이 쿼리만 작성\n",
    "- 각 쿼리는 새 줄로 구분\n",
    "\n",
    "예시:\n",
    "입력: \"연차휴가는 어떻게 계산되나요?\"\n",
    "출력:\n",
    "연차 유급휴가 계산 방법\\n\n",
    "근로자 연차 일수 산정 기준\\n\n",
    "1년 근무 시 연차 개수\\n\n",
    "연차휴가 발생 조건\"\"\",\n",
    "                ),\n",
    "                (\"user\", \"{query}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        chain = prompt | self.llm | StrOutputParser()\n",
    "\n",
    "        try:\n",
    "            result = chain.invoke({\"query\": query, \"num\": self.num_queries})\n",
    "\n",
    "            # 결과 파싱 (줄바꿈으로 분리)\n",
    "            queries = [q.strip() for q in result.split(\"\\n\") if q.strip()]\n",
    "\n",
    "            # 개수 제한\n",
    "            queries = queries[: self.num_queries]\n",
    "\n",
    "            # 원본 쿼리 포함\n",
    "            if self.include_original:\n",
    "                queries = [query] + queries\n",
    "\n",
    "            return queries\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"쿼리 생성 실패: {e}\")\n",
    "            return [query]  # 실패 시 원본만 반환\n",
    "\n",
    "    def _merge_results(\n",
    "        self,\n",
    "        results_list: list[list[Document]],\n",
    "    ) -> list[Document]:\n",
    "        \"\"\"여러 검색 결과를 결합\"\"\"\n",
    "\n",
    "        if self.merge_strategy == \"rrf\":\n",
    "            return self._rrf_merge(results_list)\n",
    "        elif self.merge_strategy == \"max\":\n",
    "            return self._max_merge(results_list)\n",
    "        elif self.merge_strategy == \"sum\":\n",
    "            return self._sum_merge(results_list)\n",
    "        else:\n",
    "            # 기본값: RRF\n",
    "            return self._rrf_merge(results_list)\n",
    "\n",
    "    def _rrf_merge(self, results_list: list[list[Document]]) -> list[Document]:\n",
    "        \"\"\"Reciprocal Rank Fusion\"\"\"\n",
    "        doc_scores = {}\n",
    "        doc_objects = {}\n",
    "\n",
    "        for results in results_list:\n",
    "            for rank, doc in enumerate(results, start=1):\n",
    "                doc_id = hash(doc.page_content)\n",
    "\n",
    "                if doc_id not in doc_scores:\n",
    "                    doc_scores[doc_id] = 0.0\n",
    "                    doc_objects[doc_id] = doc\n",
    "\n",
    "                # RRF 점수: 1 / (k + rank)\n",
    "                doc_scores[doc_id] += 1.0 / (self.rrf_k + rank)\n",
    "\n",
    "        # 점수 기준 정렬\n",
    "        sorted_docs = sorted(\n",
    "            doc_scores.items(),\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True,\n",
    "        )\n",
    "\n",
    "        # 메타데이터에 점수 추가\n",
    "        results = []\n",
    "        for doc_id, score in sorted_docs:\n",
    "            doc = doc_objects[doc_id]\n",
    "            new_metadata = {**doc.metadata, \"rrf_score\": score}\n",
    "            new_doc = Document(\n",
    "                page_content=doc.page_content,\n",
    "                metadata=new_metadata,\n",
    "            )\n",
    "            results.append(new_doc)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def _max_merge(self, results_list: list[list[Document]]) -> list[Document]:\n",
    "        \"\"\"최대 점수 선택 (점수가 메타데이터에 있다고 가정)\"\"\"\n",
    "        doc_scores = {}\n",
    "        doc_objects = {}\n",
    "\n",
    "        for results in results_list:\n",
    "            for doc in results:\n",
    "                doc_id = hash(doc.page_content)\n",
    "                score = doc.metadata.get(\"score\", 0.0)\n",
    "\n",
    "                if doc_id not in doc_scores or score > doc_scores[doc_id]:\n",
    "                    doc_scores[doc_id] = score\n",
    "                    doc_objects[doc_id] = doc\n",
    "\n",
    "        sorted_docs = sorted(\n",
    "            doc_scores.items(),\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True,\n",
    "        )\n",
    "\n",
    "        return [doc_objects[doc_id] for doc_id, _ in sorted_docs]\n",
    "\n",
    "    def _sum_merge(self, results_list: list[list[Document]]) -> list[Document]:\n",
    "        \"\"\"점수 합계\"\"\"\n",
    "        doc_scores = {}\n",
    "        doc_objects = {}\n",
    "\n",
    "        for results in results_list:\n",
    "            for doc in results:\n",
    "                doc_id = hash(doc.page_content)\n",
    "                score = doc.metadata.get(\"score\", 1.0)\n",
    "\n",
    "                if doc_id not in doc_scores:\n",
    "                    doc_scores[doc_id] = 0.0\n",
    "                    doc_objects[doc_id] = doc\n",
    "\n",
    "                doc_scores[doc_id] += score\n",
    "\n",
    "        sorted_docs = sorted(\n",
    "            doc_scores.items(),\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True,\n",
    "        )\n",
    "\n",
    "        return [doc_objects[doc_id] for doc_id, _ in sorted_docs]\n",
    "\n",
    "    def _get_relevant_documents(\n",
    "        self,\n",
    "        query: str,\n",
    "        *,\n",
    "        run_manager: CallbackManagerForRetrieverRun | None = None,\n",
    "    ) -> list[Document]:\n",
    "        \"\"\"검색 실행\"\"\"\n",
    "        # 1. 쿼리 변형 생성\n",
    "        queries = self._generate_queries(query)\n",
    "\n",
    "        print(f\"\\n생성된 쿼리 {len(queries)}개:\")\n",
    "        for idx, q in enumerate(queries, 1):\n",
    "            print(f\"  {idx}. {q}\")\n",
    "\n",
    "        # 2. 각 쿼리로 검색\n",
    "        results_list = []\n",
    "        for q in queries:\n",
    "            results = self.base_retriever.invoke(q)\n",
    "            results_list.append(results)\n",
    "\n",
    "        # 3. 결과 병합\n",
    "        merged = self._merge_results(results_list)\n",
    "\n",
    "        return merged\n",
    "\n",
    "    async def _aget_relevant_documents(\n",
    "        self,\n",
    "        query: str,\n",
    "        *,\n",
    "        run_manager: CallbackManagerForRetrieverRun | None = None,\n",
    "    ) -> list[Document]:\n",
    "        \"\"\"비동기 검색 실행\"\"\"\n",
    "        # 1. 쿼리 변형 생성\n",
    "        queries = self._generate_queries(query)\n",
    "\n",
    "        # 2. 병렬 검색\n",
    "        tasks = [self.base_retriever.ainvoke(q) for q in queries]\n",
    "        results_list = await asyncio.gather(*tasks)\n",
    "\n",
    "        # 3. 결과 병합\n",
    "        merged = self._merge_results(results_list)\n",
    "\n",
    "        return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe45099",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # 베이스 리트리버 (KiwiBM25 사용)\n",
    "    base_retriever = KiwiBM25Retriever.from_documents(\n",
    "        documents=sample_docs,\n",
    "        k=5,\n",
    "    )\n",
    "\n",
    "    # MultiQueryRetriever 생성\n",
    "    multi_query_retriever = MultiQueryRetriever(\n",
    "        base_retriever=base_retriever,\n",
    "        llm=llm,\n",
    "        num_queries=3,\n",
    "        merge_strategy=\"rrf\",\n",
    "        include_original=True,\n",
    "    )\n",
    "\n",
    "    # 테스트 쿼리\n",
    "    test_query = \"휴가는 얼마나 받을 수 있나요?\"\n",
    "\n",
    "    print(f\"\\n원본 쿼리: {test_query}\")\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "    # 검색 실행\n",
    "    results = multi_query_retriever.invoke(test_query)\n",
    "\n",
    "    print(\"\\n최종 결과 (Top-3):\")\n",
    "    for idx, doc in enumerate(results[:3], 1):\n",
    "        rrf_score = doc.metadata.get(\"rrf_score\", 0)\n",
    "        print(f\"\\n[{idx}] RRF 점수: {rrf_score:.6f}\")\n",
    "        print(f\"    내용: {doc.page_content[:80]}...\")\n",
    "        print(f\"    출처: {doc.metadata.get('source', 'N/A')}\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"⚠️  OpenAI 패키지가 설치되지 않았습니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️  데모 실행 실패: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d475294",
   "metadata": {},
   "source": [
    "### ConvexEnsembleRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e8b3fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvexEnsembleRetriever(BaseRetriever):\n",
    "    \"\"\"\n",
    "    Convex Ensemble Retriever: 여러 검색기의 결과를 가중 결합합니다.\n",
    "\n",
    "    Convex Combination:\n",
    "    - 최종 점수 = Σ (weight_i × normalized_score_i)\n",
    "    - 가중치 합 = 1.0 (Convex 조건)\n",
    "\n",
    "    점수 정규화 전략:\n",
    "    1. Min-Max: (score - min) / (max - min)\n",
    "    2. Reciprocal Rank: 1 / rank\n",
    "    3. Softmax: exp(score) / Σ exp(scores)\n",
    "\n",
    "    장점:\n",
    "    - 각 검색기의 강점 활용\n",
    "    - 가중치 조절로 도메인 최적화\n",
    "    - 점수 스케일 불일치 해결\n",
    "\n",
    "    참고:\n",
    "    - https://wikidocs.net/263833\n",
    "    - https://github.com/teddylee777/langchain-teddynote\n",
    "    \"\"\"\n",
    "\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "\n",
    "    retrievers: list[BaseRetriever] = Field(description=\"검색기 리스트\")\n",
    "    weights: list[float] = Field(description=\"가중치 리스트\")\n",
    "    normalize_strategy: str = Field(\n",
    "        default=\"reciprocal_rank\",\n",
    "        description=\"정규화 전략: min_max, reciprocal_rank, softmax\",\n",
    "    )\n",
    "    c: int = Field(\n",
    "        default=60,\n",
    "        description=\"Reciprocal Rank 상수\",\n",
    "    )\n",
    "\n",
    "    def __init__(self, **data):\n",
    "        super().__init__(**data)\n",
    "\n",
    "        # 가중치 검증\n",
    "        if len(self.retrievers) != len(self.weights):\n",
    "            raise ValueError(\"검색기와 가중치 개수가 일치해야 합니다.\")\n",
    "\n",
    "        # Convex 조건 검증 (가중치 합 = 1.0)\n",
    "        weight_sum = sum(self.weights)\n",
    "        if not (0.99 <= weight_sum <= 1.01):\n",
    "            print(f\"⚠️  가중치 합이 {weight_sum:.3f}입니다. 1.0으로 정규화합니다.\")\n",
    "            self.weights = [w / weight_sum for w in self.weights]\n",
    "\n",
    "    def _normalize_scores(\n",
    "        self,\n",
    "        docs_with_scores: list[tuple[Document, float]],\n",
    "    ) -> list[tuple[Document, float]]:\n",
    "        \"\"\"점수 정규화\"\"\"\n",
    "\n",
    "        if not docs_with_scores:\n",
    "            return []\n",
    "\n",
    "        if self.normalize_strategy == \"min_max\":\n",
    "            return self._min_max_normalize(docs_with_scores)\n",
    "        elif self.normalize_strategy == \"reciprocal_rank\":\n",
    "            return self._reciprocal_rank_normalize(docs_with_scores)\n",
    "        elif self.normalize_strategy == \"softmax\":\n",
    "            return self._softmax_normalize(docs_with_scores)\n",
    "        else:\n",
    "            # 기본값: reciprocal rank\n",
    "            return self._reciprocal_rank_normalize(docs_with_scores)\n",
    "\n",
    "    def _min_max_normalize(\n",
    "        self,\n",
    "        docs_with_scores: list[tuple[Document, float]],\n",
    "    ) -> list[tuple[Document, float]]:\n",
    "        \"\"\"Min-Max 정규화: [0, 1] 범위로 스케일링\"\"\"\n",
    "        scores = [score for _, score in docs_with_scores]\n",
    "\n",
    "        min_score = min(scores)\n",
    "        max_score = max(scores)\n",
    "\n",
    "        if max_score - min_score < 1e-6:\n",
    "            # 모든 점수가 같으면 동일 점수 부여\n",
    "            return [(doc, 1.0) for doc, _ in docs_with_scores]\n",
    "\n",
    "        normalized = []\n",
    "        for doc, score in docs_with_scores:\n",
    "            norm_score = (score - min_score) / (max_score - min_score)\n",
    "            normalized.append((doc, norm_score))\n",
    "\n",
    "        return normalized\n",
    "\n",
    "    def _reciprocal_rank_normalize(\n",
    "        self,\n",
    "        docs_with_scores: list[tuple[Document, float]],\n",
    "    ) -> list[tuple[Document, float]]:\n",
    "        \"\"\"Reciprocal Rank 정규화: 순위 기반\"\"\"\n",
    "        # 점수 기준 정렬\n",
    "        sorted_docs = sorted(\n",
    "            docs_with_scores,\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True,\n",
    "        )\n",
    "\n",
    "        normalized = []\n",
    "        for rank, (doc, _) in enumerate(sorted_docs, start=1):\n",
    "            # 1 / (c + rank)\n",
    "            norm_score = 1.0 / (self.c + rank)\n",
    "            normalized.append((doc, norm_score))\n",
    "\n",
    "        # 원래 순서로 복원 (hash 기반)\n",
    "        doc_score_map = {hash(doc.page_content): score for doc, score in normalized}\n",
    "\n",
    "        result = []\n",
    "        for doc, _ in docs_with_scores:\n",
    "            norm_score = doc_score_map.get(hash(doc.page_content), 0.0)\n",
    "            result.append((doc, norm_score))\n",
    "\n",
    "        return result\n",
    "\n",
    "    def _softmax_normalize(\n",
    "        self,\n",
    "        docs_with_scores: list[tuple[Document, float]],\n",
    "    ) -> list[tuple[Document, float]]:\n",
    "        \"\"\"Softmax 정규화: 확률 분포로 변환\"\"\"\n",
    "        scores = np.array([score for _, score in docs_with_scores])\n",
    "\n",
    "        # Softmax\n",
    "        exp_scores = np.exp(scores - np.max(scores))\n",
    "        softmax_scores = exp_scores / exp_scores.sum()\n",
    "\n",
    "        normalized = []\n",
    "        for (doc, _), norm_score in zip(docs_with_scores, softmax_scores, strict=False):\n",
    "            normalized.append((doc, float(norm_score)))\n",
    "\n",
    "        return normalized\n",
    "\n",
    "    def _weighted_fusion(\n",
    "        self,\n",
    "        results_list: list[list[tuple[Document, float]]],\n",
    "    ) -> list[Document]:\n",
    "        \"\"\"가중 결합 (Convex Combination)\"\"\"\n",
    "\n",
    "        # 각 검색기의 결과 정규화\n",
    "        normalized_results = []\n",
    "        for results in results_list:\n",
    "            normalized = self._normalize_scores(results)\n",
    "            normalized_results.append(normalized)\n",
    "\n",
    "        # 문서별 가중 점수 계산\n",
    "        doc_scores = {}\n",
    "        doc_objects = {}\n",
    "\n",
    "        for weight, results in zip(self.weights, normalized_results, strict=False):\n",
    "            for doc, norm_score in results:\n",
    "                doc_id = hash(doc.page_content)\n",
    "\n",
    "                if doc_id not in doc_scores:\n",
    "                    doc_scores[doc_id] = 0.0\n",
    "                    doc_objects[doc_id] = doc\n",
    "\n",
    "                # Convex Combination: Σ (weight_i × score_i)\n",
    "                doc_scores[doc_id] += weight * norm_score\n",
    "\n",
    "        # 점수 기준 정렬\n",
    "        sorted_docs = sorted(\n",
    "            doc_scores.items(),\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True,\n",
    "        )\n",
    "\n",
    "        # 메타데이터에 점수 추가\n",
    "        results = []\n",
    "        for doc_id, score in sorted_docs:\n",
    "            doc = doc_objects[doc_id]\n",
    "            new_metadata = {**doc.metadata, \"convex_score\": score}\n",
    "            new_doc = Document(\n",
    "                page_content=doc.page_content,\n",
    "                metadata=new_metadata,\n",
    "            )\n",
    "            results.append(new_doc)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def _get_relevant_documents(\n",
    "        self,\n",
    "        query: str,\n",
    "        *,\n",
    "        run_manager: CallbackManagerForRetrieverRun | None = None,\n",
    "    ) -> list[Document]:\n",
    "        \"\"\"검색 실행\"\"\"\n",
    "        # 각 검색기로 검색\n",
    "        results_list = []\n",
    "\n",
    "        for idx, retriever in enumerate(self.retrievers):\n",
    "            # 검색 실행\n",
    "            docs = retriever.invoke(query)\n",
    "\n",
    "            # 점수 추출 (메타데이터 또는 기본값 1.0)\n",
    "            docs_with_scores = []\n",
    "            for doc in docs:\n",
    "                score = doc.metadata.get(\"score\", 1.0)\n",
    "                docs_with_scores.append((doc, score))\n",
    "\n",
    "            results_list.append(docs_with_scores)\n",
    "\n",
    "        # 가중 결합\n",
    "        merged = self._weighted_fusion(results_list)\n",
    "\n",
    "        return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1556499",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "앙상블 리트리버: 여러 리트리버의 결과를 결합하는 검색기\n",
    "\n",
    "이 모듈은 두 가지 앙상블 방법을 지원합니다:\n",
    "\n",
    "1. RRF (Reciprocal Rank Fusion): 순위 기반 점수 융합\n",
    "   - 각 검색기의 순위를 활용하여 점수 계산\n",
    "   - 순위만 필요하므로 실제 유사도 점수가 없어도 사용 가능\n",
    "   - 공식: score = Σ(weight_i / (rank_i + c))\n",
    "\n",
    "2. CC (Convex Combination): 볼록 조합 - 정규화된 점수의 가중 평균\n",
    "   - 각 검색기의 실제 유사도 점수를 정규화하여 가중 평균\n",
    "   - 가중치의 합이 1이어야 함 (볼록 조합의 수학적 정의)\n",
    "   - 공식: score = Σ(weight_i * normalized_score_i)\n",
    "\"\"\"\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections.abc import Callable, Hashable, Iterable, Iterator\n",
    "from enum import Enum\n",
    "from itertools import chain\n",
    "from typing import (\n",
    "    Any,\n",
    "    TypeVar,\n",
    "    cast,\n",
    ")\n",
    "\n",
    "from langchain_core.callbacks import (\n",
    "    AsyncCallbackManagerForRetrieverRun,\n",
    "    CallbackManagerForRetrieverRun,\n",
    ")\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.retrievers import BaseRetriever, RetrieverLike\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.runnables.config import ensure_config, patch_config\n",
    "from langchain_core.runnables.utils import (\n",
    "    ConfigurableFieldSpec,\n",
    "    get_unique_config_specs,\n",
    ")\n",
    "from pydantic import model_validator\n",
    "\n",
    "# 타입 변수: 제네릭 타입을 위한 선언\n",
    "T = TypeVar(\"T\")  # 임의의 타입\n",
    "H = TypeVar(\"H\", bound=Hashable)  # 해시 가능한 타입 (dict의 키로 사용 가능)\n",
    "\n",
    "\n",
    "class EnsembleMethod(str, Enum):\n",
    "    \"\"\"앙상블 방법을 정의하는 열거형\n",
    "\n",
    "    RRF: Reciprocal Rank Fusion - 순위 기반 융합\n",
    "    CC: Convex Combination - 볼록 조합 (점수 기반 융합)\n",
    "    \"\"\"\n",
    "\n",
    "    RRF = \"rrf\"\n",
    "    CC = \"cc\"\n",
    "\n",
    "\n",
    "def unique_by_key(iterable: Iterable[T], key: Callable[[T], H]) -> Iterator[T]:\n",
    "    \"\"\"주어진 키 함수를 기준으로 iterable에서 고유한 요소만 반환\n",
    "\n",
    "    중복 제거 로직:\n",
    "    - 각 요소에 대해 key 함수를 적용하여 고유 식별자 생성\n",
    "    - 이미 본 식별자는 건너뛰고, 처음 보는 식별자만 yield\n",
    "\n",
    "    예시:\n",
    "        docs = [doc1, doc2, doc1, doc3]  # doc1이 중복\n",
    "        unique_docs = unique_by_key(docs, lambda d: d.id)\n",
    "        # 결과: [doc1, doc2, doc3]\n",
    "\n",
    "    Args:\n",
    "        iterable: 필터링할 iterable 객체\n",
    "        key: 각 요소에서 해시 가능한 키를 추출하는 함수\n",
    "\n",
    "    Yields:\n",
    "        키 함수 기준으로 중복이 제거된 고유한 요소들\n",
    "    \"\"\"\n",
    "    seen = set()  # 이미 본 키들을 저장하는 집합\n",
    "    for e in iterable:\n",
    "        if (k := key(e)) not in seen:  # Walrus 연산자: 할당과 동시에 조건 검사\n",
    "            seen.add(k)  # 새로운 키를 집합에 추가\n",
    "            yield e  # 고유한 요소 반환\n",
    "\n",
    "\n",
    "class EnsembleRetriever(BaseRetriever):\n",
    "    \"\"\"여러 리트리버의 결과를 앙상블하는 리트리버\n",
    "\n",
    "    두 가지 앙상블 방법을 지원:\n",
    "    1. RRF (Reciprocal Rank Fusion): 순위 기반 융합\n",
    "    2. CC (Convex Combination): 볼록 조합 방식의 점수 기반 융합\n",
    "\n",
    "    사용 예시:\n",
    "        # BM25와 Dense Retriever를 3:7 비율로 결합 (CC 방법)\n",
    "        ensemble = EnsembleRetriever(\n",
    "            retrievers=[bm25_retriever, dense_retriever],\n",
    "            weights=[0.3, 0.7],  # CC 방법은 합이 1이어야 함\n",
    "            method=EnsembleMethod.CC\n",
    "        )\n",
    "\n",
    "        # RRF 방법으로 동일 가중치 적용\n",
    "        ensemble = EnsembleRetriever(\n",
    "            retrievers=[bm25_retriever, dense_retriever],\n",
    "            weights=[1.0, 1.0],  # RRF는 합이 1일 필요 없음\n",
    "            method=EnsembleMethod.RRF,\n",
    "            c=60  # RRF 상수\n",
    "        )\n",
    "\n",
    "    Args:\n",
    "        retrievers: 앙상블할 리트리버들의 리스트\n",
    "        weights: 각 리트리버에 대응하는 가중치 리스트\n",
    "                 CC 방법 사용 시 반드시 합이 1이어야 함\n",
    "        method: 사용할 앙상블 방법 (\"rrf\" 또는 \"cc\")\n",
    "        c: RRF 방법에서 사용할 상수. 기본값 60\n",
    "           - 작을수록 상위 순위에 더 큰 가중치\n",
    "           - 클수록 순위 간 점수 차이가 완만해짐\n",
    "        id_key: 문서 고유성 판단에 사용할 metadata의 키\n",
    "                지정하지 않으면 page_content를 사용\n",
    "    \"\"\"\n",
    "\n",
    "    retrievers: list[RetrieverLike]  # 앙상블할 리트리버 목록\n",
    "    weights: list[float]  # 각 리트리버의 가중치\n",
    "    method: EnsembleMethod = EnsembleMethod.RRF  # 앙상블 방법 (기본: RRF)\n",
    "    c: int = 60  # RRF 상수\n",
    "    id_key: str | None = None  # 문서 고유 식별 키\n",
    "\n",
    "    @model_validator(mode=\"before\")\n",
    "    @classmethod\n",
    "    def validate_weights(cls, values: dict[str, Any]) -> Any:\n",
    "        \"\"\"가중치 유효성 검증\n",
    "\n",
    "        1. 가중치가 없으면 균등 가중치 자동 설정\n",
    "        2. CC 방법 사용 시 가중치 합이 1인지 검증\n",
    "\n",
    "        볼록 조합(Convex Combination)의 수학적 정의:\n",
    "        - Σw_i = 1 (가중치의 합이 1)\n",
    "        - w_i ≥ 0 (모든 가중치가 0 이상)\n",
    "        이 조건을 만족해야 결과가 입력 점수들의 볼록 포(convex hull) 내에 존재\n",
    "        \"\"\"\n",
    "        weights = values.get(\"weights\")\n",
    "        method = values.get(\"method\", EnsembleMethod.RRF)\n",
    "\n",
    "        if not weights:\n",
    "            # 가중치가 없으면 균등 분배\n",
    "            n_retrievers = len(values[\"retrievers\"])\n",
    "            values[\"weights\"] = [1 / n_retrievers] * n_retrievers\n",
    "        elif method == EnsembleMethod.CC and abs(sum(weights) - 1.0) > 1e-6:\n",
    "            # CC 방법은 가중치 합이 1이어야 함 (볼록 조합의 정의)\n",
    "            raise ValueError(\"Weights must sum to 1.0 for CC method\")\n",
    "\n",
    "        return values\n",
    "\n",
    "    @property\n",
    "    def config_specs(self) -> list[ConfigurableFieldSpec]:\n",
    "        \"\"\"이 runnable의 설정 가능한 필드 목록을 반환\"\"\"\n",
    "        return get_unique_config_specs(\n",
    "            spec for retriever in self.retrievers for spec in retriever.config_specs\n",
    "        )\n",
    "\n",
    "    def invoke(\n",
    "        self, input: str, config: RunnableConfig | None = None, **kwargs: Any\n",
    "    ) -> list[Document]:\n",
    "        from langchain_core.callbacks import CallbackManager\n",
    "\n",
    "        config = ensure_config(config)\n",
    "        callback_manager = CallbackManager.configure(\n",
    "            config.get(\"callbacks\"),\n",
    "            None,\n",
    "            verbose=kwargs.get(\"verbose\", False),\n",
    "            inheritable_tags=config.get(\"tags\", []),\n",
    "            local_tags=self.tags,\n",
    "            inheritable_metadata=config.get(\"metadata\", {}),\n",
    "            local_metadata=self.metadata,\n",
    "        )\n",
    "        run_manager = callback_manager.on_retriever_start(\n",
    "            None,\n",
    "            input,\n",
    "            name=config.get(\"run_name\") or self.get_name(),\n",
    "            **kwargs,\n",
    "        )\n",
    "        try:\n",
    "            result = self.rank_fusion(input, run_manager=run_manager, config=config)\n",
    "        except Exception as e:\n",
    "            run_manager.on_retriever_error(e)\n",
    "            raise e\n",
    "        else:\n",
    "            run_manager.on_retriever_end(\n",
    "                result,\n",
    "                **kwargs,\n",
    "            )\n",
    "            return result\n",
    "\n",
    "    async def ainvoke(\n",
    "        self, input: str, config: RunnableConfig | None = None, **kwargs: Any\n",
    "    ) -> list[Document]:\n",
    "        from langchain_core.callbacks import AsyncCallbackManager\n",
    "\n",
    "        config = ensure_config(config)\n",
    "        callback_manager = AsyncCallbackManager.configure(\n",
    "            config.get(\"callbacks\"),\n",
    "            None,\n",
    "            verbose=kwargs.get(\"verbose\", False),\n",
    "            inheritable_tags=config.get(\"tags\", []),\n",
    "            local_tags=self.tags,\n",
    "            inheritable_metadata=config.get(\"metadata\", {}),\n",
    "            local_metadata=self.metadata,\n",
    "        )\n",
    "        run_manager = await callback_manager.on_retriever_start(\n",
    "            None,\n",
    "            input,\n",
    "            name=config.get(\"run_name\") or self.get_name(),\n",
    "            **kwargs,\n",
    "        )\n",
    "        try:\n",
    "            result = await self.arank_fusion(input, run_manager=run_manager, config=config)\n",
    "        except Exception as e:\n",
    "            await run_manager.on_retriever_error(e)\n",
    "            raise e\n",
    "        else:\n",
    "            await run_manager.on_retriever_end(\n",
    "                result,\n",
    "                **kwargs,\n",
    "            )\n",
    "            return result\n",
    "\n",
    "    def _get_relevant_documents(\n",
    "        self,\n",
    "        query: str,\n",
    "        *,\n",
    "        run_manager: CallbackManagerForRetrieverRun,\n",
    "    ) -> list[Document]:\n",
    "        \"\"\"주어진 쿼리에 대해 관련 문서들을 검색\n",
    "\n",
    "        BaseRetriever의 추상 메서드 구현.\n",
    "        실제 로직은 rank_fusion 메서드에 위임.\n",
    "\n",
    "        Args:\n",
    "            query: 검색할 쿼리 문자열\n",
    "\n",
    "        Returns:\n",
    "            앙상블되어 재순위화된 문서 리스트\n",
    "        \"\"\"\n",
    "\n",
    "        # 모든 리트리버의 결과를 융합\n",
    "        fused_documents = self.rank_fusion(query, run_manager)\n",
    "\n",
    "        return fused_documents\n",
    "\n",
    "    async def _aget_relevant_documents(\n",
    "        self,\n",
    "        query: str,\n",
    "        *,\n",
    "        run_manager: AsyncCallbackManagerForRetrieverRun,\n",
    "    ) -> list[Document]:\n",
    "        \"\"\"주어진 쿼리에 대해 관련 문서들을 비동기로 검색\n",
    "\n",
    "        BaseRetriever의 비동기 추상 메서드 구현.\n",
    "        실제 로직은 arank_fusion 메서드에 위임.\n",
    "\n",
    "        Args:\n",
    "            query: 검색할 쿼리 문자열\n",
    "\n",
    "        Returns:\n",
    "            앙상블되어 재순위화된 문서 리스트\n",
    "        \"\"\"\n",
    "\n",
    "        # 모든 리트리버의 결과를 비동기로 융합\n",
    "        fused_documents = await self.arank_fusion(query, run_manager)\n",
    "\n",
    "        return fused_documents\n",
    "\n",
    "    def ensemble_results(self, doc_lists: list[list[Document]]) -> list[Document]:\n",
    "        \"\"\"RRF 또는 CC 방법을 사용하여 결과를 앙상블\n",
    "\n",
    "        여러 검색기의 결과를 하나로 융합하는 진입점.\n",
    "        설정된 method에 따라 적절한 앙상블 함수로 분기.\n",
    "\n",
    "        Args:\n",
    "            doc_lists: 각 리트리버의 검색 결과 리스트들\n",
    "                      예: [[doc1, doc2, doc3], [doc3, doc1, doc4]]\n",
    "\n",
    "        Returns:\n",
    "            최종 점수 기준 내림차순으로 정렬된 문서 리스트\n",
    "\n",
    "        Raises:\n",
    "            ValueError: 문서 리스트 개수와 가중치 개수가 다른 경우\n",
    "        \"\"\"\n",
    "        if len(doc_lists) != len(self.weights):\n",
    "            raise ValueError(\"Number of rank lists must be equal to the number of weights.\")\n",
    "\n",
    "        # 설정된 앙상블 방법에 따라 분기\n",
    "        if self.method == EnsembleMethod.RRF:\n",
    "            return self.reciprocal_rank_fusion(doc_lists)\n",
    "        elif self.method == EnsembleMethod.CC:\n",
    "            return self.convex_combination(doc_lists)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid ensemble method\")\n",
    "\n",
    "    def reciprocal_rank_fusion(self, doc_lists: list[list[Document]]) -> list[Document]:\n",
    "        \"\"\"여러 순위 리스트에 대해 Reciprocal Rank Fusion 수행\n",
    "\n",
    "        RRF 개념:\n",
    "        - 각 검색기에서 문서의 순위만을 사용 (실제 점수 불필요)\n",
    "        - 상위 순위일수록 높은 점수 부여 (역수 사용)\n",
    "        - 여러 검색기에서 공통으로 상위에 랭크된 문서가 최종적으로 높은 점수\n",
    "\n",
    "        RRF 공식:\n",
    "            score(doc) = Σ weight_i / (rank_i + c)\n",
    "\n",
    "        예시 (c=60, weights=[1.0, 1.0]):\n",
    "            Retriever1: [A(1위), B(2위), C(3위)]\n",
    "            Retriever2: [B(1위), C(2위), A(5위)]\n",
    "\n",
    "            A의 점수 = 1.0/(1+60) + 1.0/(5+60) = 0.0164 + 0.0154 = 0.0318\n",
    "            B의 점수 = 1.0/(2+60) + 1.0/(1+60) = 0.0161 + 0.0164 = 0.0325 ← 최고\n",
    "            C의 점수 = 1.0/(3+60) + 1.0/(2+60) = 0.0159 + 0.0161 = 0.0320\n",
    "\n",
    "            최종 순위: B > C > A\n",
    "\n",
    "        장점:\n",
    "        - 실제 유사도 점수가 없어도 작동 (순위만 필요)\n",
    "        - 서로 다른 스케일의 점수를 가진 검색기도 공정하게 결합\n",
    "        - 구현이 단순하고 효과적\n",
    "        \"\"\"\n",
    "        rrf_score: dict[str, float] = defaultdict(float)  # 문서별 RRF 점수 누적\n",
    "\n",
    "        # 각 리트리버의 결과를 순회하며 점수 계산\n",
    "        for doc_list, weight in zip(doc_lists, self.weights, strict=True):\n",
    "            for rank, doc in enumerate(doc_list, start=1):  # 순위는 1부터 시작\n",
    "                # 문서의 고유 ID 추출\n",
    "                doc_id = doc.page_content if self.id_key is None else doc.metadata[self.id_key]\n",
    "                # RRF 공식: weight / (rank + c)\n",
    "                # rank가 작을수록 (상위일수록) 높은 점수\n",
    "                rrf_score[doc_id] += weight / (rank + self.c)\n",
    "\n",
    "        # 모든 문서를 하나의 리스트로 결합\n",
    "        all_docs = chain.from_iterable(doc_lists)\n",
    "\n",
    "        # 중복 제거하고 RRF 점수 기준 내림차순 정렬\n",
    "        sorted_docs = sorted(\n",
    "            unique_by_key(\n",
    "                all_docs,\n",
    "                lambda doc: (\n",
    "                    doc.page_content if self.id_key is None else doc.metadata[self.id_key]\n",
    "                ),\n",
    "            ),\n",
    "            key=lambda doc: rrf_score[\n",
    "                doc.page_content if self.id_key is None else doc.metadata[self.id_key]\n",
    "            ],\n",
    "            reverse=True,  # 높은 점수가 먼저\n",
    "        )\n",
    "        return sorted_docs\n",
    "\n",
    "    def convex_combination(self, doc_lists: list[list[Document]]) -> list[Document]:\n",
    "        \"\"\"여러 순위 리스트에 대해 Convex Combination(볼록 조합) 수행\n",
    "\n",
    "        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "        Convex Combination이란?\n",
    "        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "        수학적 정의:\n",
    "            볼록 조합(Convex Combination)은 여러 값들을 가중 평균하는 방법으로,\n",
    "            가중치의 합이 1이고 모든 가중치가 0 이상인 선형 결합입니다.\n",
    "\n",
    "            공식: score(doc) = Σ w_i × normalized_score_i\n",
    "            제약: Σ w_i = 1, w_i ≥ 0\n",
    "\n",
    "        핵심 아이디어:\n",
    "            1. 각 검색기의 점수를 정규화 (0~1 범위로)\n",
    "            2. 정규화된 점수에 가중치를 곱해서 합산\n",
    "            3. 가중치 합이 1이므로 최종 점수도 0~1 범위 유지\n",
    "\n",
    "        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "        구체적인 예시\n",
    "        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "        상황: BM25와 Dense Retriever를 3:7 비율로 결합\n",
    "\n",
    "        BM25 결과 (weight=0.3):\n",
    "            문서A: 15.3점\n",
    "            문서B: 12.7점\n",
    "            문서C: 8.5점\n",
    "            max_score = 15.3\n",
    "\n",
    "        Dense Retriever 결과 (weight=0.7):\n",
    "            문서A: 0.82점\n",
    "            문서B: 0.91점\n",
    "            문서C: 0.75점\n",
    "            max_score = 0.91\n",
    "\n",
    "        Step 1: 정규화 (각 검색기 내에서 최댓값으로 나눔)\n",
    "            BM25 정규화:\n",
    "                문서A: 15.3 / 15.3 = 1.00\n",
    "                문서B: 12.7 / 15.3 = 0.83\n",
    "                문서C: 8.5 / 15.3 = 0.56\n",
    "\n",
    "            Dense 정규화:\n",
    "                문서A: 0.82 / 0.91 = 0.90\n",
    "                문서B: 0.91 / 0.91 = 1.00\n",
    "                문서C: 0.75 / 0.91 = 0.82\n",
    "\n",
    "        Step 2: 가중 조합 (정규화된 점수 × 가중치의 합)\n",
    "            문서A: 0.3 × 1.00 + 0.7 × 0.90 = 0.30 + 0.63 = 0.93\n",
    "            문서B: 0.3 × 0.83 + 0.7 × 1.00 = 0.25 + 0.70 = 0.95 ← 최고!\n",
    "            문서C: 0.3 × 0.56 + 0.7 × 0.82 = 0.17 + 0.57 = 0.74\n",
    "\n",
    "        Step 3: 최종 순위\n",
    "            B (0.95) > A (0.93) > C (0.74)\n",
    "\n",
    "        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "        RRF vs CC 비교\n",
    "        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "        RRF (Reciprocal Rank Fusion):\n",
    "            ✓ 순위만 필요 (점수 불필요)\n",
    "            ✓ 스케일이 다른 점수 체계도 공정하게 처리\n",
    "            ✓ 구현 간단\n",
    "            ✗ 실제 점수 정보 활용 안 함\n",
    "\n",
    "        CC (Convex Combination):\n",
    "            ✓ 실제 유사도 점수 활용\n",
    "            ✓ 검색기별 신뢰도 반영 가능 (가중치)\n",
    "            ✓ 수학적으로 명확한 의미 (볼록 집합 내 점)\n",
    "            ✗ 점수가 필수 (metadata에 'score' 필요)\n",
    "            ✗ 가중치 합이 1이어야 함 (제약)\n",
    "\n",
    "        선택 가이드:\n",
    "            - 검색기 점수가 신뢰할 만하고, 각 검색기의 중요도를 명확히\n",
    "              조절하고 싶다면 → CC 사용\n",
    "            - 검색기 점수가 없거나, 단순히 순위만 중요하다면 → RRF 사용\n",
    "\n",
    "        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "        \"\"\"\n",
    "        cc_scores: dict[str, float] = defaultdict(float)  # 문서별 CC 점수 누적\n",
    "\n",
    "        # 각 리트리버의 결과를 순회하며 점수 계산\n",
    "        for doc_list, weight in zip(doc_lists, self.weights, strict=True):\n",
    "            # Step 1: 정규화를 위한 최댓값 찾기\n",
    "            # 해당 검색기 결과 중 가장 높은 점수를 찾음 (0 방지를 위해 or 1)\n",
    "            max_score = max(doc.metadata.get(\"score\", 0) for doc in doc_list) or 1\n",
    "\n",
    "            # Step 2: 각 문서의 점수를 정규화하고 가중치 적용\n",
    "            for doc in doc_list:\n",
    "                # 문서의 고유 ID 추출\n",
    "                doc_id = doc.page_content if self.id_key is None else doc.metadata[self.id_key]\n",
    "\n",
    "                # 정규화: 원본 점수 / 최댓값 → [0, 1] 범위로 변환\n",
    "                # 최고 점수 문서는 1.0, 나머지는 비율에 따라 0~1 사이 값\n",
    "                normalized_score = doc.metadata.get(\"score\", 0) / max_score\n",
    "\n",
    "                # 볼록 조합 공식 적용: weight × normalized_score\n",
    "                # 여러 검색기에서 같은 문서가 나오면 점수가 누적됨\n",
    "                cc_scores[doc_id] += weight * normalized_score\n",
    "\n",
    "        # Step 3: 중복 제거 - 모든 검색기 결과에서 고유 문서만 추출\n",
    "        all_docs = list(\n",
    "            unique_by_key(\n",
    "                chain.from_iterable(doc_lists),\n",
    "                lambda doc: (\n",
    "                    doc.page_content if self.id_key is None else doc.metadata[self.id_key]\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Step 4: CC 점수 기준 내림차순 정렬\n",
    "        sorted_docs = sorted(\n",
    "            all_docs,\n",
    "            key=lambda doc: cc_scores[\n",
    "                doc.page_content if self.id_key is None else doc.metadata[self.id_key]\n",
    "            ],\n",
    "            reverse=True,  # 높은 점수가 먼저\n",
    "        )\n",
    "\n",
    "        return sorted_docs\n",
    "\n",
    "    def rank_fusion(\n",
    "        self,\n",
    "        query: str,\n",
    "        run_manager: CallbackManagerForRetrieverRun,\n",
    "        *,\n",
    "        config: RunnableConfig | None = None,\n",
    "    ) -> list[Document]:\n",
    "        \"\"\"모든 리트리버의 결과를 수집하고 융합\n",
    "\n",
    "        전체 프로세스:\n",
    "        1. 각 리트리버에 쿼리를 전달하여 결과 수집\n",
    "        2. 결과가 Document 타입인지 확인 및 변환\n",
    "        3. 설정된 앙상블 방법(RRF/CC)으로 결과 융합\n",
    "\n",
    "        Args:\n",
    "            query: 검색 쿼리\n",
    "            run_manager: 콜백 관리자\n",
    "            config: 런타임 설정\n",
    "\n",
    "        Returns:\n",
    "            앙상블된 최종 문서 리스트\n",
    "        \"\"\"\n",
    "        # Step 1: 모든 리트리버의 결과 수집\n",
    "        # 각 리트리버를 순회하며 동일한 쿼리로 검색 수행\n",
    "        retriever_docs = [\n",
    "            retriever.invoke(\n",
    "                query,\n",
    "                patch_config(config, callbacks=run_manager.get_child(tag=f\"retriever_{i + 1}\")),\n",
    "            )\n",
    "            for i, retriever in enumerate(self.retrievers)\n",
    "        ]\n",
    "\n",
    "        # Step 2: 결과가 모두 Document 객체인지 확인\n",
    "        # 일부 리트리버는 문자열을 반환할 수 있으므로 Document로 변환\n",
    "        for i in range(len(retriever_docs)):\n",
    "            retriever_docs[i] = [\n",
    "                Document(page_content=cast(str, doc)) if isinstance(doc, str) else doc\n",
    "                for doc in retriever_docs[i]\n",
    "            ]\n",
    "\n",
    "        # Step 3: 앙상블 방법 적용 (RRF 또는 CC)\n",
    "        fused_documents = self.ensemble_results(retriever_docs)\n",
    "\n",
    "        return fused_documents\n",
    "\n",
    "    async def arank_fusion(\n",
    "        self,\n",
    "        query: str,\n",
    "        run_manager: AsyncCallbackManagerForRetrieverRun,\n",
    "        *,\n",
    "        config: RunnableConfig | None = None,\n",
    "    ) -> list[Document]:\n",
    "        \"\"\"모든 리트리버의 결과를 비동기로 수집하고 융합\n",
    "\n",
    "        rank_fusion의 비동기 버전.\n",
    "        여러 리트리버를 병렬로 실행하여 성능 향상.\n",
    "\n",
    "        전체 프로세스:\n",
    "        1. asyncio.gather로 모든 리트리버를 병렬 실행\n",
    "        2. 결과가 Document 타입인지 확인 및 변환\n",
    "        3. 설정된 앙상블 방법(RRF/CC)으로 결과 융합\n",
    "\n",
    "        Args:\n",
    "            query: 검색 쿼리\n",
    "            run_manager: 비동기 콜백 관리자\n",
    "            config: 런타임 설정\n",
    "\n",
    "        Returns:\n",
    "            앙상블된 최종 문서 리스트\n",
    "        \"\"\"\n",
    "        # Step 1: 모든 리트리버를 병렬로 실행 (asyncio.gather)\n",
    "        # 순차 실행보다 훨씬 빠름 (특히 네트워크 I/O가 있는 경우)\n",
    "        retriever_docs = await asyncio.gather(\n",
    "            *[\n",
    "                retriever.ainvoke(\n",
    "                    query,\n",
    "                    patch_config(config, callbacks=run_manager.get_child(tag=f\"retriever_{i + 1}\")),\n",
    "                )\n",
    "                for i, retriever in enumerate(self.retrievers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Step 2: 결과가 모두 Document 객체인지 확인\n",
    "        # 일부 리트리버는 문자열을 반환할 수 있으므로 Document로 변환\n",
    "        for i in range(len(retriever_docs)):\n",
    "            retriever_docs[i] = [\n",
    "                Document(page_content=doc) if not isinstance(doc, Document) else doc  # type: ignore[arg-type]\n",
    "                for doc in retriever_docs[i]\n",
    "            ]\n",
    "\n",
    "        # Step 3: 앙상블 방법 적용 (RRF 또는 CC)\n",
    "        # 이 부분은 동기 함수(하지만 CPU Bound 부하량이 작아서 속도는 크게 영향을 끼치지 않음)\n",
    "        # 필요하면 asyncio.to_thread로 넣어서 asyncio eventloop 깨지지 않도록 가능.\n",
    "        fused_documents = self.ensemble_results(retriever_docs)\n",
    "\n",
    "        return fused_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e500d469",
   "metadata": {},
   "source": [
    "### Multi-Vector Search\n",
    "\n",
    "Multi-Vector Search는 문서의 여러 측면(제목, 본문, 요약 등)을 별도 벡터로 인덱싱하여 검색 정확도를 높이는 전략입니다.\n",
    "\n",
    "## 학습 목표\n",
    "\n",
    "1. **Named Vectors 활용**: Qdrant의 Named Vectors 기능으로 다중 벡터 저장\n",
    "  > Embedding 모델은 Context Size 에 따라서 적절하게 '큰 것' 부터 '작은 것'까지 배치하도록 합니다.\n",
    "2. **다중 표현 전략**: `title, summary, body, parent_docs_summary` 등을 각각 위 규칙에 맞게 Dense Embedding\n",
    "3. **가중 검색**: 벡터별로 가중치를 달리하여 검색\n",
    "4. **파이프라인**: LLM 요약 생성 + 임베딩 + 인덱싱\n",
    "\n",
    "## Multi-Vector vs Single-Vector\n",
    "\n",
    "| 항목 | Single-Vector | Multi-Vector |\n",
    "|------|---------------|--------------|\n",
    "| 인덱스 크기 | 작음 | 2~3배 |\n",
    "| 검색 정확도 | 보통 | 높음 |\n",
    "| 레이턴시 | 빠름 | 약간 느림 |\n",
    "| 구현 복잡도 | 낮음 | 중간 |\n",
    "\n",
    "## 참고 자료\n",
    "\n",
    "- [Multi-Vector 개념](https://wikidocs.net/234281)\n",
    "- [Qdrant Named Vectors](https://qdrant.tech/documentation/concepts/vectors/#named-vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8c06fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 1. Multi-Vector 인덱싱 파이프라인\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def generate_summary(text: str, llm: Runnable, max_length: int = 100) -> str:\n",
    "    \"\"\"\n",
    "    LLM을 사용하여 텍스트 요약 생성\n",
    "\n",
    "    Args:\n",
    "        text: 원본 텍스트\n",
    "        llm: LLM 모델\n",
    "        max_length: 최대 요약 길이\n",
    "\n",
    "    Returns:\n",
    "        요약 텍스트\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                f\"다음 텍스트를 {max_length}자 이내로 요약하세요. 핵심 내용만 간결하게 작성하세요.\",\n",
    "            ),\n",
    "            (\"user\", \"{text}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    try:\n",
    "        summary = chain.invoke({\"text\": text})\n",
    "        return summary.strip()\n",
    "    except Exception as e:\n",
    "        print(f\" 요약 생성 실패: {e}\")\n",
    "        # 실패 시 앞 부분 잘라서 반환\n",
    "        return text[:max_length]\n",
    "\n",
    "\n",
    "def create_multi_vector_collection(\n",
    "    collection_name: str,\n",
    "    dimension: int = 1536,\n",
    "    on_disk: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Multi-Vector용 Qdrant 컬렉션 생성\n",
    "\n",
    "    Named Vectors:\n",
    "    - dense_title: 제목 임베딩\n",
    "    - dense_summary: 요약 임베딩\n",
    "    - dense_body: 본문 임베딩\n",
    "    \"\"\"\n",
    "    from qdrant_client.models import Distance, VectorParams\n",
    "\n",
    "    client = QdrantClient(url=os.getenv(\"QDRANT_URL\", \"http://localhost:6333\"))\n",
    "\n",
    "    # 기존 컬렉션 삭제 (테스트용)\n",
    "    try:\n",
    "        client.delete_collection(collection_name)\n",
    "        print(f\"기존 컬렉션 '{collection_name}' 삭제\")\n",
    "    except Exception as e:\n",
    "        print(f\"기존 컬렉션 '{collection_name}' 삭제 실패: {e}\")\n",
    "\n",
    "    # Named Vectors 정의\n",
    "    vectors_config = {\n",
    "        \"dense_title\": VectorParams(\n",
    "            size=dimension,\n",
    "            distance=Distance.COSINE,\n",
    "            on_disk=on_disk,\n",
    "        ),\n",
    "        \"dense_summary\": VectorParams(\n",
    "            size=dimension,\n",
    "            distance=Distance.COSINE,\n",
    "            on_disk=on_disk,\n",
    "        ),\n",
    "        \"dense_body\": VectorParams(\n",
    "            size=dimension,\n",
    "            distance=Distance.COSINE,\n",
    "            on_disk=on_disk,\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    # 컬렉션 생성\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=vectors_config,\n",
    "    )\n",
    "\n",
    "    print(f\"Multi-Vector 컬렉션 '{collection_name}' 생성 완료\")\n",
    "    print(f\"   - Named Vectors: {list(vectors_config.keys())}\")\n",
    "\n",
    "    return client\n",
    "\n",
    "\n",
    "def index_multi_vector_documents(\n",
    "    documents: list[Document],\n",
    "    collection_name: str,\n",
    "    embeddings: OpenAIEmbeddings,\n",
    "    llm: Runnable | None = None,\n",
    "    generate_summaries: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    문서를 Multi-Vector로 인덱싱\n",
    "\n",
    "    Args:\n",
    "        documents: 문서 리스트\n",
    "        collection_name: 컬렉션 이름\n",
    "        embeddings: 임베딩 모델\n",
    "        llm: 요약 생성용 LLM (선택)\n",
    "        generate_summaries: 요약 자동 생성 여부\n",
    "    \"\"\"\n",
    "    client = QdrantClient(url=os.getenv(\"QDRANT_URL\", \"http://localhost:6333\"))\n",
    "\n",
    "    points = []\n",
    "    max_length = 500\n",
    "\n",
    "    for idx, doc in enumerate(documents):\n",
    "        # 제목 추출 (메타데이터 또는 첫 문장)\n",
    "        title = doc.metadata.get(\"title\", doc.page_content.split(\"\\n\")[0][:100])\n",
    "\n",
    "        # 요약 생성\n",
    "        if generate_summaries and llm:\n",
    "            summary = generate_summary(doc.page_content, llm, max_length=max_length)\n",
    "        else:\n",
    "            # 요약이 없으면 앞 150자 사용\n",
    "            summary = doc.page_content[:max_length]\n",
    "\n",
    "        # 본문\n",
    "        body = doc.page_content\n",
    "\n",
    "        # 각각 임베딩\n",
    "        title_vector = embeddings.embed_query(title)\n",
    "        summary_vector = embeddings.embed_query(summary)\n",
    "        body_vector = embeddings.embed_query(body)\n",
    "\n",
    "        # Named Vectors로 저장\n",
    "        point = PointStruct(\n",
    "            id=idx,\n",
    "            vector={\n",
    "                \"dense_title\": title_vector,\n",
    "                \"dense_summary\": summary_vector,\n",
    "                \"dense_body\": body_vector,\n",
    "            },\n",
    "            payload={\n",
    "                \"page_content\": body,\n",
    "                \"metadata\": doc.metadata,\n",
    "                \"title\": title,\n",
    "                \"summary\": summary,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        points.append(point)\n",
    "\n",
    "    # 배치 업로드\n",
    "    client.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points=points,\n",
    "    )\n",
    "\n",
    "    print(f\"{len(points)}개 문서 인덱싱 완료\")\n",
    "    print(\"   - Title, Summary, Body 각각 임베딩\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4814a075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Multi-Vector 검색 전략\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def multi_vector_search(\n",
    "    query: str,\n",
    "    collection_name: str,\n",
    "    embeddings: OpenAIEmbeddings,\n",
    "    vector_weights: dict | None = None,\n",
    "    k: int = 5,\n",
    ") -> list[tuple[Document, float]]:\n",
    "    \"\"\"\n",
    "    Multi-Vector 검색: 여러 Named Vector를 가중 결합\n",
    "\n",
    "    Args:\n",
    "        query: 검색 쿼리\n",
    "        collection_name: 컬렉션 이름\n",
    "        embeddings: 임베딩 모델\n",
    "        vector_weights: 벡터별 가중치 {\"dense_title\": 0.3, \"dense_summary\": 0.3, \"dense_body\": 0.4}\n",
    "        k: 반환할 문서 개수\n",
    "\n",
    "    Returns:\n",
    "        (Document, score) 리스트\n",
    "    \"\"\"\n",
    "    client = QdrantClient(url=os.getenv(\"QDRANT_URL\", \"http://localhost:6333\"))\n",
    "\n",
    "    # 기본 가중치\n",
    "    if vector_weights is None:\n",
    "        vector_weights = {\n",
    "            \"dense_title\": 0.3,\n",
    "            \"dense_summary\": 0.3,\n",
    "            \"dense_body\": 0.4,\n",
    "        }\n",
    "\n",
    "    # 쿼리 임베딩\n",
    "    query_vector = embeddings.embed_query(query)\n",
    "\n",
    "    # 각 Named Vector로 검색\n",
    "    results_dict = {}\n",
    "\n",
    "    for vector_name, weight in vector_weights.items():\n",
    "        search_result = client.search(\n",
    "            collection_name=collection_name,\n",
    "            query_vector=(vector_name, query_vector),\n",
    "            limit=k * 2,  # 여유있게 가져오기\n",
    "            with_payload=True,\n",
    "        )\n",
    "\n",
    "        # 점수 저장\n",
    "        for point in search_result:\n",
    "            doc_id = point.id\n",
    "\n",
    "            if doc_id not in results_dict:\n",
    "                results_dict[doc_id] = {\n",
    "                    \"payload\": point.payload,\n",
    "                    \"score\": 0.0,\n",
    "                }\n",
    "\n",
    "            # 가중 점수 누적\n",
    "            results_dict[doc_id][\"score\"] += weight * point.score\n",
    "\n",
    "    # 점수 기준 정렬\n",
    "    sorted_results = sorted(\n",
    "        results_dict.items(),\n",
    "        key=lambda x: x[1][\"score\"],\n",
    "        reverse=True,\n",
    "    )[:k]\n",
    "\n",
    "    # Document 객체로 변환\n",
    "    documents = []\n",
    "    for _, data in sorted_results:\n",
    "        doc = Document(\n",
    "            page_content=data[\"payload\"][\"page_content\"],\n",
    "            metadata=data[\"payload\"].get(\"metadata\", {}),\n",
    "        )\n",
    "        documents.append((doc, data[\"score\"]))\n",
    "\n",
    "    return documents\n",
    "\n",
    "\n",
    "print(\"\"\"\n",
    "가중치 전략:\n",
    "1. Title-Boost (제목 중심)\n",
    "   - dense_title: 0.5\n",
    "   - dense_summary: 0.3\n",
    "   - dense_body: 0.2\n",
    "   사용: 제목이 중요한 논문, 법률 문서\n",
    "\n",
    "2. Balanced (균형)\n",
    "   - dense_title: 0.3\n",
    "   - dense_summary: 0.3\n",
    "   - dense_body: 0.4\n",
    "   사용: 일반 문서 검색\n",
    "\n",
    "3. Content-Focused (본문 중심)\n",
    "   - dense_title: 0.1\n",
    "   - dense_summary: 0.2\n",
    "   - dense_body: 0.7\n",
    "   사용: 긴 문서, 상세 내용 검색\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
