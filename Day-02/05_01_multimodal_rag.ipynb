{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57d4f85b",
   "metadata": {},
   "source": [
    "# Multi-Modal RAG\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "\n",
    "**Multi-Modal RAG**: í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ í†µí•©í•œ ì˜ë¯¸ì  ê²€ìƒ‰\n",
    "\n",
    "## í•™ìŠµ êµ¬ì„±\n",
    "\n",
    "**Part 1: Multi-Modal RAG** (1ì‹œê°„)\n",
    "- Jina Embeddings v4 ëª¨ë¸ì„ ì‚¬ìš©í•œ ë‹¤êµ­ì–´ ì„ë² ë”©\n",
    "- Qdrant Named Vectorsë¥¼ í™œìš©í•œ Multi-Modal ì €ì¥\n",
    "- Cross-Lingual Search ë° Late Fusion ì „ëµ\n",
    "\n",
    "## ì°¸ê³ ì‚¬í•­\n",
    "\n",
    "- Multi-Modal ì´ë¯¸ì§€ëŠ” `Day2/images/multimodal/` ê²½ë¡œì— ìˆëŠ” ê²ƒì„ ì‚¬ìš©í•©ë‹ˆë‹¤\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - ì›ë³¸ ë²•ë ¹ ê²½ë¡œ: ./law\n",
      "  - ë³€í™˜ ê²°ê³¼ ê²½ë¡œ: ./law/markdown\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "LAW_DATA_DIR = \"./law\"\n",
    "PROCESSED_LAW_DIR = \"./law/markdown\"\n",
    "print(f\"  - ì›ë³¸ ë²•ë ¹ ê²½ë¡œ: {LAW_DATA_DIR}\")\n",
    "print(f\"  - ë³€í™˜ ê²°ê³¼ ê²½ë¡œ: {PROCESSED_LAW_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# OpenAI / OpenRouter ëª¨ë¸ ì´ˆê¸°í™” í—¬í¼\n",
    "# ----------------------------------------------------------------------------\n",
    "from typing import Literal\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def _resolve_api_context() -> tuple[str, str]:\n",
    "    \"\"\"ì„ íƒëœ API í‚¤ì™€ ë² ì´ìŠ¤ URL ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
    "    api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise RuntimeError(\"OPENROUTER_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "    base_url = os.getenv(\"OPENROUTER_API_BASE\") or \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "    return (api_key, base_url)\n",
    "\n",
    "\n",
    "def create_openrouter_llm(\n",
    "    model: str = \"openai/gpt-4.1-mini\",\n",
    "    temperature: float = 0.3,\n",
    "    max_tokens: int | None = None,\n",
    "    **kwargs: object,\n",
    ") -> ChatOpenAI:\n",
    "    \"\"\"OpenAI í˜¸í™˜ LLM ìƒì„± í—¬í¼.\n",
    "\n",
    "    Args:\n",
    "        model: ëª¨ë¸ ì´ë¦„. OpenRouterì—ì„œëŠ” provider/model í˜•ì‹ ì‚¬ìš© ê°€ëŠ¥\n",
    "               (ì˜ˆ: openai/gpt-4o, anthropic/claude-3-sonnet, google/gemini-pro)\n",
    "        temperature: ìƒì„± ì˜¨ë„ (0.0-2.0)\n",
    "        max_tokens: ìµœëŒ€ ìƒì„± í† í° ìˆ˜\n",
    "\n",
    "    Returns:\n",
    "        ChatOpenAI: ì„¤ì •ëœ LLM ì¸ìŠ¤í„´ìŠ¤\n",
    "    \"\"\"\n",
    "    api_key, base_url = _resolve_api_context()\n",
    "\n",
    "    openai_kwargs: dict = {\n",
    "        \"model\": model,\n",
    "        \"api_key\": api_key,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_retries\": 3,\n",
    "        \"timeout\": 60,\n",
    "        **kwargs,\n",
    "    }\n",
    "    if max_tokens is not None:\n",
    "        openai_kwargs[\"max_tokens\"] = max_tokens\n",
    "    if base_url:\n",
    "        openai_kwargs[\"base_url\"] = base_url\n",
    "    return ChatOpenAI(**openai_kwargs)\n",
    "\n",
    "\n",
    "def create_embedding_model(\n",
    "    model: str = \"openai/text-embedding-3-small\",\n",
    "    **kwargs,\n",
    ") -> OpenAIEmbeddings:\n",
    "    \"\"\"OpenAI í˜¸í™˜ ì„ë² ë”© ëª¨ë¸ ìƒì„±.\n",
    "\n",
    "    Args:\n",
    "        model: ì„ë² ë”© ëª¨ë¸ ì´ë¦„. OpenRouterì—ì„œëŠ” provider/model í˜•ì‹ ì‚¬ìš© ê°€ëŠ¥\n",
    "               (ì˜ˆ: openai/text-embedding-3-small, openai/text-embedding-3-large)\n",
    "        **kwargs: ì¶”ê°€ íŒŒë¼ë¯¸í„° (encoding_format ë“±ì€ model_kwargsë¡œ ì „ë‹¬ë¨)\n",
    "\n",
    "    Returns:\n",
    "        OpenAIEmbeddings: ì„¤ì •ëœ ì„ë² ë”© ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤\n",
    "    \"\"\"\n",
    "    api_key, base_url = _resolve_api_context()\n",
    "\n",
    "    # ì „ë‹¬ë°›ì€ kwargsì—ì„œ model_kwargsë¡œ ì „ë‹¬í•  íŒŒë¼ë¯¸í„° ë¶„ë¦¬\n",
    "    # encoding_format, extra_headers ë“±ì€ model_kwargsë¡œ ì „ë‹¬\n",
    "    model_kwargs: dict = {}\n",
    "    embedding_kwargs: dict = {\n",
    "        \"model\": model,\n",
    "        \"api_key\": api_key,\n",
    "        \"show_progress_bar\": True,\n",
    "        \"skip_empty\": True,\n",
    "    }\n",
    "\n",
    "    # ì „ë‹¬ë°›ì€ kwargs ì²˜ë¦¬\n",
    "    for key, value in kwargs.items():\n",
    "        # OpenRouter API íŠ¹ì • íŒŒë¼ë¯¸í„°ëŠ” model_kwargsë¡œ ì „ë‹¬\n",
    "        if key in (\"encoding_format\"):\n",
    "            model_kwargs[key] = value\n",
    "        else:\n",
    "            # ë‚˜ë¨¸ì§€ëŠ” OpenAIEmbeddingsì— ì§ì ‘ ì „ë‹¬\n",
    "            embedding_kwargs[key] = value\n",
    "\n",
    "    if base_url:\n",
    "        embedding_kwargs[\"base_url\"] = base_url\n",
    "\n",
    "    # model_kwargsê°€ ìˆìœ¼ë©´ ì „ë‹¬\n",
    "    if model_kwargs:\n",
    "        embedding_kwargs[\"model_kwargs\"] = model_kwargs\n",
    "\n",
    "    return OpenAIEmbeddings(**embedding_kwargs)\n",
    "\n",
    "\n",
    "def create_embedding_model_direct(\n",
    "    model: str = \"qwen/qwen3-embedding-0.6b\",\n",
    "    encoding_format: Literal[\"float\", \"base64\"] = \"float\",\n",
    "    input_text: str | list[str] = \"\",\n",
    "    **kwargs,\n",
    ") -> list[float] | list[list[float]]:\n",
    "    \"\"\"OpenAI SDKë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ì„ë² ë”© ìƒì„± (encoding_format ì§€ì›).\n",
    "\n",
    "    LangChainì˜ OpenAIEmbeddingsê°€ encoding_formatì„ ì§€ì›í•˜ì§€ ì•Šì„ ë•Œ ì‚¬ìš©.\n",
    "\n",
    "    Args:\n",
    "        model: ì„ë² ë”© ëª¨ë¸ ì´ë¦„\n",
    "        encoding_format: ì¸ì½”ë”© í˜•ì‹ (\"float\")\n",
    "        input_text: ì„ë² ë”©í•  í…ìŠ¤íŠ¸ (ë¬¸ìì—´ ë˜ëŠ” ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸)\n",
    "        **kwargs: ì¶”ê°€ íŒŒë¼ë¯¸í„°\n",
    "\n",
    "    Returns:\n",
    "        ì„ë² ë”© ë²¡í„° ë¦¬ìŠ¤íŠ¸ (ë‹¨ì¼ í…ìŠ¤íŠ¸) ë˜ëŠ” ë¦¬ìŠ¤íŠ¸ì˜ ë¦¬ìŠ¤íŠ¸ (ì—¬ëŸ¬ í…ìŠ¤íŠ¸)\n",
    "    \"\"\"\n",
    "    from openai import OpenAI\n",
    "\n",
    "    api_key, base_url = _resolve_api_context()\n",
    "\n",
    "    client = OpenAI(\n",
    "        base_url=base_url,\n",
    "        api_key=api_key,\n",
    "    )\n",
    "\n",
    "    # input_textê°€ ë¹„ì–´ìˆìœ¼ë©´ kwargsì—ì„œ ê°€ì ¸ì˜¤ê¸°\n",
    "    if not input_text:\n",
    "        input_text = kwargs.get(\"input\", \"\")\n",
    "\n",
    "    response = client.embeddings.create(\n",
    "        model=model,\n",
    "        input=input_text,\n",
    "        encoding_format=encoding_format,\n",
    "    )\n",
    "\n",
    "    # ë‹¨ì¼ í…ìŠ¤íŠ¸ì¸ ê²½ìš° ì²« ë²ˆì§¸ ì„ë² ë”© ë°˜í™˜\n",
    "    if isinstance(input_text, str):\n",
    "        return response.data[0].embedding\n",
    "    else:\n",
    "        # ì—¬ëŸ¬ í…ìŠ¤íŠ¸ì¸ ê²½ìš° ëª¨ë“  ì„ë² ë”© ë°˜í™˜\n",
    "        return [item.embedding for item in response.data]\n",
    "\n",
    "\n",
    "def get_available_model_types() -> dict[str, list[str]]:\n",
    "    \"\"\"OpenRouterì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ìœ í˜•ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, list[str]]: ëª¨ë¸ ìœ í˜•ë³„ ëª¨ë¸ ëª©ë¡\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"chat\": [\n",
    "            \"openai/gpt-4.1\",\n",
    "            \"openai/gpt-4.1-mini\",\n",
    "            \"openai/gpt-5\",\n",
    "            \"openai/gpt-5-mini\",\n",
    "            \"anthropic/claude-sonnet-4.5\",\n",
    "            \"anthropic/claude-haiku-4.5\",\n",
    "            \"google/gemini-2.5-flash-preview-09-2025\",\n",
    "            \"google/gemini-pro-2.5\",\n",
    "            \"x-ai/grok-4-fast\",\n",
    "            \"moonshotai/kimi-k2-thinking\",\n",
    "            \"liquid/lfm-2.2-6b\",\n",
    "            \"z-ai/glm-4.6\",\n",
    "        ],\n",
    "        \"embedding\": [\n",
    "            \"openai/text-embedding-3-small\",\n",
    "            \"openai/text-embedding-3-large\",\n",
    "            \"google/gemini-embedding-001\",\n",
    "            \"qwen/qwen3-embedding-0.6b\",\n",
    "            \"qwen/qwen3-embedding-4b\",\n",
    "            \"qwen/qwen3-embedding-8b\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "\n",
    "embeddings = create_embedding_model()\n",
    "llm = create_openrouter_llm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c8f2f2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Multi-Modal RAG\n",
    "\n",
    "### 1.1 Multi-Modal RAG ê°œë… ì†Œê°œ\n",
    "\n",
    "**ì •ì˜**: í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ë“± ì—¬ëŸ¬ ëª¨ë‹¬ë¦¬í‹°ì˜ ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ ì˜ë¯¸ì  ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” RAG ì‹œìŠ¤í…œ\n",
    "\n",
    "**í•µì‹¬ ê°œë…**:\n",
    "- **Semantic Gap**: ì„œë¡œ ë‹¤ë¥¸ ëª¨ë‹¬ë¦¬í‹° ê°„ì˜ ì˜ë¯¸ì  ì°¨ì´ë¥¼ ì„ë² ë”© ê³µê°„ì—ì„œ í•´ì†Œ\n",
    "- **Shared Embedding Space**: í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ë™ì¼í•œ ë²¡í„° ê³µê°„ì— ë§¤í•‘\n",
    "- **Cross-Modal Search**: í…ìŠ¤íŠ¸ë¡œ ì´ë¯¸ì§€ë¥¼ ì°¾ê±°ë‚˜, ì´ë¯¸ì§€ë¡œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ëŠ” ê²€ìƒ‰\n",
    "\n",
    "**í™œìš© ì‚¬ë¡€**:\n",
    "1. ì˜ë£Œ: \"íë ´ X-ray ì´ë¯¸ì§€\"ë¥¼ í…ìŠ¤íŠ¸ë¡œ ê²€ìƒ‰\n",
    "2. ì „ììƒê±°ë˜: ì´ë¯¸ì§€ë¡œ ìœ ì‚¬ ìƒí’ˆ ì°¾ê¸°\n",
    "3. ë¬¸ì„œ ë¶„ì„: PDF ìŠ¤í¬ë¦°ìƒ·ì—ì„œ ê´€ë ¨ ì¡°í•­ ê²€ìƒ‰\n",
    "4. ë²•ë¥ : ì°¨íŠ¸/ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ê´€ë ¨ ì¡°ë¬¸ ì°¾ê¸°\n",
    "\n",
    "**ì°¸ê³ **: [Qdrant Multilingual & Multimodal Search](https://qdrant.tech/documentation/multimodal-search/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe81691a",
   "metadata": {},
   "source": [
    "### 1.2 ë°ì´í„°ì…‹ í™•ì¸\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911d371d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Multi-Modal ë°ëª¨ ë°ì´í„°ì…‹ ì •ì˜\n",
    "# ============================================================================\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "image_dir = DAY2_ROOT / \"images\" / \"multimodal\"\n",
    "\n",
    "predefined_documents = [\n",
    "    {\n",
    "        \"id\": \"mm_doc_001\",\n",
    "        \"filename\": \"working_hours.png\",\n",
    "        \"caption_ko\": \"ê·¼ë¡œê¸°ì¤€ë²• ì œ50ì¡° ê·¼ë¡œì‹œê°„ ìš”ì•½ ë‹¤ì´ì–´ê·¸ë¨: ì£¼ 40ì‹œê°„, ì—°ì¥ 12ì‹œê°„ ì´ë‚´\",\n",
    "        \"caption_en\": \"Diagram summarizing Korea Labor Standards Act Article 50: 40 hours/week, max 12 hours overtime\",\n",
    "        \"metadata\": {\"topic\": \"ê·¼ë¡œì‹œê°„\", \"law_reference\": \"ê·¼ë¡œê¸°ì¤€ë²• ì œ50ì¡°\"},\n",
    "    },\n",
    "]\n",
    "\n",
    "multimodal_documents: list[dict[str, Any]] = []\n",
    "missing_assets: list[str] = []\n",
    "\n",
    "for doc in predefined_documents:\n",
    "    path = image_dir / doc[\"filename\"]\n",
    "    if path.exists():\n",
    "        multimodal_documents.append(\n",
    "            {\n",
    "                \"id\": doc[\"id\"],\n",
    "                \"caption_ko\": doc[\"caption_ko\"],\n",
    "                \"caption_en\": doc[\"caption_en\"],\n",
    "                \"image_path\": path,\n",
    "                \"metadata\": {**doc[\"metadata\"], \"filename\": doc[\"filename\"]},\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        missing_assets.append(doc[\"filename\"])\n",
    "\n",
    "print(f\"ë¡œë”©ëœ ë©€í‹°ëª¨ë‹¬ ìƒ˜í”Œ ìˆ˜: {len(multimodal_documents)}\")\n",
    "if missing_assets:\n",
    "    print(f\"ëˆ„ë½ëœ ì´ë¯¸ì§€ íŒŒì¼: {missing_assets}\")\n",
    "\n",
    "if not multimodal_documents:\n",
    "    raise RuntimeError(\n",
    "        \"ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì…‹ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. Day2/images/multimodal ê²½ë¡œì— ì´ë¯¸ì§€ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.\"\n",
    "    )\n",
    "\n",
    "# DataFrame ì¶œë ¥\n",
    "display(\n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"id\": doc[\"id\"],\n",
    "                \"caption_ko\": doc[\"caption_ko\"][:60] + \"...\",\n",
    "                \"topic\": doc[\"metadata\"].get(\"topic\", \"N/A\"),\n",
    "            }\n",
    "            for doc in multimodal_documents\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5317de",
   "metadata": {},
   "source": [
    "### 1.3 Multi-Modal ì„ë² ë”© ëª¨ë¸\n",
    "\n",
    "1. **Qwen3-VL-4B**\n",
    "\n",
    "\n",
    "- ì¶œì²˜: [Qwen/Qwen3-VL-4B-Instruct](Qwen/Qwen3-VL-4B-Instruct)\n",
    "\n",
    "2. **LiquidAI/LFM2-VL-3B**\n",
    "\n",
    "- ì¶œì²˜: [https://huggingface.co/LiquidAI/LFM2-VL-3B](https://huggingface.co/LiquidAI/LFM2-VL-3B)\n",
    "\n",
    "3. **MinerU2.5-2509-1.2B**\n",
    "\n",
    "- ì¶œì²˜: [https://huggingface.co/opendatalab/MinerU2.5-2509-1.2B](https://huggingface.co/opendatalab/MinerU2.5-2509-1.2B)\n",
    "\n",
    "4. **Jina Embeddings v4** (Qwen/Qwen2.5-VL-3B-Instruct ê¸°ë°˜, Multi-Modal, 768ì°¨ì›)\n",
    "   - Hugging Face Text Embeddings Inference (TEI)ë¡œ ë°°í¬\n",
    "   - ì•„ì‰½ê²Œë„ `License ê°€ CC-BY-NC` ì´ë¼ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì‚¬ìš© ë¶ˆê°€\n",
    "   - ì¶œì²˜: [https://huggingface.co/jinaai/jina-embeddings-v4](https://huggingface.co/jinaai/jina-embeddings-v4)\n",
    "\n",
    "5. **Jina Reranker v3** (ì¬ì •ë ¬)\n",
    "   - Late-Fusion í›„ ìµœì¢… ì¬ì •ë ¬, TEIë¡œ ë°°í¬ ê°€ëŠ¥\n",
    "   - ì•„ì‰½ê²Œë„ `License ê°€ CC-BY-NC` ì´ë¼ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì‚¬ìš© ë¶ˆê°€\n",
    "   - ì¶œì²˜: [https://huggingface.co/jinaai/jina-reranker-v3](https://huggingface.co/jinaai/jina-reranker-v3)\n",
    "\n",
    "\n",
    "### ì¤‘êµ­ëª¨ë¸ ì´ìŠˆ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941d8952",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DAY2_ROOT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Multi-Modal ì„ë² ë”© ì´ˆê¸°í™” (Omni-Embed + Jina v4)\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m sys.path.insert(\u001b[32m0\u001b[39m, \u001b[38;5;28mstr\u001b[39m(\u001b[43mDAY2_ROOT\u001b[49m / \u001b[33m\"\u001b[39m\u001b[33msrc\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhttpx\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmmrag\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingfaceMMEmbedding\n",
      "\u001b[31mNameError\u001b[39m: name 'DAY2_ROOT' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Multi-Modal ì„ë² ë”© ì´ˆê¸°í™” (Omni-Embed + Jina v4)\n",
    "# ============================================================================\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, str(DAY2_ROOT / \"src\"))\n",
    "\n",
    "import httpx\n",
    "from mmrag.embeddings import HuggingfaceMMEmbedding\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ í™•ì¸\n",
    "EMBED_MM_URL = os.getenv(\"EMBED_MM_URL\", \"http://localhost:8001\")\n",
    "EMBED_TEXT_URL = os.getenv(\"EMBED_TEXT_URL\", \"http://localhost:8002\")\n",
    "RERANK_URL = os.getenv(\"RERANK_URL\", \"http://localhost:8003\")\n",
    "\n",
    "print(f\"ë©€í‹°ëª¨ë‹¬ ì„ë² ë”© ì„œë²„: {EMBED_MM_URL}\")\n",
    "print(f\"í…ìŠ¤íŠ¸ ì„ë² ë”© ì„œë²„: {EMBED_TEXT_URL}\")\n",
    "print(f\"ë¦¬ë­í¬ ì„œë²„: {RERANK_URL}\")\n",
    "\n",
    "# Omni-Embed í´ë¼ì´ì–¸íŠ¸ (í…ìŠ¤íŠ¸/ì´ë¯¸ì§€)\n",
    "omni_embedder = HuggingfaceMMEmbedding(\n",
    "    text_url=EMBED_MM_URL,\n",
    "    image_url=EMBED_MM_URL,\n",
    "    timeout=60.0,\n",
    "    batch_size_text=16,\n",
    "    batch_size_image=8,\n",
    ")\n",
    "\n",
    "\n",
    "# Jina Embeddings v4 í´ë¼ì´ì–¸íŠ¸ (í…ìŠ¤íŠ¸ ì „ìš©, TEI ìŠ¤íƒ€ì¼)\n",
    "class JinaTextEmbedding:\n",
    "    def __init__(self, url: str):\n",
    "        self.url = url.rstrip(\"/\")\n",
    "        self.client = httpx.Client(timeout=30.0)\n",
    "\n",
    "    def embed_documents(self, texts: list[str]) -> list[list[float]]:\n",
    "        resp = self.client.post(f\"{self.url}/embed\", json={\"inputs\": texts})\n",
    "        resp.raise_for_status()\n",
    "        return resp.json()\n",
    "\n",
    "    def health_check(self) -> dict:\n",
    "        try:\n",
    "            resp = self.client.get(f\"{self.url}/health\")\n",
    "            resp.raise_for_status()\n",
    "            return resp.json()\n",
    "        except Exception as e:\n",
    "            return {\"status\": \"error\", \"message\": str(e)}\n",
    "\n",
    "\n",
    "jina_embedder = JinaTextEmbedding(url=EMBED_TEXT_URL)\n",
    "\n",
    "# í—¬ìŠ¤ì²´í¬\n",
    "print(\"\\nì„œë²„ í—¬ìŠ¤ì²´í¬:\")\n",
    "print(f\"  Omni-Embed: {omni_embedder.health_check()}\")\n",
    "print(f\"  Jina v4: {jina_embedder.health_check()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526d29dc",
   "metadata": {},
   "source": [
    "#### ì´ë¯¸ì§€ ë° í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±\n",
    "\n",
    "Jina v4ì™€ Omni-Embedë¥¼ ì‚¬ìš©í•˜ì—¬ 3ì¢…ë¥˜ì˜ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤:\n",
    "- Jina v4 í…ìŠ¤íŠ¸ ì„ë² ë”© (í•œêµ­ì–´/ì˜ì–´ í‰ê· )\n",
    "- Omni-Embed í…ìŠ¤íŠ¸ ì„ë² ë”© (í•œêµ­ì–´/ì˜ì–´ í‰ê· , 2048ì°¨ì›)\n",
    "- Omni-Embed ì´ë¯¸ì§€ ì„ë² ë”© (2048ì°¨ì›)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1ad458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Multi-Modal ì„ë² ë”© ìƒì„± (Omni-Embed + Jina v4)\n",
    "# ============================================================================\n",
    "import numpy as np\n",
    "\n",
    "# ìº¡ì…˜ ì¶”ì¶œ\n",
    "captions_ko = [doc[\"caption_ko\"] for doc in multimodal_documents]\n",
    "captions_en = [doc[\"caption_en\"] for doc in multimodal_documents]\n",
    "\n",
    "# 1. Jina v4 í…ìŠ¤íŠ¸ ì„ë² ë”© (í•œêµ­ì–´/ì˜ì–´ í‰ê· )\n",
    "print(\"ğŸ”„ Jina v4 í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± ì¤‘...\")\n",
    "text_emb_ko = np.array(jina_embedder.embed_documents(captions_ko))\n",
    "text_emb_en = np.array(jina_embedder.embed_documents(captions_en))\n",
    "text_embeddings_jina = (text_emb_ko + text_emb_en) / 2\n",
    "\n",
    "# 2. Omni-Embed í…ìŠ¤íŠ¸ ì„ë² ë”© (í•œêµ­ì–´/ì˜ì–´ í‰ê· )\n",
    "print(\"ğŸ”„ Omni-Embed í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± ì¤‘...\")\n",
    "text_emb_omni_ko = omni_embedder.embed_texts(captions_ko)\n",
    "text_emb_omni_en = omni_embedder.embed_texts(captions_en)\n",
    "text_embeddings_omni = (text_emb_omni_ko + text_emb_omni_en) / 2\n",
    "\n",
    "# 3. Omni-Embed ì´ë¯¸ì§€ ì„ë² ë”©\n",
    "print(\"ğŸ”„ Omni-Embed ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„± ì¤‘...\")\n",
    "image_paths = [doc[\"image_path\"] for doc in multimodal_documents]\n",
    "image_embeddings = omni_embedder.embed_images(image_paths)\n",
    "\n",
    "# ì°¨ì› í™•ì¸\n",
    "print(\"\\nâœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ:\")\n",
    "print(f\"   Jina í…ìŠ¤íŠ¸: {text_embeddings_jina.shape}\")\n",
    "print(f\"   Omni í…ìŠ¤íŠ¸: {text_embeddings_omni.shape} (2048ì°¨ì›)\")\n",
    "print(f\"   Omni ì´ë¯¸ì§€: {image_embeddings.shape} (2048ì°¨ì›)\")\n",
    "\n",
    "# ì°¨ì› ìë™ ê°ì§€\n",
    "dim_jina = text_embeddings_jina.shape[1]\n",
    "dim_omni = 2048\n",
    "\n",
    "print(\"\\nğŸ“ ìë™ ê°ì§€ëœ ì°¨ì›:\")\n",
    "print(f\"   text (Jina): {dim_jina}\")\n",
    "print(f\"   text_mm (Omni): {dim_omni}\")\n",
    "print(f\"   image (Omni): {dim_omni}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10b7f76",
   "metadata": {},
   "source": [
    "#### Qdrant Named Vectors ì»¬ë ‰ì…˜ ìƒì„±\n",
    "\n",
    "3ê°œì˜ Named Vectorsë¡œ ë©€í‹°ëª¨ë‹¬ ì„ë² ë”©ì„ ì €ì¥í•©ë‹ˆë‹¤:\n",
    "- `text`: Jina v4 í…ìŠ¤íŠ¸ ì„ë² ë”© (ê²€ìƒ‰ìš©)\n",
    "- `text_mm`: Omni-Embed í…ìŠ¤íŠ¸ ì„ë² ë”© (êµì°¨ ê²€ìƒ‰ìš©)\n",
    "- `image`: Omni-Embed ì´ë¯¸ì§€ ì„ë² ë”©\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c207df7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Qdrant Named Vectors ì»¬ë ‰ì…˜ ìƒì„± ë° ì—…ì„œíŠ¸\n",
    "# ============================================================================\n",
    "import pandas as pd\n",
    "from mmrag.qdrant_io import create_named_vectors_collection, upsert_multimodal_documents\n",
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "# Qdrant í´ë¼ì´ì–¸íŠ¸\n",
    "qdrant_url = os.getenv(\"QDRANT_URL\", \"http://localhost:6333\")\n",
    "qdrant_api_key = os.getenv(\"QDRANT_API_KEY\")\n",
    "print(f\"ğŸ“¡ Qdrant endpoint: {qdrant_url}\")\n",
    "\n",
    "qdrant_client = QdrantClient(url=qdrant_url, api_key=qdrant_api_key)\n",
    "MULTIMODAL_COLLECTION = \"day2_multimodal_rag_v2\"\n",
    "\n",
    "# Named Vectors ì»¬ë ‰ì…˜ ìƒì„± (ì°¨ì› ìë™ ê°ì§€)\n",
    "created = create_named_vectors_collection(\n",
    "    client=qdrant_client,\n",
    "    collection_name=MULTIMODAL_COLLECTION,\n",
    "    vector_configs={\n",
    "        \"text\": dim_jina,\n",
    "        \"text_mm\": dim_omni,\n",
    "        \"image\": dim_omni,\n",
    "    },\n",
    "    distance=models.Distance.COSINE,\n",
    "    on_disk=True,\n",
    ")\n",
    "\n",
    "if created:\n",
    "    print(f\"âœ… ì»¬ë ‰ì…˜ '{MULTIMODAL_COLLECTION}' ìƒì„± ì™„ë£Œ\")\n",
    "else:\n",
    "    print(f\"âš ï¸ ì»¬ë ‰ì…˜ '{MULTIMODAL_COLLECTION}' ì´ë¯¸ ì¡´ì¬, ê¸°ì¡´ ì‚¬ìš©\")\n",
    "\n",
    "# ë¬¸ì„œ ì—…ì„œíŠ¸\n",
    "embeddings_dict = {\n",
    "    \"text\": text_embeddings_jina,\n",
    "    \"text_mm\": text_embeddings_omni,\n",
    "    \"image\": image_embeddings,\n",
    "}\n",
    "\n",
    "num_uploaded = upsert_multimodal_documents(\n",
    "    client=qdrant_client,\n",
    "    collection_name=MULTIMODAL_COLLECTION,\n",
    "    documents=multimodal_documents,\n",
    "    embeddings=embeddings_dict,\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… {num_uploaded}ê°œ ë¬¸ì„œ ì—…ë¡œë“œ ì™„ë£Œ\")\n",
    "\n",
    "# ì—…ë¡œë“œëœ ë¬¸ì„œ í™•ì¸\n",
    "uploaded_df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"id\": doc[\"id\"],\n",
    "            \"caption_ko\": doc[\"caption_ko\"][:50] + \"...\",\n",
    "            \"topic\": doc[\"metadata\"].get(\"topic\", \"N/A\"),\n",
    "        }\n",
    "        for doc in multimodal_documents\n",
    "    ]\n",
    ")\n",
    "display(uploaded_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7772d5eb",
   "metadata": {},
   "source": [
    "#### í…ìŠ¤íŠ¸â†”ì´ë¯¸ì§€ êµì°¨ ê²€ìƒ‰\n",
    "\n",
    "Omni-EmbedëŠ” í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ë™ì¼í•œ ë²¡í„° ê³µê°„(2048ì°¨ì›)ì— ë§¤í•‘í•˜ë¯€ë¡œ\n",
    "êµì°¨ ê²€ìƒ‰ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤:\n",
    "\n",
    "1. **í…ìŠ¤íŠ¸ â†’ ì´ë¯¸ì§€**: í…ìŠ¤íŠ¸ ì¿¼ë¦¬ë¡œ ê´€ë ¨ ì´ë¯¸ì§€ ê²€ìƒ‰\n",
    "2. **ì´ë¯¸ì§€ â†’ í…ìŠ¤íŠ¸**: ì´ë¯¸ì§€ ì¿¼ë¦¬ë¡œ ê´€ë ¨ í…ìŠ¤íŠ¸(ìº¡ì…˜) ê²€ìƒ‰\n",
    "3. **Late-Fusion (RRF)**: ì—¬ëŸ¬ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í†µí•©\n",
    "4. **Reranker**: ìµœì¢… ì¬ì •ë ¬\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8211bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# í…ìŠ¤íŠ¸ â†” ì´ë¯¸ì§€ êµì°¨ ê²€ìƒ‰ í•¨ìˆ˜\n",
    "# ============================================================================\n",
    "from typing import Any\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from mmrag.qdrant_io import search_cross_modal, search_multimodal\n",
    "from mmrag.ranking import late_fusion_with_rerank\n",
    "\n",
    "\n",
    "def search_by_text(\n",
    "    query: str,\n",
    "    limit: int = 5,\n",
    "    use_cross_modal: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"í…ìŠ¤íŠ¸ë¡œ ê²€ìƒ‰ (í…ìŠ¤íŠ¸ ë˜ëŠ” ì´ë¯¸ì§€ ê²°ê³¼).\"\"\"\n",
    "    # ì¿¼ë¦¬ ì„ë² ë”© (Jina ë˜ëŠ” Omni)\n",
    "    if use_cross_modal:\n",
    "        # êµì°¨ ê²€ìƒ‰: í…ìŠ¤íŠ¸ â†’ ì´ë¯¸ì§€\n",
    "        query_emb = omni_embedder.embed_texts([query])[0]\n",
    "        results = search_cross_modal(\n",
    "            client=qdrant_client,\n",
    "            collection_name=MULTIMODAL_COLLECTION,\n",
    "            query_vector=query_emb,\n",
    "            query_vector_name=\"text_mm\",\n",
    "            target_vector_name=\"image\",\n",
    "            limit=limit,\n",
    "        )\n",
    "        search_type = \"í…ìŠ¤íŠ¸â†’ì´ë¯¸ì§€\"\n",
    "    else:\n",
    "        # ì¼ë°˜ ê²€ìƒ‰: í…ìŠ¤íŠ¸ â†’ í…ìŠ¤íŠ¸\n",
    "        query_emb = np.array(jina_embedder.embed_documents([query]))[0]\n",
    "        results = search_multimodal(\n",
    "            client=qdrant_client,\n",
    "            collection_name=MULTIMODAL_COLLECTION,\n",
    "            query_vector=query_emb,\n",
    "            vector_name=\"text\",\n",
    "            limit=limit,\n",
    "        )\n",
    "        search_type = \"í…ìŠ¤íŠ¸â†’í…ìŠ¤íŠ¸\"\n",
    "\n",
    "    # ê²°ê³¼ â†’ DataFrame\n",
    "    rows = []\n",
    "    for hit in results:\n",
    "        payload = hit.payload or {}\n",
    "        rows.append(\n",
    "            {\n",
    "                \"score\": hit.score,\n",
    "                \"caption_ko\": payload.get(\"caption_ko\", \"\")[:50] + \"...\",\n",
    "                \"topic\": payload.get(\"topic\", \"N/A\"),\n",
    "                \"filename\": payload.get(\"filename\", \"N/A\"),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    print(f\"ğŸ” {search_type} ê²€ìƒ‰: '{query}' â†’ {len(df)}ê°œ ê²°ê³¼\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def search_by_image(\n",
    "    image_path: str,\n",
    "    limit: int = 5,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"ì´ë¯¸ì§€ë¡œ ê²€ìƒ‰ (ìœ ì‚¬ ì´ë¯¸ì§€ ë˜ëŠ” ê´€ë ¨ í…ìŠ¤íŠ¸).\"\"\"\n",
    "    # ì´ë¯¸ì§€ ì„ë² ë”©\n",
    "    query_emb = omni_embedder.embed_images([image_path])[0]\n",
    "\n",
    "    # ì´ë¯¸ì§€ â†’ ì´ë¯¸ì§€ ê²€ìƒ‰\n",
    "    results = search_multimodal(\n",
    "        client=qdrant_client,\n",
    "        collection_name=MULTIMODAL_COLLECTION,\n",
    "        query_vector=query_emb,\n",
    "        vector_name=\"image\",\n",
    "        limit=limit,\n",
    "    )\n",
    "\n",
    "    # ê²°ê³¼ â†’ DataFrame\n",
    "    rows = []\n",
    "    for hit in results:\n",
    "        payload = hit.payload or {}\n",
    "        rows.append(\n",
    "            {\n",
    "                \"score\": hit.score,\n",
    "                \"caption_ko\": payload.get(\"caption_ko\", \"\")[:50] + \"...\",\n",
    "                \"topic\": payload.get(\"topic\", \"N/A\"),\n",
    "                \"filename\": payload.get(\"filename\", \"N/A\"),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    print(f\"ğŸ” ì´ë¯¸ì§€â†’ì´ë¯¸ì§€ ê²€ìƒ‰ â†’ {len(df)}ê°œ ê²°ê³¼\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def search_hybrid_with_rerank(\n",
    "    query: str,\n",
    "    top_k: int = 3,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: í…ìŠ¤íŠ¸ + êµì°¨ ê²€ìƒ‰ â†’ RRF â†’ Reranker.\"\"\"\n",
    "    # 1. í…ìŠ¤íŠ¸â†’í…ìŠ¤íŠ¸ ê²€ìƒ‰\n",
    "    query_emb_jina = np.array(jina_embedder.embed_documents([query]))[0]\n",
    "    results_text = search_multimodal(\n",
    "        client=qdrant_client,\n",
    "        collection_name=MULTIMODAL_COLLECTION,\n",
    "        query_vector=query_emb_jina,\n",
    "        vector_name=\"text\",\n",
    "        limit=10,\n",
    "    )\n",
    "\n",
    "    # 2. í…ìŠ¤íŠ¸â†’ì´ë¯¸ì§€ êµì°¨ ê²€ìƒ‰\n",
    "    query_emb_omni = omni_embedder.embed_texts([query])[0]\n",
    "    results_cross = search_cross_modal(\n",
    "        client=qdrant_client,\n",
    "        collection_name=MULTIMODAL_COLLECTION,\n",
    "        query_vector=query_emb_omni,\n",
    "        query_vector_name=\"text_mm\",\n",
    "        target_vector_name=\"image\",\n",
    "        limit=10,\n",
    "    )\n",
    "\n",
    "    # 3. ê²°ê³¼ â†’ dict í˜•íƒœë¡œ ë³€í™˜\n",
    "    def to_dict_list(results: list) -> list[dict[str, Any]]:\n",
    "        return [\n",
    "            {\n",
    "                \"id\": hit.payload.get(\"doc_id\", \"\"),\n",
    "                \"score\": hit.score,\n",
    "                \"text\": hit.payload.get(\"caption_ko\", \"\"),\n",
    "                **hit.payload,\n",
    "            }\n",
    "            for hit in results\n",
    "        ]\n",
    "\n",
    "    list_text = to_dict_list(results_text)\n",
    "    list_cross = to_dict_list(results_cross)\n",
    "\n",
    "    # 4. Late-Fusion (RRF) + Reranker\n",
    "    fused = late_fusion_with_rerank(\n",
    "        query=query,\n",
    "        result_lists=[list_text, list_cross],\n",
    "        rerank_url=RERANK_URL,\n",
    "        rrf_k=60,\n",
    "        fusion_top_k=20,\n",
    "        final_top_n=top_k,\n",
    "        text_key=\"caption_ko\",\n",
    "    )\n",
    "\n",
    "    # 5. DataFrame ë³€í™˜\n",
    "    rows = []\n",
    "    for doc in fused:\n",
    "        rows.append(\n",
    "            {\n",
    "                \"rerank_score\": doc.get(\"rerank_score\", 0.0),\n",
    "                \"rrf_score\": doc.get(\"rrf_score\", 0.0),\n",
    "                \"caption_ko\": doc.get(\"caption_ko\", \"\")[:60] + \"...\",\n",
    "                \"topic\": doc.get(\"topic\", \"N/A\"),\n",
    "                \"filename\": doc.get(\"filename\", \"N/A\"),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    print(f\"ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (RRF + Reranker): '{query}' â†’ {len(df)}ê°œ ê²°ê³¼\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ë°ëª¨ ì‹¤í–‰\n",
    "print(\"=\" * 70)\n",
    "print(\"ë°ëª¨ 1: í…ìŠ¤íŠ¸â†’í…ìŠ¤íŠ¸ ê²€ìƒ‰\")\n",
    "display(search_by_text(\"ê·¼ë¡œì‹œê°„ ì œí•œ\", limit=3))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ë°ëª¨ 2: í…ìŠ¤íŠ¸â†’ì´ë¯¸ì§€ êµì°¨ ê²€ìƒ‰\")\n",
    "display(search_by_text(\"ì£¼ 40ì‹œê°„ ê·¼ë¡œ\", limit=3, use_cross_modal=True))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ë°ëª¨ 3: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (RRF + Reranker)\")\n",
    "display(search_hybrid_with_rerank(\"ì—°ì°¨ íœ´ê°€ ì¼ìˆ˜\", top_k=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5741557",
   "metadata": {},
   "source": [
    "### 1.4 Part 1 ìš”ì•½ ë° ì°¸ê³ ìë£Œ\n",
    "\n",
    "#### ì£¼ìš” í•™ìŠµ ë‚´ìš©\n",
    "\n",
    "1. **Omni-Embed + Jina v4** ê¸°ë°˜ 3ì¢…ë¥˜ ì„ë² ë”© ìƒì„± ë° Qdrant Named Vectors ì €ì¥\n",
    "   - Jina v4 í…ìŠ¤íŠ¸ ì„ë² ë”© (ê²€ìƒ‰ìš©)\n",
    "   - Omni-Embed í…ìŠ¤íŠ¸ ì„ë² ë”© (êµì°¨ ê²€ìƒ‰ìš©, 2048ì°¨ì›)\n",
    "   - Omni-Embed ì´ë¯¸ì§€ ì„ë² ë”© (2048ì°¨ì›)\n",
    "\n",
    "2. **êµì°¨ ê²€ìƒ‰ ë° í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰** êµ¬í˜„\n",
    "   - í…ìŠ¤íŠ¸ â†’ í…ìŠ¤íŠ¸ ê²€ìƒ‰ (Jina v4)\n",
    "   - í…ìŠ¤íŠ¸ â†’ ì´ë¯¸ì§€ êµì°¨ ê²€ìƒ‰ (Omni-Embed)\n",
    "   - ì´ë¯¸ì§€ â†’ ì´ë¯¸ì§€ ê²€ìƒ‰ (Omni-Embed)\n",
    "   - RRF + Reranker í†µí•© íŒŒì´í”„ë¼ì¸\n",
    "\n",
    "3. **í”„ë¡œë•ì…˜ ìˆ˜ì¤€ ê¸°ëŠ¥**\n",
    "   - Late-Fusion (Reciprocal Rank Fusion)\n",
    "   - Jina Reranker v3ë¥¼ í†µí•œ ìµœì¢… ì¬ì •ë ¬\n",
    "   - ë°°ì¹˜ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë¡œì§\n",
    "\n",
    "#### ì°¸ê³ ìë£Œ\n",
    "- [Qdrant Multimodal Search ê°€ì´ë“œ](https://qdrant.tech/documentation/multimodal-search/)\n",
    "- [Omni-Embed Nemotron 3B](https://huggingface.co/nvidia/omni-embed-nemotron-3b)\n",
    "- [Jina Embeddings v4](https://huggingface.co/jinaai/jina-embeddings-v4)\n",
    "- [Jina Reranker v3](https://huggingface.co/jinaai/jina-reranker-v3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d23b731",
   "metadata": {},
   "source": [
    "### 1.5 RAG ìƒì„± ì²´ì¸\n",
    "\n",
    "ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ LLMì— ì „ë‹¬í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "**í•µì‹¬ ì›ì¹™**:\n",
    "- ì¶œì²˜ í‘œê¸° (íŒŒì¼ëª…/ìº¡ì…˜)\n",
    "- ëª¨ë¥´ëŠ” ë‚´ìš©ì€ ì†”ì§í•˜ê²Œ \"ëª¨ë¥¸ë‹¤\" ë‹µë³€\n",
    "- LangFuse íŠ¸ë ˆì´ì‹±ìœ¼ë¡œ ê´€ì¸¡\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e98b518",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# LLM ì´ˆê¸°í™”\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m llm = \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\u001b[39;00m\n\u001b[32m     15\u001b[39m rag_template = \u001b[33m\"\"\"\u001b[39m\u001b[33më‹¹ì‹ ì€ í•œêµ­ ë²•ë¥ /ë¬¸ì„œ ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤.\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[33mì œê³µëœ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.\u001b[39m\n\u001b[32m     17\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m \n\u001b[32m     28\u001b[39m \u001b[33m**ë‹µë³€**:\u001b[39m\u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/sds_class/.venv/lib/python3.13/site-packages/langchain_core/load/serializable.py:116\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    115\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419  # Intentional blank docstring\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/sds_class/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:914\u001b[39m, in \u001b[36mBaseChatOpenAI.validate_environment\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    904\u001b[39m         \u001b[38;5;28mself\u001b[39m.http_async_client = httpx.AsyncClient(\n\u001b[32m    905\u001b[39m             proxy=\u001b[38;5;28mself\u001b[39m.openai_proxy, verify=global_ssl_context\n\u001b[32m    906\u001b[39m         )\n\u001b[32m    907\u001b[39m     async_specific = {\n\u001b[32m    908\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttp_client\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.http_async_client\n\u001b[32m    909\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _get_default_async_httpx_client(\n\u001b[32m   (...)\u001b[39m\u001b[32m    912\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mapi_key\u001b[39m\u001b[33m\"\u001b[39m: async_api_key_value,\n\u001b[32m    913\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m     \u001b[38;5;28mself\u001b[39m.root_async_client = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAsyncOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mclient_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43masync_specific\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    918\u001b[39m     \u001b[38;5;28mself\u001b[39m.async_client = \u001b[38;5;28mself\u001b[39m.root_async_client.chat.completions\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/sds_class/.venv/lib/python3.13/site-packages/openai/_client.py:488\u001b[39m, in \u001b[36mAsyncOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    486\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    489\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    490\u001b[39m     )\n\u001b[32m    491\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(api_key):\n\u001b[32m    492\u001b[39m     \u001b[38;5;28mself\u001b[39m.api_key = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# RAG ì²´ì¸ êµ¬í˜„\n",
    "# ============================================================================\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "rag_template = \"\"\"ë‹¹ì‹ ì€ í•œêµ­ ë²•ë¥ /ë¬¸ì„œ ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤.\n",
    "ì œê³µëœ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.\n",
    "\n",
    "**ê·œì¹™**:\n",
    "1. ì¶œì²˜ë¥¼ ëª…í™•íˆ í‘œê¸°í•˜ì„¸ìš” (ì˜ˆ: \"ê·¼ë¡œê¸°ì¤€ë²• ì œ50ì¡° ë‹¤ì´ì–´ê·¸ë¨ì— ë”°ë¥´ë©´...\")\n",
    "2. ì»¨í…ìŠ¤íŠ¸ì— ì—†ëŠ” ë‚´ìš©ì€ ì†”ì§í•˜ê²Œ ëª¨ë¥¸ë‹¤ê³  ë‹µë³€í•˜ì„¸ìš”.\n",
    "3. ë²•ì  ì¡°ì–¸ì´ í•„ìš”í•œ ê²½ìš° ì „ë¬¸ê°€ ìƒë‹´ì„ ê¶Œìœ í•˜ì„¸ìš”.\n",
    "\n",
    "**ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸**:\n",
    "{context}\n",
    "\n",
    "**ì§ˆë¬¸**: {question}\n",
    "\n",
    "**ë‹µë³€**:\"\"\"\n",
    "\n",
    "rag_prompt = PromptTemplate(\n",
    "    template=rag_template,\n",
    "    input_variables=[\"context\", \"question\"],\n",
    ")\n",
    "\n",
    "# RAG ì²´ì¸\n",
    "rag_chain = rag_prompt | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "def multimodal_rag_answer(query: str, top_k: int = 3) -> str:\n",
    "    \"\"\"ë©€í‹°ëª¨ë‹¬ RAG ë‹µë³€ ìƒì„±.\"\"\"\n",
    "    # 1. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰\n",
    "    results_df = search_hybrid_with_rerank(query, top_k=top_k)\n",
    "\n",
    "    # 2. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±\n",
    "    context_parts = []\n",
    "    for idx, row in results_df.iterrows():\n",
    "        context_parts.append(\n",
    "            f\"[ë¬¸ì„œ {idx + 1}] {row['filename']}\\n\"\n",
    "            f\"ë‚´ìš©: {row['caption_ko']}\\n\"\n",
    "            f\"ì£¼ì œ: {row['topic']}\\n\"\n",
    "            f\"ê´€ë ¨ë„: {row['rerank_score']:.3f}\\n\"\n",
    "        )\n",
    "\n",
    "    context = \"\\n\".join(context_parts)\n",
    "\n",
    "    # 3. LLM ë‹µë³€ ìƒì„±\n",
    "    answer = rag_chain.invoke({\"context\": context, \"question\": query})\n",
    "\n",
    "    return answer\n",
    "\n",
    "\n",
    "# ë°ëª¨ ì‹¤í–‰\n",
    "print(\"=\" * 70)\n",
    "print(\"ë©€í‹°ëª¨ë‹¬ RAG ë‹µë³€ ìƒì„± ë°ëª¨\\n\")\n",
    "\n",
    "test_queries = [\n",
    "    \"ê·¼ë¡œì‹œê°„ì€ ì–´ë–»ê²Œ ì œí•œë˜ë‚˜ìš”?\",\n",
    "    \"ì—°ì°¨ íœ´ê°€ëŠ” ëª‡ ì¼ì¸ê°€ìš”?\",\n",
    "]\n",
    "\n",
    "for q in test_queries:\n",
    "    print(f\"\\nì§ˆë¬¸: {q}\")\n",
    "    print(\"-\" * 70)\n",
    "    answer = multimodal_rag_answer(q, top_k=3)\n",
    "    print(f\"ë‹µë³€:\\n{answer}\\n\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nPart 1: Multi-Modal RAG ì™„ë£Œ!\")\n",
    "print(\"   ë‹¤ìŒ: Part 2 (GraphRAG)ë¡œ ì´ë™í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625eabd7",
   "metadata": {},
   "source": [
    "**Multi-Modal RAGì˜ ì¥ì **:\n",
    "1. ë‹¤ì–‘í•œ ë°ì´í„° í˜•ì‹ í†µí•© (í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤)\n",
    "2. ë‹¤êµ­ì–´ ê²€ìƒ‰ ìš©ì´\n",
    "3. OCR ì—†ì´ë„ ì´ë¯¸ì§€ ë‚´ìš© ê²€ìƒ‰ ê°€ëŠ¥\n",
    "4. êµ¬í˜„ì´ ìƒëŒ€ì ìœ¼ë¡œ ë‹¨ìˆœí•¨\n",
    "\n",
    "**Multi-Modal RAGì˜ ë‹¨ì **:\n",
    "1. ë¬¸ì„œ êµ¬ì¡° ì •ë³´ í™œìš© ì–´ë ¤ì›€\n",
    "2. ê³„ì¸µì  ë¬¸ë§¥ ì œê³µ ë¶ˆê°€\n",
    "3. ëŒ€ìš©ëŸ‰ ëª¨ë¸ í•„ìš” (GPU ìš”êµ¬)\n",
    "4. ì´ë¯¸ì§€ í’ˆì§ˆì— ë¯¼ê°\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bf1a32",
   "metadata": {},
   "source": [
    "### ì–¸ì œ Multi-Modal RAGë¥¼ ì„ íƒí• ê¹Œìš”?\n",
    "\n",
    "**ì í•©í•œ ì‹œë‚˜ë¦¬ì˜¤**:\n",
    "1. ì˜ë£Œ ì˜ìƒ ê²€ìƒ‰ ì‹œìŠ¤í…œ\n",
    "2. ì „ììƒê±°ë˜ ìƒí’ˆ ê²€ìƒ‰ (ì´ë¯¸ì§€ ê¸°ë°˜)\n",
    "3. êµìœ¡ í”Œë«í¼ (ë‹¤ì´ì–´ê·¸ë¨, ì°¨íŠ¸ ê²€ìƒ‰)\n",
    "4. ë¯¸ë””ì–´ ê´€ë¦¬ ì‹œìŠ¤í…œ\n",
    "5. ë‹¤êµ­ì–´ ë¬¸ì„œ ê²€ìƒ‰\n",
    "\n",
    "**ì„ íƒ ê¸°ì¤€**:\n",
    "- í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ê°€ í˜¼ì¬ëœ ë°ì´í„°\n",
    "- ë¬¸ì„œ êµ¬ì¡°ê°€ ì¤‘ìš”í•˜ì§€ ì•Šì€ ê²½ìš°\n",
    "- ë¹ ë¥¸ êµ¬ì¶•ì´ í•„ìš”í•œ ê²½ìš°\n",
    "- ë‹¤ì–‘í•œ ì–¸ì–´ ì§€ì›ì´ í•„ìš”í•œ ê²½ìš°\n",
    "\n",
    "### Multi-Modal RAG êµ¬í˜„ ì‹œ\n",
    "\n",
    "- ì´ë¯¸ì§€ í’ˆì§ˆ í™•ì¸ (í•´ìƒë„, ì„ ëª…ë„)\n",
    "- ì ì ˆí•œ ì„ë² ë”© ëª¨ë¸ ì„ íƒ (vdr-2b-multi-v1, CLIP ë“±)\n",
    "- GPU ë¦¬ì†ŒìŠ¤ í™•ë³´ (ëª¨ë¸ í¬ê¸° ê³ ë ¤)\n",
    "- ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„± ì „ëµ ê²°ì • (ìë™/ìˆ˜ë™)\n",
    "- Named Vectors êµ¬ì¡° ì„¤ê³„\n",
    "- Late Fusion ì „ëµ êµ¬í˜„\n",
    "- ë‹¤êµ­ì–´ ì§€ì› í…ŒìŠ¤íŠ¸\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
